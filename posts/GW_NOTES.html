<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>GW note</title><style type='text/css'>html {overflow-x: initial !important;}:root { --bg-color: #ffffff; --text-color: #333333; --select-text-bg-color: #B5D6FC; --select-text-font-color: auto; --monospace: "Lucida Console",Consolas,"Courier",monospace; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
body { margin: 0px; padding: 0px; height: auto; bottom: 0px; top: 0px; left: 0px; right: 0px; font-size: 1rem; line-height: 1.42857143; overflow-x: hidden; background-image: inherit; background-size: inherit; background-attachment: inherit; background-origin: inherit; background-clip: inherit; background-color: inherit; background-position: inherit inherit; background-repeat: inherit inherit; }
iframe { margin: auto; }
a.url { word-break: break-all; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; word-wrap: break-word; position: relative; white-space: normal; padding-bottom: 70px; overflow-x: visible; }
.first-line-indent #write div, .first-line-indent #write li, .first-line-indent #write p { text-indent: 2em; }
.first-line-indent #write div :not(p):not(div), .first-line-indent #write div.md-htmlblock-container, .first-line-indent #write p *, .first-line-indent pre { text-indent: 0px; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
@media screen and (max-width: 500px) { 
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  .CodeMirror-sizer { margin-left: 0px !important; }
  .CodeMirror-gutters { display: none !important; }
}
#write > blockquote:first-child, #write > div:first-child, #write > figure:first-child, #write > ol:first-child, #write > p:first-child, #write > pre:first-child, #write > ul:first-child { margin-top: 30px; }
#write li > figure:first-child { margin-top: -20px; }
#write ol, #write ul { position: relative; }
img { max-width: 100%; vertical-align: middle; }
button, input, select, textarea { color: inherit; font-family: inherit; font-size: inherit; font-style: inherit; font-variant-caps: inherit; font-weight: inherit; font-stretch: inherit; line-height: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p { position: relative; }
h1, h2, h3, h4, h5, h6 { break-after: avoid-page; break-inside: avoid; orphans: 2; }
p { orphans: 4; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
.md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p { margin-top: 1rem; margin-bottom: 1rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.701961); color: rgb(85, 85, 85); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; cursor: pointer; }
sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
figure { overflow-x: auto; margin: 1.2em 0px; max-width: calc(100% + 16px); padding: 0px; }
figure > table { margin: 0px !important; }
tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 80px; }
.CodeMirror-gutters { border-right-width: 0px; background-color: inherit; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
#write pre { white-space: pre-wrap; }
#write.fences-no-line-wrapping pre { white-space: pre; }
#write pre.ty-contain-cm { white-space: normal; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background-image: inherit; background-size: inherit; background-attachment: inherit; background-origin: inherit; background-clip: inherit; background-color: inherit; position: relative !important; background-position: inherit inherit; background-repeat: inherit inherit; }
.md-diagram-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
#write .md-fences.mock-cm { white-space: pre-wrap; }
.md-fences.md-fences-with-lineno { padding-left: 0px; }
#write.fences-no-line-wrapping .md-fences.mock-cm { white-space: pre; overflow-x: auto; }
.md-fences.mock-cm.md-fences-with-lineno { padding-left: 8px; }
.CodeMirror-line, twitterwidget { break-inside: avoid; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; direction: ltr; background-position: 0px 0px; background-repeat: initial initial; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child, li > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; }
#write .footnote-line { white-space: pre-wrap; }
@media print { 
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid-page; break-before: avoid-page; }
  #write { margin-top: 0px; border-color: transparent !important; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  html.blink-to-pdf { font-size: 13px; }
  .typora-export #write { padding-left: 1cm; padding-right: 1cm; padding-bottom: 0px; break-after: avoid-page; }
  .typora-export #write::after { height: 0px; }
  @page { margin: 20mm 0px; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background-color: rgb(204, 204, 204); display: block; overflow-x: hidden; background-position: initial initial; background-repeat: initial initial; }
p > img:only-child { display: block; margin: auto; }
p > .md-image:only-child { display: inline-block; width: 100%; text-align: center; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.md-math-block { width: 100%; }
.md-math-block:not(:empty)::after { display: none; }
[contenteditable="true"]:active, [contenteditable="true"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-top-left-radius: 10px; border-top-right-radius: 10px; border-bottom-right-radius: 10px; border-bottom-left-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-content::after, .md-toc::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) { 
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, samp, tt { font-family: var(--monospace); }
kbd { margin: 0px 0.1em; padding: 0.1em 0.6em; font-size: 0.8em; color: rgb(36, 39, 41); background-color: rgb(255, 255, 255); border: 1px solid rgb(173, 179, 185); border-top-left-radius: 3px; border-top-right-radius: 3px; border-bottom-right-radius: 3px; border-bottom-left-radius: 3px; box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset; white-space: nowrap; vertical-align: middle; background-position: initial initial; background-repeat: initial initial; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.8; font-family: var(--monospace); }
code { text-align: left; }
a.md-print-anchor { white-space: pre !important; border: none !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; text-shadow: initial !important; background-position: 0px 0px !important; background-repeat: initial initial !important; }
.md-inline-math .MathJax_SVG .noError { display: none !important; }
.md-math-block .MathJax_SVG_Display { text-align: center; margin: 0px; position: relative; text-indent: 0px; max-width: none; max-height: none; min-height: 0px; min-width: 100%; width: auto; overflow-y: hidden; display: block !important; }
.MathJax_SVG_Display, .md-inline-math .MathJax_SVG_Display { width: auto; margin: inherit; display: inline-block !important; }
.MathJax_SVG .MJX-monospace { font-family: var(--monospace); }
.MathJax_SVG .MJX-sans-serif { font-family: sans-serif; }
.MathJax_SVG { display: inline; font-style: normal; font-weight: 400; line-height: normal; zoom: 90%; text-indent: 0px; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px; }
.MathJax_SVG * { transition: none; }
.MathJax_SVG_Display svg { vertical-align: middle !important; margin-bottom: 0px !important; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="mermaid"] svg, [lang="flow"] svg { max-width: 100%; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom-width: 0px; }
video { max-width: 100%; display: block; margin: 0px auto; }
iframe { max-width: 100%; width: 100%; border: none; }
.highlight td, .highlight tr { border: 0px; }


:root {
    --side-bar-bg-color: #fff;
    --control-text-color: #777;
}

/* cyrillic-ext */
@font-face {
    font-family: 'Roboto Mono';
    font-style: normal;
    font-weight: 400;
    src: local('Roboto Mono'), local('RobotoMono-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/L0x5DF4xlVMF-BfR8bXMIjhGq3-cXbKDO1w.woff2') format('woff2');
    unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}

/* cyrillic */
@font-face {
    font-family: 'Roboto Mono';
    font-style: normal;
    font-weight: 400;
    src: local('Roboto Mono'), local('RobotoMono-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/L0x5DF4xlVMF-BfR8bXMIjhPq3-cXbKDO1w.woff2') format('woff2');
    unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}

/* greek-ext */
@font-face {
    font-family: 'Roboto Mono';
    font-style: normal;
    font-weight: 400;
    src: local('Roboto Mono'), local('RobotoMono-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/L0x5DF4xlVMF-BfR8bXMIjhHq3-cXbKDO1w.woff2') format('woff2');
    unicode-range: U+1F00-1FFF;
}

/* greek */
@font-face {
    font-family: 'Roboto Mono';
    font-style: normal;
    font-weight: 400;
    src: local('Roboto Mono'), local('RobotoMono-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/L0x5DF4xlVMF-BfR8bXMIjhIq3-cXbKDO1w.woff2') format('woff2');
    unicode-range: U+0370-03FF;
}

/* vietnamese */
@font-face {
    font-family: 'Roboto Mono';
    font-style: normal;
    font-weight: 400;
    src: local('Roboto Mono'), local('RobotoMono-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/L0x5DF4xlVMF-BfR8bXMIjhEq3-cXbKDO1w.woff2') format('woff2');
    unicode-range: U+0102-0103, U+0110-0111, U+1EA0-1EF9, U+20AB;
}

/* latin-ext */
@font-face {
    font-family: 'Roboto Mono';
    font-style: normal;
    font-weight: 400;
    src: local('Roboto Mono'), local('RobotoMono-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/L0x5DF4xlVMF-BfR8bXMIjhFq3-cXbKDO1w.woff2') format('woff2');
    unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}

/* latin */
@font-face {
    font-family: 'Roboto Mono';
    font-style: normal;
    font-weight: 400;
    src: local('Roboto Mono'), local('RobotoMono-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/L0x5DF4xlVMF-BfR8bXMIjhLq3-cXbKD.woff2') format('woff2');
    unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}

/* cyrillic-ext */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 300;
    src: local('Source Sans Pro Light'), local('SourceSansPro-Light'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwmhduz8A.woff2') format('woff2');
    unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}

/* cyrillic */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 300;
    src: local('Source Sans Pro Light'), local('SourceSansPro-Light'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwkxduz8A.woff2') format('woff2');
    unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}

/* greek-ext */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 300;
    src: local('Source Sans Pro Light'), local('SourceSansPro-Light'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwmxduz8A.woff2') format('woff2');
    unicode-range: U+1F00-1FFF;
}

/* greek */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 300;
    src: local('Source Sans Pro Light'), local('SourceSansPro-Light'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwlBduz8A.woff2') format('woff2');
    unicode-range: U+0370-03FF;
}

/* vietnamese */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 300;
    src: local('Source Sans Pro Light'), local('SourceSansPro-Light'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwmBduz8A.woff2') format('woff2');
    unicode-range: U+0102-0103, U+0110-0111, U+1EA0-1EF9, U+20AB;
}

/* latin-ext */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 300;
    src: local('Source Sans Pro Light'), local('SourceSansPro-Light'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwmRduz8A.woff2') format('woff2');
    unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}

/* latin */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 300;
    src: local('Source Sans Pro Light'), local('SourceSansPro-Light'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwlxdu.woff2') format('woff2');
    unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}

/* cyrillic-ext */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 400;
    src: local('Source Sans Pro Regular'), local('SourceSansPro-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNa7lqDY.woff2') format('woff2');
    unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}

/* cyrillic */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 400;
    src: local('Source Sans Pro Regular'), local('SourceSansPro-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qPK7lqDY.woff2') format('woff2');
    unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}

/* greek-ext */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 400;
    src: local('Source Sans Pro Regular'), local('SourceSansPro-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNK7lqDY.woff2') format('woff2');
    unicode-range: U+1F00-1FFF;
}

/* greek */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 400;
    src: local('Source Sans Pro Regular'), local('SourceSansPro-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qO67lqDY.woff2') format('woff2');
    unicode-range: U+0370-03FF;
}

/* vietnamese */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 400;
    src: local('Source Sans Pro Regular'), local('SourceSansPro-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qN67lqDY.woff2') format('woff2');
    unicode-range: U+0102-0103, U+0110-0111, U+1EA0-1EF9, U+20AB;
}

/* latin-ext */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 400;
    src: local('Source Sans Pro Regular'), local('SourceSansPro-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNq7lqDY.woff2') format('woff2');
    unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}

/* latin */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 400;
    src: local('Source Sans Pro Regular'), local('SourceSansPro-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qOK7l.woff2') format('woff2');
    unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}

/* cyrillic-ext */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 600;
    src: local('Source Sans Pro SemiBold'), local('SourceSansPro-SemiBold'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmhduz8A.woff2') format('woff2');
    unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}

/* cyrillic */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 600;
    src: local('Source Sans Pro SemiBold'), local('SourceSansPro-SemiBold'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwkxduz8A.woff2') format('woff2');
    unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}

/* greek-ext */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 600;
    src: local('Source Sans Pro SemiBold'), local('SourceSansPro-SemiBold'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmxduz8A.woff2') format('woff2');
    unicode-range: U+1F00-1FFF;
}

/* greek */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 600;
    src: local('Source Sans Pro SemiBold'), local('SourceSansPro-SemiBold'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwlBduz8A.woff2') format('woff2');
    unicode-range: U+0370-03FF;
}

/* vietnamese */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 600;
    src: local('Source Sans Pro SemiBold'), local('SourceSansPro-SemiBold'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmBduz8A.woff2') format('woff2');
    unicode-range: U+0102-0103, U+0110-0111, U+1EA0-1EF9, U+20AB;
}

/* latin-ext */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 600;
    src: local('Source Sans Pro SemiBold'), local('SourceSansPro-SemiBold'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmRduz8A.woff2') format('woff2');
    unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}

/* latin */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 600;
    src: local('Source Sans Pro SemiBold'), local('SourceSansPro-SemiBold'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwlxdu.woff2') format('woff2');
    unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}

html {
    font-size: 16px;
}

body {
    font-family: Source Sans Pro, Helvetica Neue, Arial, sans-serif !important;
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

#write {
    max-width: 860px;
    margin: 0 auto;
    padding: 20px 30px 40px 30px;
    padding-top: 20px;
    padding-bottom: 100px;
}

#write p {
    /* text-indent: 2rem; */
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write>ul:first-child,
#write>ol:first-child {
    margin-top: 30px;
}

body>*:first-child {
    margin-top: 0 !important;
}

body>*:last-child {
    margin-bottom: 0 !important;
}

a {
    color: #42b983;
    font-weight: 600;
    padding: 0px 2px;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 1rem;
    font-weight: bold;
    line-height: 1.4;
    cursor: text;
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit;
}

h2 tt,
h2 code {
    font-size: inherit;
}

h3 tt,
h3 code {
    font-size: inherit;
}

h4 tt,
h4 code {
    font-size: inherit;
}

h5 tt,
h5 code {
    font-size: inherit;
}

h6 tt,
h6 code {
    font-size: inherit;
}

h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}

h2 {
    font-size: 1.75rem;
    line-height: 1.225;
    margin: 35px 0px 15px 0px;
}

h3 {
    font-size: 1.4rem;
    line-height: 1.43;
    margin: 20px 0px 7px 0px;
}

h4 {
    font-size: 1.2rem;
}

h5 {
    font-size: 1rem;
}

h6 {
    font-size: 1rem;
    color: #777;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li>ol,
li>ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body>h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body>h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body>h1:first-child+h2 {
    margin-top: 0;
    padding-top: 0;
}

body>h3:first-child,
body>h4:first-child,
body>h5:first-child,
body>h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

blockquote {
    border-left: 4px solid #42b983;
    padding: 10px 0px 10px 15px;
    color: #777;
    background-color: rgba(66, 185, 131, .1);
}

table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

table tr:nth-child(2n),
thead {
    background-color: #fafafa;
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

#write strong {
    padding: 0px 1px 0 1px;
}

#write em {
    padding: 0px 5px 0 2px;
}

#write table thead th {
    background-color: #f2f2f2;
}

#write .CodeMirror-gutters {
    border-right: none;
}

#write .md-fences {
    border: 1px solid #F4F4F4;
    -webkit-font-smoothing: initial;
    margin: 0.8rem 0 !important;
    padding: 0.3rem 0rem !important;
    line-height: 1.43rem;
    background-color: #F8F8F8 !important;
    border-radius: 2px;
    font-family: Roboto Mono, Source Sans Pro, Monaco, courier, monospace !important;
    font-size: 0.85rem;
    word-wrap: normal;
}

#write .CodeMirror-wrap .CodeMirror-code pre {
    padding-left: 12px;
}

#write code, tt {
    margin: 0 2px;
    padding: 2px 4px;
    border-radius: 2px;
    font-family: Source Sans Pro, Roboto Mono, Monaco, courier, monospace !important;
    font-size: 0.92rem;
    color: #e96900;
    background-color: #f8f8f8;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: #e96900;
}

/* heighlight. */
#write mark {
    background-color:#EBFFEB;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
    color: #222;
    font-weight: 500;
}

#write del {
    padding: 1px 2px;
}

.cm-s-inner .cm-link,
.cm-s-inner.cm-link {
    color: #22a2c9;
}

.cm-s-inner .cm-string {
    color: #22a2c9;
}

.md-task-list-item>input {
    margin-left: -1.3em;
}

@media screen and (min-width: 914px) {
    /*body {
        width: 854px;
        margin: 0 auto;
    }*/
}

@media print {
    html {
        font-size: 13px;
    }
    table,
    pre {
        page-break-inside: avoid;
    }
    pre {
        word-wrap: break-word;
    }
}

.md-fences {
    background-color: #f8f8f8;
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block>.code-tooltip {
    bottom: .375rem;
}

#write>h3.md-focus:before {
    left: -1.5625rem;
    top: .375rem;
}

#write>h4.md-focus:before {
    left: -1.5625rem;
    top: .285714286rem;
}

#write>h5.md-focus:before {
    left: -1.5625rem;
    top: .285714286rem;
}

#write>h6.md-focus:before {
    left: -1.5625rem;
    top: .285714286rem;
}

.md-image>.md-meta {
    /*border: 1px solid #ddd;*/
    border-radius: 3px;
    font-family: Consolas, "Liberation Mono", Courier, monospace;
    padding: 2px 0px 0px 4px;
    font-size: 0.9em;
    color: inherit;
}

.md-tag {
    color: inherit;
}

.md-toc {
    margin-top: 20px;
    padding-bottom: 20px;
}

.sidebar-tabs {
    border-bottom: none;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

/** focus mode */

.on-focus-mode blockquote {
    border-left-color: rgba(85, 85, 85, 0.12);
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: "Segoe UI", "Arial", sans-serif;
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.mac-seamless-mode #typora-sidebar {
    background-color: #fafafa;
    background-color: var(--side-bar-bg-color);
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}


</style>
</head>
<body class='typora-export' >
<div  id='write'  class = 'is-mac'><p>&nbsp;</p><div class='md-toc' mdtype='toc'><p class="md-toc-content"><span class="md-toc-item md-toc-h1" data-ref="n13"><a class="md-toc-inner" style="" href="#header-n13">值得关注更新的站点</a></span><span class="md-toc-item md-toc-h1" data-ref="n53"><a class="md-toc-inner" style="" href="#header-n53">值得阅读的技术博客：</a></span><span class="md-toc-item md-toc-h1" data-ref="n134"><a class="md-toc-inner" style="" href="#header-n134">值得关注更新的公众号</a></span><span class="md-toc-item md-toc-h1" data-ref="n145"><a class="md-toc-inner" style="" href="#header-n145">关乎研究和学习经验</a></span><span class="md-toc-item md-toc-h1" data-ref="n173"><a class="md-toc-inner" style="" href="#header-n173">关于 Books</a></span><span class="md-toc-item md-toc-h1" data-ref="n183"><a class="md-toc-inner" style="" href="#header-n183">Scientific tips</a></span><span class="md-toc-item md-toc-h1" data-ref="n203"><a class="md-toc-inner" style="" href="#header-n203">概述性文章</a></span><span class="md-toc-item md-toc-h1" data-ref="n231"><a class="md-toc-inner" style="" href="#header-n231">Mathematics of DL</a></span><span class="md-toc-item md-toc-h1" data-ref="n237"><a class="md-toc-inner" style="" href="#header-n237">Power and Limits of Deep Learning</a></span><span class="md-toc-item md-toc-h1" data-ref="n250"><a class="md-toc-inner" style="" href="#header-n250">经典的公开课程 &amp; 入门教学</a></span><span class="md-toc-item md-toc-h1" data-ref="n318"><a class="md-toc-inner" style="" href="#header-n318">迁移学习</a></span><span class="md-toc-item md-toc-h1" data-ref="n334"><a class="md-toc-inner" style="" href="#header-n334">t-sne</a></span><span class="md-toc-item md-toc-h1" data-ref="n342"><a class="md-toc-inner" style="" href="#header-n342">DNN</a></span><span class="md-toc-item md-toc-h1" data-ref="n346"><a class="md-toc-inner" style="" href="#header-n346">卷积神经网络</a></span><span class="md-toc-item md-toc-h2" data-ref="n358"><a class="md-toc-inner" style="" href="#header-n358">综述性文章</a></span><span class="md-toc-item md-toc-h2" data-ref="n392"><a class="md-toc-inner" style="" href="#header-n392">基准模型</a></span><span class="md-toc-item md-toc-h2" data-ref="n394"><a class="md-toc-inner" style="" href="#header-n394">架构设计</a></span><span class="md-toc-item md-toc-h2" data-ref="n422"><a class="md-toc-inner" style="" href="#header-n422">可视化</a></span><span class="md-toc-item md-toc-h2" data-ref="n427"><a class="md-toc-inner" style="" href="#header-n427">卷积</a></span><span class="md-toc-item md-toc-h2" data-ref="n434"><a class="md-toc-inner" style="" href="#header-n434">调参经验</a></span><span class="md-toc-item md-toc-h2" data-ref="n454"><a class="md-toc-inner" style="" href="#header-n454">Optimizing Hyperparameters</a></span><span class="md-toc-item md-toc-h2" data-ref="n457"><a class="md-toc-inner" style="" href="#header-n457">Transposed convolution</a></span><span class="md-toc-item md-toc-h2" data-ref="n461"><a class="md-toc-inner" style="" href="#header-n461">空洞卷积技术 Dilated Convolutions</a></span><span class="md-toc-item md-toc-h2" data-ref="n465"><a class="md-toc-inner" style="" href="#header-n465">Activation</a></span><span class="md-toc-item md-toc-h2" data-ref="n474"><a class="md-toc-inner" style="" href="#header-n474">Pooling</a></span><span class="md-toc-item md-toc-h2" data-ref="n486"><a class="md-toc-inner" style="" href="#header-n486">Receptive Field</a></span><span class="md-toc-item md-toc-h2" data-ref="n491"><a class="md-toc-inner" style="" href="#header-n491">Kernel size</a></span><span class="md-toc-item md-toc-h2" data-ref="n493"><a class="md-toc-inner" style="" href="#header-n493">Learning rate</a></span><span class="md-toc-item md-toc-h2" data-ref="n498"><a class="md-toc-inner" style="" href="#header-n498">Batch size</a></span><span class="md-toc-item md-toc-h2" data-ref="n501"><a class="md-toc-inner" style="" href="#header-n501">Loss function</a></span><span class="md-toc-item md-toc-h2" data-ref="n505"><a class="md-toc-inner" style="" href="#header-n505">Batch Normalization</a></span><span class="md-toc-item md-toc-h2" data-ref="n514"><a class="md-toc-inner" style="" href="#header-n514">Dropout</a></span><span class="md-toc-item md-toc-h2" data-ref="n523"><a class="md-toc-inner" style="" href="#header-n523">Overfitting</a></span><span class="md-toc-item md-toc-h2" data-ref="n527"><a class="md-toc-inner" style="" href="#header-n527">Optimization 梯度下降优化 &amp; 凸优化与近似</a></span><span class="md-toc-item md-toc-h1" data-ref="n555"><a class="md-toc-inner" style="" href="#header-n555">GAN</a></span><span class="md-toc-item md-toc-h2" data-ref="n604"><a class="md-toc-inner" style="" href="#header-n604">关于对抗性</a></span><span class="md-toc-item md-toc-h1" data-ref="n629"><a class="md-toc-inner" style="" href="#header-n629">Autoencoders</a></span><span class="md-toc-item md-toc-h1" data-ref="n633"><a class="md-toc-inner" style="" href="#header-n633">变分自编码器（VAE）</a></span><span class="md-toc-item md-toc-h2" data-ref="n3147"><a class="md-toc-inner" style="" href="#header-n3147">Inception</a></span><span class="md-toc-item md-toc-h1" data-ref="n637"><a class="md-toc-inner" style="" href="#header-n637">残差网络</a></span><span class="md-toc-item md-toc-h1" data-ref="n643"><a class="md-toc-inner" style="" href="#header-n643">目标检测算法</a></span><span class="md-toc-item md-toc-h1" data-ref="n656"><a class="md-toc-inner" style="" href="#header-n656">语义分割</a></span><span class="md-toc-item md-toc-h1" data-ref="n661"><a class="md-toc-inner" style="" href="#header-n661">降噪</a></span><span class="md-toc-item md-toc-h1" data-ref="n677"><a class="md-toc-inner" style="" href="#header-n677">数据不均衡&amp;数据扩增</a></span><span class="md-toc-item md-toc-h1" data-ref="n685"><a class="md-toc-inner" style="" href="#header-n685">数据预处理</a></span><span class="md-toc-item md-toc-h1" data-ref="n3206"><a class="md-toc-inner" style="" href="#header-n3206">Feature Scaling and Normalization</a></span><span class="md-toc-item md-toc-h1" data-ref="n690"><a class="md-toc-inner" style="" href="#header-n690">权重初始化</a></span><span class="md-toc-item md-toc-h1" data-ref="n714"><a class="md-toc-inner" style="" href="#header-n714">可解释性</a></span><span class="md-toc-item md-toc-h1" data-ref="n783"><a class="md-toc-inner" style="" href="#header-n783">泛化能力</a></span><span class="md-toc-item md-toc-h1" data-ref="n793"><a class="md-toc-inner" style="" href="#header-n793">RNN/LSTM</a></span><span class="md-toc-item md-toc-h1" data-ref="n799"><a class="md-toc-inner" style="" href="#header-n799">PDE</a></span><span class="md-toc-item md-toc-h1" data-ref="n802"><a class="md-toc-inner" style="" href="#header-n802">NLP</a></span><span class="md-toc-item md-toc-h1" data-ref="n816"><a class="md-toc-inner" style="" href="#header-n816">模型评估</a></span><span class="md-toc-item md-toc-h1" data-ref="n829"><a class="md-toc-inner" style="" href="#header-n829">稳定性</a></span><span class="md-toc-item md-toc-h1" data-ref="n835"><a class="md-toc-inner" style="" href="#header-n835">推荐系统</a></span><span class="md-toc-item md-toc-h1" data-ref="n838"><a class="md-toc-inner" style="" href="#header-n838">变量相关性</a></span><span class="md-toc-item md-toc-h1" data-ref="n841"><a class="md-toc-inner" style="" href="#header-n841">SVM</a></span><span class="md-toc-item md-toc-h1" data-ref="n844"><a class="md-toc-inner" style="" href="#header-n844">可视化</a></span><span class="md-toc-item md-toc-h1" data-ref="n859"><a class="md-toc-inner" style="" href="#header-n859">机器学习</a></span><span class="md-toc-item md-toc-h1" data-ref="n864"><a class="md-toc-inner" style="" href="#header-n864">特征工程</a></span><span class="md-toc-item md-toc-h1" data-ref="n869"><a class="md-toc-inner" style="" href="#header-n869">数学</a></span><span class="md-toc-item md-toc-h1" data-ref="n879"><a class="md-toc-inner" style="" href="#header-n879">Coding</a></span><span class="md-toc-item md-toc-h1" data-ref="n899"><a class="md-toc-inner" style="" href="#header-n899">Python</a></span><span class="md-toc-item md-toc-h2" data-ref="n954"><a class="md-toc-inner" style="" href="#header-n954">PyTorch</a></span><span class="md-toc-item md-toc-h1" data-ref="n957"><a class="md-toc-inner" style="" href="#header-n957">Shell</a></span><span class="md-toc-item md-toc-h2" data-ref="n961"><a class="md-toc-inner" style="" href="#header-n961">Emacs</a></span><span class="md-toc-item md-toc-h2" data-ref="n962"><a class="md-toc-inner" style="" href="#header-n962">Vim</a></span><span class="md-toc-item md-toc-h2" data-ref="n964"><a class="md-toc-inner" style="" href="#header-n964">正则表达式</a></span><span class="md-toc-item md-toc-h1" data-ref="n966"><a class="md-toc-inner" style="" href="#header-n966">Jupyter</a></span><span class="md-toc-item md-toc-h1" data-ref="n981"><a class="md-toc-inner" style="" href="#header-n981">Time series analysis</a></span><span class="md-toc-item md-toc-h1" data-ref="n986"><a class="md-toc-inner" style="" href="#header-n986">Black Holes</a></span><span class="md-toc-item md-toc-h1" data-ref="n1021"><a class="md-toc-inner" style="" href="#header-n1021">强化学习</a></span><span class="md-toc-item md-toc-h1" data-ref="n1028"><a class="md-toc-inner" style="" href="#header-n1028">PhD thesis</a></span><span class="md-toc-item md-toc-h1" data-ref="n1031"><a class="md-toc-inner" style="" href="#header-n1031">Kaggle &amp; Competitions for DS</a></span><span class="md-toc-item md-toc-h1" data-ref="n1072"><a class="md-toc-inner" style="" href="#header-n1072">GWs news</a></span><span class="md-toc-item md-toc-h1" data-ref="n1099"><a class="md-toc-inner" style="" href="#header-n1099">Physics</a></span><span class="md-toc-item md-toc-h1" data-ref="n1106"><a class="md-toc-inner" style="" href="#header-n1106">信号处理</a></span><span class="md-toc-item md-toc-h1" data-ref="n1121"><a class="md-toc-inner" style="" href="#header-n1121">会议</a></span><span class="md-toc-item md-toc-h1" data-ref="n1135"><a class="md-toc-inner" style="" href="#header-n1135">写作</a></span><span class="md-toc-item md-toc-h1" data-ref="n1195"><a class="md-toc-inner" style="" href="#header-n1195">PhD</a></span><span class="md-toc-item md-toc-h1" data-ref="n1214"><a class="md-toc-inner" style="" href="#header-n1214">Papers</a></span><span class="md-toc-item md-toc-h1" data-ref="n1220"><a class="md-toc-inner" style="" href="#header-n1220">杂</a></span><span class="md-toc-item md-toc-h1" data-ref="n1256"><a class="md-toc-inner" style="" href="#header-n1256">并行计算 &amp; 计算天文</a></span></p></div><p><a href='https://medium.com/@alexrachnog/ultimate-following-list-to-keep-updated-in-artificial-intelligence-32776ffcd079'>跟踪AI最新技术动态的网站大列表 Ultimate following list to keep updated in artificial intelligence</a></p><p>&nbsp;</p><p>为啥要写技术博客？读读这个：<a href='https://medium.freecodecamp.org/every-developer-should-have-a-blog-heres-why-and-how-to-stick-with-it-5fd55a247fbf'>Every developer should have a blog. Here’s why, and how to stick with it.</a></p><p>深度学习该怎么入门？读读这个：</p><p><a href='https://medium.com/@julsimon/10-steps-on-the-road-to-deep-learning-part-1-f9e4b5c0a459'>10 steps on the road to Deep Learning (part 1)</a></p><p><a href='https://medium.com/@julsimon/10-steps-on-the-road-to-deep-learning-part-2-3ec757908c5e'>10 steps on the road to Deep Learning (part 2)</a></p><p>各种关于 MXNet 的入门和应用？</p><p><a href='https://medium.com/@julsimon/getting-started-with-deep-learning-and-apache-mxnet-34a978a854b4'>Getting started with Deep Learning and Apache MXNet</a></p><p>&nbsp;</p><h1><a name='header-n13' class='md-header-anchor '></a>值得关注更新的站点</h1><p>ArXiv：<a href='https://arxiv.org/list/cs.CV/recent'>cs.CV</a>，[ <a href='https://arxiv.org/list/gr-qc/new'>gr-qc</a>，<a href='https://arxiv.org/list/hep-th/new'>hep-th</a> ]</p><blockquote><p>ArXiv 预印本网站从90年代初开始就作为物理学预印论文所用，1999年改名为 arXiv.org，现发展至今，已经涵盖了物理学、数学、计算机科学与生物学等诸多领域，完整介绍请见：<a href='https://zh.wikipedia.org/wiki/ArXiv'>Wikipedia</a> or <a href='https://www.zhihu.com/question/31864895'>知乎</a>。</p><p>作为一个科研人员来说，ArXiv 是每天(周一到周五)早9点左右必刷的网站，了解科研前沿动态，开拓思路视野都极为有帮助。值得留意的缺点是，虽然每天新出炉的论文非常多，但是质量参差不齐，非常需要有一双发现亮点的眼睛。学会取其精华，去其糟粕是非常重要的。</p></blockquote><p><a href='http://www.gitxiv.com/'>GitXiv</a></p><blockquote><p>看名字就大概能猜到，这是个开源+合作的计算机科学项目站点。每个项目都有<strong>arXiv + Github + Links + Discussion</strong>。</p><p>该站点更新并不频繁，偶尔搜一搜，关注下自己感兴趣的开源项目就好。</p></blockquote><p><a href='https://paperswithcode.com'>Papers with Code</a></p><p><a href='http://www.paperweekly.site/home'>paper weekly</a></p><p><a href='http://www.arxiv-sanity.com/'>Arxiv Sanity Preserver</a></p><blockquote><p>介绍很简单：Built in spare time by<a href='https://twitter.com/karpathy'>@karpathy</a> to accelerate research. Serving last 44653 papers from cs.[CV|CL|LG|AI|NE]/stat.ML</p><p>大牛Karpathy你总该知道，李飞飞高徒！曾经他的博客上一篇 <a href='http://karpathy.github.io/neuralnets/'>Hacker&#39;s guide to Neural Networks</a> 对我影响就很大。</p><p>这个网站上几乎每天也会更新，个人最常关注的是“most recent”和“top recent”。尤其是“top recent”的文章，至少每篇的摘要是必读的，直接了解当代最最前沿的 DL 动态啊！</p></blockquote><p><a href='https://nurture.ai/'>NURTURE.AI</a></p><blockquote><p>这是一个类似Arxiv Sanity的站点，可以很好的筛选paper和看到大家对于一些 paper 的评分和评价。</p><p>此外，其所链接的 AI6 是一个很不错的非盈利免费 DL 教程！</p></blockquote><p><a href='https://medium.com'>Medium</a></p><blockquote><p>非常著名的写作分享平台。虽然层被“简书”抄袭，但是 Medium 上的文章和用户仍旧拥有高质量，高水平，高拥护度的特点。文章内容涉猎广泛且相当有深度，比“简书”等国内博客平台的各种软文鸡汤强大牛逼的太多。</p><p>你可能还会留意到国内大多的公众号技术博文，基本原文都是来自于 Medium 上的文章。</p><p>关注方式：可以考虑和我一样直接注册付费会员，长期关注一些频道和高水平作者的推送即可。也可以每天翻翻网站，随意浏览。（注：Medium 站点是只能翻墙才可以打开的）</p></blockquote><p><a href='https://weibo.com/fly51fly'>@爱可可-爱生活</a></p><blockquote><p>这个微博博主的介绍是： 北邮PRIS模式识别实验室陈老师。</p><p>每天的更新量很大，粉丝众多，分享的内容虽然会和上面提到过的内容有所重复，但是博主分享的都必然是经过筛选的精品之作。据小道消息，有些知名数据科学技术公众号的工作人员也会每天盯着这位博主的更新，以获取最新资讯哈~</p><p>而我会在 mac 微博客户端登陆，有任何更新推送都会立马提醒我哈~ </p></blockquote><p><a href='https://realpython.com' target='_blank' class='url'>https://realpython.com</a></p><blockquote><p>这是一个逼格很有意思的网站。其实我每次没那么多精力会去打开这个网站学习 Python 的技巧。不过我订阅了这个网站，所以几乎每天都会发一条主题为 [🐍PyTricks] 的邮件，里面会有一条很短但又典型的 Python 骚操作。每天一读，每天就都小有收获一点，还能博人一笑，哇哈哈哈。。。</p></blockquote><p><a href='http://www.depthfirstlearning.com'>Depth First Learning</a></p><blockquote><p>一个新的站点，可以期待未来会有很不错的文章发不出来。</p></blockquote><p>&nbsp;</p><p>搜一下下面这个网站上面的内容：</p><p><a href='https://www.tinymind.cn/sites' target='_blank' class='url'>https://www.tinymind.cn/sites</a></p><p><a href='https://www.bigdatanews.datasciencecentral.com' target='_blank' class='url'>https://www.bigdatanews.datasciencecentral.com</a></p><h1><a name='header-n53' class='md-header-anchor '></a>值得阅读的技术博客：</h1><p><a href='https://www.jianshu.com/u/130f76596b02'>SeanCheney</a></p><blockquote><p>大神啊！在简书上独立翻译了<a href='https://www.jianshu.com/p/04d180d90a3f'>《利用Python进行数据分析·第2版》</a> 等，也参与了<a href='https://github.com/apachecn/hands_on_Ml_with_Sklearn_and_TF'>《Scikit-Learn与TensorFlow机器学习实用指南》 </a> 翻译的开源项目，质量也非常高！</p></blockquote><p><a href='https://www.zhihu.com/people/wizardforcel/posts'>飞龙</a></p><blockquote><p>和上面一样的大神！也是 <a href='https://github.com/apachecn/hands_on_Ml_with_Sklearn_and_TF'>《Scikit-Learn与TensorFlow机器学习实用指南》</a> 开源项目的译者，此外也在独立的翻译《<a href='https://zhuanlan.zhihu.com/p/29691333'>数据结构思维</a>》，《<a href='https://zhuanlan.zhihu.com/p/36007117'>复杂性思维</a>》等数据。质量之高，值得长期关注！</p></blockquote><p><a href='https://sgugger.github.io/'>Sylvain Gugger</a></p><blockquote><p>This blog is a means for me to explain the concepts I learn as I delve further into machine learning, because I think that it&#39;s the best way to really master new topics.</p></blockquote><p><a href='https://www.jeremyjordan.me'>Jeremy&#39;s Blog</a></p><blockquote><p>Jeremy saids: I&#39;m super excited to share what I&#39;m learning here on this blog. 博客非常漂亮，而且内容非常原创！</p></blockquote><p><a href='https://jeremykun.com'>jeremykun</a></p><blockquote><p>最初因为这篇文章：<a href='https://jeremykun.com/2018/04/13/for-mathematicians-does-not-mean-equality/'>For mathematicians, = does not mean equality</a>，开始关注此博。</p></blockquote><p><a href='http://noahgolmant.com/'>Noah Golmant</a></p><blockquote><p>直觉告诉我这是一个妹子。博客还很新，文章还不多，不过内容可以感觉到人家是高手，应该好好学习！最近的两篇文章非常值得细读：<a href='http://noahgolmant.com/maml.html'>Meta-Learning and Optimization</a> and <a href='http://noahgolmant.com/sgd-noise.html'>Fine-tuned Noise</a></p></blockquote><p><a href='https://medium.com/@hiromi_suenaga?source=post_header_lockup'>Hiromi Suenaga</a></p><blockquote><p>这个妹子厉害了，在 Medium 上贴出了自己学习 fast.ai 课程Part1&amp;Part2的详细笔记。非常细致入微，值得仔细阅读！</p></blockquote><p><a href='https://medium.com/@SeoJaeDuk/latest'>Jae Duk Seo</a></p><blockquote><p>这个韩国哥们牛逼到爆了，在 Medium 和自己的<a href='https://jaedukseo.me'>博客</a>上撰文。写过Only Numpy 和 Paper Summary 等等系列，他的文章都非常值得学习和仔细研读！</p></blockquote><p><a href='http://tomaugspurger.github.io/'>datas-frame</a></p><blockquote><p>起初是因为 Modern Pandas 的系列文章开始关注这个博客。能感觉到这是一位大神，内容原创性也很强！</p></blockquote><p><a href='https://deeplearning4j.org/documentation'>DL4J</a></p><blockquote><p>本来这是一个 Deep Learning for JAVA 的库文档。但吸引人的是他的文档写的很深入浅出，内容讲解的很细致也很原创，很适合DL入门学习。</p></blockquote><p><a href='https://liam0205.me'>始终</a></p><blockquote><p>博客内的  ML 和 DL 部分文章虽然并不多，但是每篇确实实实在在的原创，值得留意和精读。</p></blockquote><p><a href='http://nooverfit.com/wp/'>David 9的博客</a></p><blockquote><p>偶然间留意到的博客，2016年就开始更新，内容已经非常丰富了，且都是原创。从基础普及贴到各种会议论文精选，值得好好读读。</p></blockquote><p><a href='https://jakevdp.github.io/'>Pythonic Perambulations</a></p><blockquote><p>一位天文学家，当初因为他写的一篇 FFT 文章开始关注此博客，全部是原创深度好文，已经出过三本畅销书籍。从文章中，可以感受到博主渊博的知识和对 Python 的狂热。</p></blockquote><p><a href='https://int8.io'>Int8</a></p><blockquote><p>这个博客作者不详，内容全原创，理论也很深刻。近期刚刚开始重新更新了。</p></blockquote><p><a href='https://cplberry.com'>Christopher Berry</a></p><blockquote><p>这是一位研究 GW 的博后的博客。是我学习和效仿的偶像和目标！</p></blockquote><p><a href='https://stevertaylor.github.io'>DR. STEPHEN TAYLOR</a></p><blockquote><p>一位专注于引力波理论研究的博士后。</p></blockquote><p><a href='https://sites.google.com/site/mostafasibrahim/'>Homepage of Mostafa S. Ibrahim</a></p><blockquote><p>特别帅的大胡子！专门搞 CV 的。博客内容丰富，干货超级干！超级原创！</p></blockquote><p><a href='https://blog.piekniewski.info/'>Piekniewski&#39;s blog</a></p><blockquote><p>因为一篇针对<a href='https://arxiv.org/abs/1807.03247'>CoordConv</a> 的《<a href='https://blog.piekniewski.info/2018/07/14/autopsy-dl-paper/'>Autopsy Of A Deep Learning Paper</a>》吐槽剖析文，决定要关注此人的博客。</p></blockquote><p><a href='https://twiecki.github.io/'>While My MCMC Gently Samples</a></p><blockquote><p>因为一篇文【信息先验层次贝叶斯神经网络】《Hierarchical Bayesian Neural Networks with Informative Priors》by Thomas Wiecki <a href='http://t.cn/RDnGosK' target='_blank' class='url'>http://t.cn/RDnGosK</a> 开始关注这位统计学大拿。</p></blockquote><p><a href='http://ruder.io/#open'>Sebastian Ruder</a></p><blockquote><p>这是大神！他写的<a href='http://ruder.io/semi-supervised/'>An overview of proxy-label approaches for semi-supervised learning</a> 这篇博文在网络上流传很广，而且还在持续更新，也可以在 arxiv 上找到。</p></blockquote><p><a href='https://livefreeordichotomize.com'>Live Free or Dichotomize</a></p><blockquote><p>这是两个人在维护的博客。博客非常漂亮和有创意，内容深刻还不失干货，因为一篇《<a href='https://livefreeordichotomize.com/2018/09/14/one-year-to-dissertate/'>One year to dissertate</a>》让我发现了它。</p></blockquote><p><a href='https://ai.googleblog.com'>Google AI Blog</a></p><p><a href='http://anotherdatum.com'>Another Datum</a></p><blockquote><p>因为这样一篇文章开始关注此博：【实例介绍：Gumbel Softmax与GANs】《Neural Networks gone wild! They can sample from discrete distributions now!》 <a href='http://t.cn/RgQZ0nw' target='_blank' class='url'>http://t.cn/RgQZ0nw</a> ref:《GANS for Sequences of Discrete Elements with the Gumbel-softmax Distribution》<a href='http://weibo.com/1402400261/EhKFi4hxn' target='_blank' class='url'>http://weibo.com/1402400261/EhKFi4hxn</a> </p></blockquote><p><a href='https://rajatvd.github.io/'>Rajat&#39;s Blog</a></p><blockquote><p>Goodfellow 转推了他的一篇文章《<a href='https://rajatvd.github.io/Exploring-Adversarial-Reprogramming/'>Exploring Adversarial Reprogramming</a>》开始关注此博。</p></blockquote><p>&nbsp;</p><p><a href='https://plmsmile.github.io' target='_blank' class='url'>https://plmsmile.github.io</a></p><p><a href='http://outlace.com/'>Δ ℚuantitative √ourney</a></p><p><a href='http://www.iangoodfellow.com'>Ian Goodfellow</a></p><p><a href='http://xyzzyx.xyz/category/machine-learning/neural-network-for-machine-learning-%E7%AC%94%E8%AE%B0/'>XYZ</a></p><p><a href='https://github.com/NirantK/awesome-project-ideas'>Awesome Deep Learning Project Ideas</a></p><p>【“自己动手开发XX教程”大列表】“Build your own x. A curated collection of project-based programming tutorials” by Daniel Stefanovic GitHub:  <a href='https://github.com/danistefanovic/build-your-own-x'>build-your-own-x</a></p><p><a href='https://mathematical-tours.github.io'>Mathematical Tours of Data Sciences</a> </p><blockquote><p><a href='https://mathematical-tours.github.io/algorithms/' target='_blank' class='url'>https://mathematical-tours.github.io/algorithms/</a></p></blockquote><h1><a name='header-n134' class='md-header-anchor '></a>值得关注更新的公众号</h1><p>&nbsp;</p><ul><li><strong>机器之心</strong>（<a href='https://www.jiqizhixin.com'>网站</a>，微信号：almosthuman2014）</li></ul><blockquote><p>这个公众号其实不用太多介绍，内容专业性也很强，在数据科学圈里享有盛誉，自我定位也很高，2018年1月完成 A 轮融资，看来以后是不愁钱了。基本上所有的文都是追求原创或者拿到授权自己翻译的。他们有一个自己的 <a href='https://github.com/jiqizhixin/ML-Tutorial-Experiment'>Github</a> 项目，内容很实在，从 CNN，GAN，CapNet 到 RNN 等，既有理论推导说明，也有完整代码解析，值得自己都扣一遍。</p></blockquote><p>&nbsp;</p><p>Informative Repo Github：</p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n145' class='md-header-anchor '></a>关乎研究和学习经验</h1><p>《<a href='http://www.fast.ai/2018/04/10/stanford-salon/'>A Discussion about Accessibility in AI at Stanford · fast.ai</a>》by Rachel Thomas ：</p><blockquote><p>Rachel Thomas给AI研究人员的建议：配合论文写博客、分享实现代码、用单GPU跑实验、论文里多用具体例子说话。</p></blockquote><p>《<a href='https://towardsdatascience.com/my-journey-from-physics-into-data-science-5d578d0f9aa6'>My Journey from Physics into Data Science </a>》 by <a href='https://towardsdatascience.com/@admond1994?source=post_header_lockup'>Admond Lee</a></p><blockquote><p>一位学物理的新加坡小哥，最后成功走向数据科学家的道路。文中介绍了他自己如何一步一步接触和自学数据科学，也谈到了学习过程中遇到的困难。最后，给出了不少中肯的建议且分享了优秀的资源。</p></blockquote><p>《<a href='https://github.com/ZuzooVn/machine-learning-for-software-engineers'>A complete daily plan for studying to become a machine learning engineer</a>》 by <a href='https://twitter.com/zuzoovn'>Nam Vu</a></p><blockquote><p>这个越南小哥牛逼了。用中文和英文写了一个“自上而下的学习路线: 软件工程师的机器学习”。范围之丰富，内容之详尽，质量之深刻，让我瞠目结舌啊。还在 Medium 上各种撰文，是我学习的榜样啊！</p></blockquote><p>《<a href='http://web.mit.edu/tslvr/www/lessons_two_years.html'>Lessons from My First Two Years of AI Research</a>》by Tom Silver（<a href='https://mp.weixin.qq.com/s/sFIvPYjkywKnakB-N3CNXA'>中译文</a>）</p><blockquote><p>这个文章写得内容非常详尽和诚恳，有着诸多的倾情贴心建议，关于如何起步，如何读 paper，如何做 AI 的研究等等。超满分推荐的文，适合任何方向领域的科研人员阅读！同时，在他的博客上还一直在更新所谓的 Favorite Papers，值得参考。</p></blockquote><p>《<a href='https://video.deakin.edu.au/media/t/0_mgtiu9wx'>PhD Completion for Supervisors with Professor Leslie Willcocks</a>》by Leslie P. Willcocks</p><blockquote><p>“三年博士生研究通关攻略” #bilibili#搬运：<a href='http://t.cn/RuE5LEg' target='_blank' class='url'>http://t.cn/RuE5LEg</a>  【<a href='http://www.deakin.edu.au/__data/assets/pdf_file/0009/806256/Completing-your-PhD-with-Professor-Leslie-Willcocks-2016.pdf'>Slice</a>】</p></blockquote><ul><li><a href='https://randomekek.github.io/deep/deeplearning.html'>Deep Learning Cheat Sheet for Beginners</a> <a href='https://www.datasciencecentral.com/profiles/blogs/deep-learning-for-beginners-1'>site</a> </li><li><a href='https://mp.weixin.qq.com/s/y-GEa5nB8LfKn3vc86i7JQ'>阅读深度学习论文的新姿势</a></li></ul><p>“研究计划指南”《Research Proposal: Little Quick Fix》by Zina O&#39;Leary <a href='http://t.cn/ReOtuoU' target='_blank' class='url'>http://t.cn/ReOtuoU</a> </p><p>【为什么离开学术圈并非意味着‘失败’】《Why it is not a ‘failure’ to leave academia》 <a href='http://t.cn/RDzu6BP' target='_blank' class='url'>http://t.cn/RDzu6BP</a> </p><p>【你和你的研究】《You and Your Research》by Richard Hamming <a href='http://t.cn/7VYLa' target='_blank' class='url'>http://t.cn/7VYLa</a> </p><p>【如何组织和(高效)阅读文献】《Organising and reading literature》 <a href='http://t.cn/RD5ewqb' target='_blank' class='url'>http://t.cn/RD5ewqb</a> </p><p>【如何自学复杂知识？认清不理解的部分-对自己的知识充满信心-提出问题-做针对性研究】《How to teach yourself hard things - Julia Evans》by Julia Evans <a href='http://t.cn/RFj35aB' target='_blank' class='url'>http://t.cn/RFj35aB</a> </p><p>【一图读懂：让你更聪明的十二种方法】《12 ways to get smarter – in one chart》by Jeff Desjardins <a href='http://t.cn/RsE1KzC' target='_blank' class='url'>http://t.cn/RsE1KzC</a> </p><p> <a href='https://medium.com/cracking-the-data-science-interview/how-to-think-like-a-data-scientist-in-12-steps-157ea8ad5da8'>How to Think Like a Data Scientist in 12 Steps</a></p><h1><a name='header-n173' class='md-header-anchor '></a>关于 Books</h1><p><a href='https://towardsdatascience.com/list-of-must-read-free-data-science-books-bfae4c5c5a16'>List of Must — Read Free Data Science Books</a></p><p><a href='https://towardsdatascience.com/list-of-free-must-read-machine-learning-books-89576749d2ff'>List of Free Must-Read Machine Learning Books</a></p><p>【80本最棒的数据科学书】《<a href='https://www.bigdatanews.datasciencecentral.com/profiles/blogs/80-best-data-science-books-that-are-worthy-reading'>80 Best Data Science Books That Are Worthy Reading | Big Data News</a>》</p><p><a href='http://www.cs.cornell.edu/jeh/book.pdf'>Foundations of Data Science</a> - by Avrim Blum, John Hopcroft, and Ravindran Kannan </p><p>《Interpretable Machine Learning》Read free eBook <a href='https://christophm.github.io/interpretable-ml-book/'>here</a>. </p><p><a href='https://machinelearningmastery.com/machine-learning-algorithms-from-scratch/'>Machine Learning Algorithms From Scratch</a></p><p>【各个主题的最佳教科书】《The Best Textbooks on Every Subject》 <a href='http://t.cn/ReqcJS7' target='_blank' class='url'>http://t.cn/ReqcJS7</a> </p><p>【Python建模与仿真(第二版)】《Modeling and Simulation in Python》by Allen B. Downey <a href='http://t.cn/RKAUayI' target='_blank' class='url'>http://t.cn/RKAUayI</a> pdf:<a href='http://t.cn/RKAUayt' target='_blank' class='url'>http://t.cn/RKAUayt</a> GitHub:<a href='http://t.cn/RkaESti' target='_blank' class='url'>http://t.cn/RkaESti</a> </p><p>&nbsp;</p><h1><a name='header-n183' class='md-header-anchor '></a>Scientific tips</h1><ul><li><p><a href='https://medium.com/@timferriss/scientific-speed-reading-how-to-read-300-faster-in-20-minutes-55f36e4c2cbd'>Scientific Speed Reading: How to Read 300% Faster in 20 Minutes</a></p></li><li><p>学术论文太多！不知道从何读起？有人总结好啦！看下文</p><ul><li><a href='https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap'>Deep Learning Papers Reading Roadmap</a></li><li><a href='https://github.com/terryum'>terryum</a>/<a href='https://github.com/terryum/awesome-deep-learning-papers'>awesome-deep-learning-papers</a>  The most cited deep learning papers</li><li><a href='https://www.techleer.com/articles/517-a-list-of-top-10-deep-learning-papers-the-2018-edition/'>A List Of Top 10 Deep Learning Papers, The 2018 Edition</a></li></ul></li><li><p>【怎样做(出色的)研究】《Doing (Good) Research》by Vladlen Koltun  <a href='http://t.cn/RrlHQ4S' target='_blank' class='url'>http://t.cn/RrlHQ4S</a> </p></li><li><p>【单兵作战还是团队合作？ 哈佛大学的研究表明：都不够好。最好的解决方案是“间歇式合作” - 小组工作适当穿插间隙，让成员独立思考和工作】《Collaborate on complex problems, but only intermittently | Harvard Gazette》 <a href='http://t.cn/RkijAoN' target='_blank' class='url'>http://t.cn/RkijAoN</a> </p></li></ul><p>【科研最差实践】“Bad Research Practices” via:Rebecca Willén </p><p><img src='https://i.loli.net/2018/09/16/5b9e761fbebbf.png' alt='' referrerPolicy='no-referrer' /></p><p>&nbsp;</p><h1><a name='header-n203' class='md-header-anchor '></a>概述性文章</h1><p>对于整个机器学习大方向的概述，可以先看一眼：<a href='https://mp.weixin.qq.com/s/nXi6lXNqbLbbpnDD3vDJBA'>机器学习-波澜壮阔40年</a>，文末也有丰富的参考文献。</p><p><a href='https://mp.weixin.qq.com/s/d3NqDETPhffzkm2sK1X2_w'>「凡是过往，皆为序章。」64岁的RODNEY BROOKS谈人工智能的起源与发展</a></p><p>关于中文的DL 概述，<a href='https://blog.csdn.net/zouxy09'>zouxy09</a>早在2013年就在 csdn 上发布了他自己的深度学习整理笔记，虽然年代距离现在有些早，但是内容很丰富，内容也很干，基本是去掉花书《Deep Learning》里数学基础部分的言简意赅版。<a href='https://blog.csdn.net/zouxy09/article/details/14222605'>这里</a><sup class='md-footnote'><a href='#dfref-footnote-1' name='ref-footnote-1'>1</a></sup>可以查看他所有的原创性博文，涉及：DL、CV、ML、Kinect、语音、图像处理等等。</p><p>英文版的概述性文章是相当多的，质量也普遍非常高的，比如：<a href='https://ujjwalkarn.me/author/ujwlkarn/'>ujjwalkarn</a>在 WordPress 上发布了关于 CNNs 的“发人深省”的一篇<a href='https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/'>博文</a>(<sup class='md-footnote'><a href='#dfref-footnote-2' name='ref-footnote-2'>2</a></sup>2016.4)，其中介绍了当时所有典型的卷积网络模型，也指明了各个模型的概念和特点，文采奕奕，通俗易懂，参考文献也很丰富，在2017.6授权了<a href='http://www.hackcv.com/index.php/archives/104/?hmsr=toutiao.io&utm_medium=toutiao.io&utm_source=toutiao.io'>中文翻译版</a><sup class='md-footnote'><a href='#dfref-footnote-2-1' name='ref-footnote-2-1'>2</a></sup></p><p>&nbsp;</p><p>另外，尤其值得关注的是著名博客网站 Medium 上的文章。比如说：</p><ul><li><p><a href='https://artificial-understanding.com/why-deep-learning-works-1b0184686af6'>Why Deep Learning Works</a> (中译文: <a href='https://mp.weixin.qq.com/s/fIAU4zzZ3t6KPeupntCWTw'>自底向上看深度学习网络的工作原理</a>) </p><blockquote><p>此文强调了在 CNNs 中，缩减(<strong>Reduction</strong>)信息和全局(<strong>Holistic</strong>)抽象的能力起到了至关重要的作用。</p></blockquote></li><li><p>还有著名的机器学习综合站点 Machine Learning Mastery 的文章也都非常 informative： <a href='https://machinelearningmastery.com/what-is-deep-learning/'>What is Deep Learning?</a></p></li></ul><p>&nbsp;</p><p>学术角度的综述文章有很多，但我毫无疑问的要首推 LeCun、Bengio、Hinton 这三大巨头在 2015 年 Nature 上合作的 《<a href='https://www.nature.com/articles/nature14539'>Deep Learning</a>》(<a href='https://mp.weixin.qq.com/s/sEwC19dBlRO4i-kIgSZldw'>中译精华版</a>)。文章非常详尽说明了深度学习推动和发展的来龙去脉，以及各关键神经网络模型的深刻理解与意义的阐述让人印象深刻，另尤其让我感到新鲜的是，原来催化深度学习复兴的是非监督学习啊：</p><blockquote><p>2006年左右，加拿大高等研究院（CIFAR）的研究员让公众重新对深度反向传播网络产生了兴趣。研究员们发明了不需要标签数据就能进行特征发现的<strong>无监督学习</strong>程序。</p></blockquote><p>然而，现在谁都知晓，深度学习目前仍是在监督学习中大放异彩，大展身手中。于是，三巨头都希望非监督学习的重要性能在未来变得更高。</p><p>&nbsp;</p><p><a href='http://www.cnblogs.com/tsiangleo/p/5450466.html'>最容易读进去的深度学习科普贴</a></p><p>Representation learning is about finding a mapping from input patterns to encodings that disentangle the underlying variational factors of the input set. [<a href='https://arxiv.org/pdf/1804.07209v1.pdf'>cite</a>]</p><p>《Recent Advances in Deep Learning: An Overview》M R Minar, J Naher [Chittagong University of Engineering and Technology] (2018) <a href='http://t.cn/RehFEsE' target='_blank' class='url'>http://t.cn/RehFEsE</a> </p><p>《Deep Learning》N G. Polson, V O. Sokolov [University of Chicago &amp; George Mason University.] (2018) <a href='http://t.cn/Re7vbdR' target='_blank' class='url'>http://t.cn/Re7vbdR</a></p><p><a href='https://towardsdatascience.com/a-weird-introduction-to-deep-learning-7828803693b0'>A “weird” introduction to Deep Learning</a></p><p><a href='https://www.cnblogs.com/payton/articles/6008571.html'>Yoshua Bengio等大神传授：26条深度学习经验</a></p><p>【学术工具集：高效设计、撰写和发表更好的研究……】“AcademicToolkit - Design, write, and publish better research...” <a href='http://t.cn/EvapAMn' target='_blank' class='url'>http://t.cn/EvapAMn</a> </p><p><a href='https://mp.weixin.qq.com/s/TTGivq_j-1zvvlCqcd_Zhw'>DeepMind-深度学习: AI革命及其前沿进展 (54页ppt报告）</a></p><p>&nbsp;</p><h1><a name='header-n231' class='md-header-anchor '></a>Mathematics of DL</h1><ul><li>【神经网络数学入门指南】《<a href='http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.161.3556&rep=rep1&type=pdf'>A Beginner&#39;s Guide to the Mathematics of Neural Networks</a>》A.C.C. Coolen [King&#39;s College London] (1998) </li></ul><p>&nbsp;</p><h1><a name='header-n237' class='md-header-anchor '></a>Power and Limits of Deep Learning</h1><p><a href='https://www.topbots.com/understanding-limits-deep-learning-artificial-intelligence/'>Understanding The Limits of Deep Learning</a></p><p><a href='https://www.youtube.com/watch?v=0tEhw5t6rhc'>Yann LeCun - Power &amp; Limits of Deep Learning</a>（Recorded Nov 1st, 2017）</p><p><a href='https://medium.com/@mijordan3/artificial-intelligence-the-revolution-hasnt-happened-yet-5e1d5812e1e7'>Michael Jordan：Artificial Intelligence — The Revolution Hasn’t Happened Yet</a> （<a href='https://mp.weixin.qq.com/s/Le3LnAELgw1ZiqcIPPUWXw'>中译文1</a>，<a href='https://mp.weixin.qq.com/s/1crA7PK_nssu3nRxPQF6vg'>中译文2</a>）</p><p><a href='https://www.gelonghui.com/p/133246'>谷歌Keras之父连发两文解析深度学习的局限性与未来</a> (来自：<a href='https://blog.keras.io/the-limitations-of-deep-learning.html'>The limitations of deep learning</a>；<a href='https://blog.keras.io/the-future-of-deep-learning.html'>The future of deep learning</a>)</p><blockquote><p>文中谈到的“从几何角度”，“局部泛化与极端泛化”等内容是让我印象很深刻的。</p></blockquote><p><a href='https://petterhol.me/2018/05/07/less-is-more/'>Less is more</a></p><p>【AI偏见面面观】《Unmasking A.I.&#39;s Bias Problem | Fortune》 <a href='http://t.cn/RrS8NJM' target='_blank' class='url'>http://t.cn/RrS8NJM</a> </p><p>【数据科学的法则和秩序——科学始于问题，数据科学始于数据。数据科学如此艰难的原因，在于它始于错误的起点】《The Law and Order of Data Science》by Roger Peng <a href='http://t.cn/RkpNwZl' target='_blank' class='url'>http://t.cn/RkpNwZl</a> </p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n250' class='md-header-anchor '></a>经典的公开课程 &amp; 入门教学</h1><ul><li><p>最经典也是认可度最高的 coursera 上深度学习的视频教程：</p><p><a href='https://www.coursera.org/learn/neural-networks' target='_blank' class='url'>https://www.coursera.org/learn/neural-networks</a></p></li><li><p>CS231N 中用于视觉研究的卷积神经网络课程：</p><p><a href='http://cs231n.stanford.edu/' target='_blank' class='url'>http://cs231n.stanford.edu/</a></p></li><li><p>牛津大学深度学习视频教程：</p><p><a href='https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/' target='_blank' class='url'>https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/</a></p></li><li><p>Nando de Freitas 教授深度学习课程的视频地址：</p><p><a href='https://www.youtube.com/playlist?list=PLE6Wd9FR--EfW8dtjAuPoTuPcqmOV53Fu&app=desktop' target='_blank' class='url'>https://www.youtube.com/playlist?list=PLE6Wd9FR--EfW8dtjAuPoTuPcqmOV53Fu&app=desktop</a></p></li><li><p>台湾国立大学李宏毅教授开设的深度学习视频：</p><p><a href='https://www.bilibili.com/video/av15889450/' target='_blank' class='url'>https://www.bilibili.com/video/av15889450/</a></p></li><li><p>吴恩达教授在网易公开课上的深度学习视频教程：</p><p><a href='https://mooc.study.163.com/smartSpec/detail/1001319001.htm' target='_blank' class='url'>https://mooc.study.163.com/smartSpec/detail/1001319001.htm</a></p></li><li><p>两个不错的 Tensorflow 中文视频资源：</p><p><a href='https://www.youtube.com/watch?v=eAtGqz8ytOI&list=PLjSwXXbVlK6IHzhLOMpwHHLjYmINRstrk' target='_blank' class='url'>https://www.youtube.com/watch?v=eAtGqz8ytOI&list=PLjSwXXbVlK6IHzhLOMpwHHLjYmINRstrk</a>，</p><p><a href='https://www.youtube.com/watch?v=TrWqRMJZU8A&list=PLwY2GJhAPWRcZxxVFpNhhfivuW0kX15yG&index=2' target='_blank' class='url'>https://www.youtube.com/watch?v=TrWqRMJZU8A&list=PLwY2GJhAPWRcZxxVFpNhhfivuW0kX15yG&index=2</a></p></li><li><p>国内人工智能教育平台七月在线的深度学习视频公开课，可作为小白学习的最佳入门课程：</p><p><a href='http://www.julyedu.com/video/play/42' target='_blank' class='url'>http://www.julyedu.com/video/play/42</a></p></li></ul><p>&nbsp;</p><p>【MIT课程：欠驱动机器人(2018)】《<a href='http://underactuated.csail.mit.edu/underactuated.html'>6.832 Underactuated Robotics</a>》by Russ </p><p>&nbsp;</p><ul><li><p><a href='https://www.youtube.com/watch?v=mkfU9zVNGkQ&list=PL465CF583900B36A3'>Lecture Series on Chaos, Fractals and Dynamical Systems</a> by Prof.S.Banerjee,Department of Electrical Engineering</p><blockquote><p>HInton 发了视频的 Twitter 才开始到的。有质量很高的英文字幕，从评论来看，老师讲得超级好！有无数种办法来解释深刻的内涵。</p></blockquote></li></ul><p>&nbsp;</p><p><a href='https://medium.com/open-machine-learning-course'>Open Machine Learning Course</a> by OpenDataScience</p><blockquote><p>A series of articles on basics of Machine Learning. Each article is followed by an assignment with a deadline. Several Kaggle Inclass competitions are held throughout the course.</p></blockquote><p><a href='https://mp.weixin.qq.com/s/qpqqeSaRwQyBJlo3P25q6g'>如何从零开始构建深度学习项目？</a>这里有一份详细的教程：</p><ul><li><a href='https://medium.com/@jonathan_hui/how-to-start-a-deep-learning-project-d9e1db90fa72'>How to start a Deep Learning project?</a></li><li><a href='https://medium.com/@jonathan_hui/build-a-deep-learning-dataset-part-2-a6837ffa2d9e'>Build a Deep Learning dataset (Part 2)</a></li><li><a href='https://medium.com/@jonathan_hui/deep-learning-designs-part-3-e0b15ef09ccc'>Deep Learning designs (Part 3)</a></li><li><a href='https://medium.com/@jonathan_hui/visualize-deep-network-models-and-metrics-part-4-9500fe06e3d0'>Visualize Deep Network models and metrics (Part 4)</a></li><li><a href='https://medium.com/@jonathan_hui/debug-a-deep-learning-network-part-5-1123c20f960d'>Debug a Deep Learning Network (Part 5)</a></li><li><a href='https://medium.com/@jonathan_hui/improve-deep-learning-models-performance-network-tuning-part-6-29bf90df6d2d'>Improve Deep Learning Models performance &amp; deep network tuning (Part 6)</a></li></ul><p>&nbsp;</p><p>【“无需博士学位”系列Tensorflow教程视频、讲义、代码汇总】“Sample code for &quot;Tensorflow without a PhD&quot; series.” GitHub: <a href='https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd' target='_blank' class='url'>https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd</a></p><p>【UC Berkeley课程：凸优化与逼近】“EE 227C (Spring 2018) Convex Optimization and Approximation” by Moritz Hardt <a href='http://t.cn/R8ntHVH' target='_blank' class='url'>http://t.cn/R8ntHVH</a> </p><p>【数据科学入门资源集】’Galvanize Data Science Primer - A set of self paced resources for anyone looking to get into data science. The materials assume an absolute beginner and are intended to prepare students for the Galvanize Data Science interview process: <a href='http://t.cn/Rk16QYH' target='_blank' class='url'>http://t.cn/Rk16QYH</a> by Zipfian Academy GitHub: <a href='http://t.cn/Rk16QYm' target='_blank' class='url'>http://t.cn/Rk16QYm</a></p><p>【神经网络入门：正向传播与反向传播】《Coding Neural Network — Forward Propagation and Backpropagtion》by Imad Dabbura <a href='http://t.cn/Rk10VTt' target='_blank' class='url'>http://t.cn/Rk10VTt</a> pdf:<a href='http://t.cn/Rk10VTf' target='_blank' class='url'>http://t.cn/Rk10VTf</a> </p><p><a href='https://medium.com/machine-learning-for-humans/why-machine-learning-matters-6164faf1df12'>Machine Learning for Humans🤖👶</a></p><p>【概率思维——基础、技巧与算法(MLSS 2018)】《Planting the Seeds of Probabilistic Thinking: Foundations | Tricks | Algorithms》 by Shakir Mohamed [DeepMind] <a href='http://t.cn/RFAOCeJ' target='_blank' class='url'>http://t.cn/RFAOCeJ</a> pdf:<a href='http://t.cn/RFAOCe6' target='_blank' class='url'>http://t.cn/RFAOCe6</a> </p><p>【神经网络数学入门指南】《A Beginner&#39;s Guide to the Mathematics of Neural Networks》A.C.C. Coolen [King&#39;s College London] (1998) <a href='http://t.cn/RJrXVRS' target='_blank' class='url'>http://t.cn/RJrXVRS</a> pdf:<a href='http://t.cn/RuYKLGH' target='_blank' class='url'>http://t.cn/RuYKLGH</a> </p><p>《DeepBayes 2018 - YouTube》 <a href='http://t.cn/RFb9kso' target='_blank' class='url'>http://t.cn/RFb9kso</a> GitHub:<a href='http://t.cn/RFCwBPr' target='_blank' class='url'>http://t.cn/RFCwBPr</a></p><p>【面向教学：纯Python实现的最小化TensorFlow】’TensorSlow - Re-implementation of TensorFlow in pure python, with an emphasis on code understandability&#39; by Daniel GitHub: <a href='http://t.cn/RnvXeCj' target='_blank' class='url'>http://t.cn/RnvXeCj</a> </p><p>【面向科学家和工程师的微分方程第一课】《Differential Equations Notes | A First Course in Differential Equations for Scientists and Engineers》by R. L. Herman <a href='http://t.cn/RsiT9AS' target='_blank' class='url'>http://t.cn/RsiT9AS</a> </p><p>【(哥伦比亚新闻学院Lede项目)算法课程材料】“Algorithms(Lede 2018) - Algorithms course materials for the Lede program at Columbia Journalism School” GitHub:<a href='http://t.cn/RskMLnB' target='_blank' class='url'>http://t.cn/RskMLnB</a> </p><p>“算法相关知识储备 - 来源 leetCode 和 其他算法书” by Cyrbuzz GitHub:<a href='http://t.cn/EPPeUeX' target='_blank' class='url'>http://t.cn/EPPeUeX</a> </p><p>&nbsp;</p><h1><a name='header-n318' class='md-header-anchor '></a>迁移学习</h1><p>关于迁移学习的理论研究（i.e. Transfer Learning and Domain Adaptation），中科院计算所的<a href='https://www.zhihu.com/people/jindongwang'>王晋东</a>整理了一份相当牛逼的资料（<a href='https://github.com/jindongwang/transferlearning'>Repo</a>，<a href='http://transferlearning.xyz'>Website</a>），按照他的描述，其中包括：介绍、综述文章、最新文章、代表工作及其代码、常用数据集、硕博士论文等等。</p><p>王兄整理的实在太好，更新速度也快，下面我只列出和我的研究极为相关的 paper：</p><p><a href='https://github.com/artix41/awesome-transfer-learning'>Awesome Transfer Learning</a></p><blockquote><p>Best transfer learning and domain adaptation resources (papers, tutorials, datasets, etc.)</p></blockquote><p>《Top100论文导读：深入理解卷积神经网络CNN》via:<a href='https://weibo.com/n/%E9%98%BF%E9%87%8C%E4%BA%91%E4%BA%91%E6%A0%96%E7%A4%BE%E5%8C%BA?from=feed&loc=at'>@阿里云云栖社区</a> Part1:<a href='http://t.cn/RavG0Md'><em>O</em>网页链接</a> Part2:<a href='http://t.cn/RavG0MB'><em>O</em>网页链接</a>  //<a href='https://weibo.com/n/%E7%88%B1%E5%8F%AF%E5%8F%AF-%E7%88%B1%E7%94%9F%E6%B4%BB?from=feed&loc=at'>@爱可可-爱生活</a>: Part2: <a href='http://t.cn/R6UjRAS'><em>O</em>网页链接</a>  pdf: <a href='http://t.cn/R6UjRAo'><em>O</em>网页链接</a>  </p><p><a href='https://blog.csdn.net/u014722627/article/details/64919741#understanding-generalization-transfer'>给研一同学们的深度学习学习规划</a></p><p><a href='https://mp.weixin.qq.com/s?timestamp=1525579193&src=3&ver=1&signature=sDYXTrwkofn4tT1Dl0Ks3ByMVjNnglGENoV6GDCjkul*GJp4nu8mkVhapcZoswPKKsVfLrgkimmn*-MDYsRKbR7iJAa7ogomS2xt9nOg2csIFHSmHf20jULv3IVKid2vlcMUXE24ksYinyKHHjkUkxnJXvp-doVFVOpOvwcUbJI='>NanoNets：数据有限如何应用深度学习？</a></p><p><a href='https://www.datacamp.com/community/tutorials/transfer-learning'>Transfer Learning: Leverage Insights from Big Data</a></p><p>Top 100论文导读（一）：纯干货！深度神经网络中的理解，泛化以及迁移学习</p><p>《Towards more Reliable Transfer Learning》Z Wang, J Carbonell [CMU] (2018) <a href='http://t.cn/Rdjg1v9' target='_blank' class='url'>http://t.cn/Rdjg1v9</a> </p><p>《A Survey on Deep Transfer Learning》C Tan, F Sun, T Kong, W Zhang, C Yang, C Liu [Tsinghua University] (2018) <a href='http://t.cn/RDSheco' target='_blank' class='url'>http://t.cn/RDSheco</a> </p><p><a href='https://nurture.us17.list-manage.com/track/click?u=64a0423ba27e56e68c24b4cc8&id=55a54af2d6&e=b1bf4f7a42'>Improving Transferability of Deep Neural Networks</a> This paper looks into the initial parameters that yield the best results during transfer learning.</p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n334' class='md-header-anchor '></a>t-sne</h1><p><a href='https://www.rsipvision.com/ComputerVisionNews-2016November/62/' target='_blank' class='url'>https://www.rsipvision.com/ComputerVisionNews-2016November/62/</a></p><p><a href='https://distill.pub/2016/misread-tsne/'>How to Use t-SNE Effectively</a></p><p>Linear tSNE Optimization for the Web arXiv:1805.10817v1 </p><p><a href='https://www.datasciencecentral.com/profiles/blogs/t-sne-algo-in-r-and-python-made-with-same-dataset'>t-SNE algo in R and Python, made with same dataset</a></p><p>《t-SNE-CUDA: GPU-Accelerated t-SNE and its Applications to Modern Data》D M. Chan, R Rao, F Huang, J F. Canny [UC Berkeley] (2018) <a href='http://t.cn/RenWCIO' target='_blank' class='url'>http://t.cn/RenWCIO</a> view:<a href='http://t.cn/RenWCI9' target='_blank' class='url'>http://t.cn/RenWCI9</a> GitHub:<a href='http://t.cn/RenWCIW' target='_blank' class='url'>http://t.cn/RenWCIW</a> </p><p>【tSNE的高速并行实现(Python)】“fastTSNE - Fast, parallel implementations of tSNE” by Pavlin Poličar GitHub:<a href='http://t.cn/EvyZvDT' target='_blank' class='url'>http://t.cn/EvyZvDT</a> </p><p>&nbsp;</p><h1><a name='header-n342' class='md-header-anchor '></a>DNN</h1><p><a href='https://mp.weixin.qq.com/s/M1TswiDh-LkH9G7jCQ_UqA'>神经网络编程 - 前向传播和后向传播（附完整代码）</a></p><p>【神经过程(Neural Processes)及其PyTorch实现】《Neural Processes in PyTorch》<a href='http://t.cn/EvpxyNu' target='_blank' class='url'>http://t.cn/EvpxyNu</a> </p><p>&nbsp;</p><h1><a name='header-n346' class='md-header-anchor '></a>卷积神经网络</h1><ul><li>CNN 与 RNN 的联系和差异（<a href='https://mp.weixin.qq.com/s/55lG1nLGdd4w_KfZrH3-Ig'>专访 | 腾讯AI Lab西雅图实验室负责人俞栋：语音识别领域的现状与进展</a>）</li></ul><blockquote><p>如果卷积的层数足够多的话，理论上，CNN是可以和RNN (在<em>处理时序数据</em>)具有同等的能力的。</p><p> 在信号处理学科中，有两种滤波器，分别叫做 IIR 和 FIR（Infinite Impulse Response Filter vs. Finite Impulse Response Filter），它们和两种神经网络相对应。IIR 就相当于 RNN 模型，FIR 就相当于 CNN 模型，在卷积了足够多层之后，它就能利用足够远的信息（类似 RNN）。就好像在很多场景下，FIR 滤波器是可以近似 IIR 滤波器的。</p><p>因此，都可以被看作是先验的 CNN 和 RNN 是「可选的」，选择时就要考虑其他因素：例如 RNN 相对于 CNN（或者是 IIR 相对于 FIR）训练难度就要更大一些。但同时 RNN 更容易对变化很大的序列建模，比如依赖关系忽大忽小的情景，可能更适用 LSTM 这样的模型来实现。</p></blockquote><p><a href='https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650746674&idx=2&sn=b365adc25905064891266f978d4aadf0&chksm=871aeb4cb06d625a39bb1af319430d549b002de1b8402c86471088579546d066ec5145cceb09#rd'>前沿 | CNN取代RNN？当序列建模不再需要循环网络</a></p><p><a href='https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650740767&idx=1&sn=e66508400834c854478aa4fc2cb5d727&chksm=871adc61b06d5577f16aa8dd7adf6b6a7462e7fc1e7cb03a2bd9197e94b7566eb2cf8cdb82d0&scene=21#wechat_redirect'>机器之心GitHub项目：从循环到卷积，探索序列建模的奥秘</a></p><p><a href='https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650742155&idx=1&sn=137825a13a4c31fffb6b2347c0304366&chksm=871ad9f5b06d50e31e2857a08a4a9ae9f57fd0191be580952d80f1518779594670cccc903fbe&scene=21#wechat_redirect'>基于注意力机制，机器之心带你理解与训练神经机器翻译系统</a></p><p>【(视觉)注意力机制】《Attention Mechanisms》by Adam R. Kosiorek <a href='http://t.cn/EPxfBbi' target='_blank' class='url'>http://t.cn/EPxfBbi</a> </p><p>&nbsp;</p><h2><a name='header-n358' class='md-header-anchor '></a>综述性文章</h2><ul><li><a href='https://mp.weixin.qq.com/s/n8LVUV-fkMuJ3LUc7zUMzg'>卷积神经网络为什么能称霸计算机视觉领域？</a> by SigAI</li></ul><ul><li><p>What Do We Understand About Convolutional Networks?  （ArXiv：1803.08834）<a href='https://mp.weixin.qq.com/s/zvPNuP_LT7pWIgoxzfeUWw'>中文简译版</a> <a href='https://mp.weixin.qq.com/s/R4I2iv22KRUEHVFwbVCYOw'>2</a></p><blockquote><p>对卷积网络的技术基础、组成模块、当前现状和研究前景进行了梳理，介绍了我们当前对 CNN 的理解。</p></blockquote></li><li><p>《How convolutional neural network see the world - A survey of convolutional neural network visualization methods》</p></li><li><p><a href='https://mp.weixin.qq.com/s/N3h0z9n3L4StvLW9Pwkaaw'>卷积神经网络的最佳解释！</a>《The best explanation of Convolutional Neural Networks on the Internet!》</p></li><li><p><a href='https://neurdiness.wordpress.com/2018/05/17/deep-convolutional-neural-networks-as-models-of-the-visual-system-qa/'>Deep Convolutional Neural Networks as Models of the Visual System: Q&amp;A</a> （<a href='https://mp.weixin.qq.com/s/2UeF1_oSJlsUSaSaQzxvmw'>专知</a>）</p></li><li><p><a href='https://www.jeremyjordan.me/convolutional-neural-networks/'>Convolutional neural networks.</a></p></li><li><p><a href='https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1'>Intuitively Understanding Convolutions for Deep Learning</a></p></li><li><p>【深度 | 卷积神经网络十五问：CNN与生物视觉系统的研究探索】近日，哥伦比亚大学神经生物学与行为学博士 Grace Lindsay 在其博客上发文，通过问答的形式讨论了 CNN 和生物视觉系统之间的区别和联系。机器之心进行了编译介绍。<a href='http://t.cn/RBG4RSY' target='_blank' class='url'>http://t.cn/RBG4RSY</a> </p></li><li><p><a href='https://sites.google.com/site/mostafasibrahim/research/articles/how-to-start'>Getting Started in Computer Vision Research</a></p></li><li><p><a href='http://rsta.royalsocietypublishing.org/content/374/2065/20150203'>Understanding deep convolutional networks</a></p></li><li><p><a href='https://arxiv.org/pdf/1707.09725.pdf'>my masters thesis,</a></p></li><li><p><a href='http://deeplearning.net/tutorial/lenet.html'>Convolutional Neural Networks (LeNet)</a></p></li><li><p>【计算机视觉任务综述】《Different Tasks in Computer Vision》by Luozm <a href='http://t.cn/Rk1f3Mk' target='_blank' class='url'>http://t.cn/Rk1f3Mk</a> </p></li><li><p>【可视化理解复杂神经网络】《Simple diagrams of convoluted neural networks》by Piotr Migdał <a href='http://t.cn/EvNmKev' target='_blank' class='url'>http://t.cn/EvNmKev</a> </p></li><li><p><a href='https://mp.weixin.qq.com/s/ggjPDSyY0khxDAzZxn_fcQ'>卷积神经网络（CNN） 详解及资料整理</a></p></li><li><p>【(Python/Keras)CNN实战入门指南】《Convolutional Neural Networks for Beginners: Practical Guide with Python and Keras》by Jordi TORRES.AI <a href='http://t.cn/EPxq1UE' target='_blank' class='url'>http://t.cn/EPxq1UE</a> </p></li></ul><h2><a name='header-n392' class='md-header-anchor '></a>基准模型</h2><p>Justin Johnson from Stanford provides some great <a href='https://github.com/jcjohnson/cnn-benchmarks'>benchmarks</a>for a few of these CNNs.</p><h2><a name='header-n394' class='md-header-anchor '></a>架构设计</h2><p>Recent advances in the general design of CNNs have presented some awesome alternatives that can speed up CNN run time and reduce memory consumption without too much loss in accuracy. All of these can be integrated into any of the above CNN network types quite easily:</p><ul><li><a href='https://arxiv.org/pdf/1801.04381.pdf'>MobileNets</a> uses a technique called depth-wise separable convolutions to vastly reduce the number of computations and memory consumption, while only sacrificing 1% to 5% accuracy, depending on how much computational savings you want.</li><li><a href='https://arxiv.org/pdf/1603.05279.pdf'>XNOR-Net</a> uses binary convolutions i.e only two possible values for a convolution: zero or one. With this design, the network has a high degree of sparsity and can thus be easily compressed and not take up too much memory.</li><li><a href='https://arxiv.org/pdf/1707.01083.pdf'>ShuffleNet</a> uses pointwise group convolution and channel shuffle to greatly reduce computation cost while maintaining accuracy even better than MobileNets. In fact, they can achieve the accuracy of earlier state-of-the-art classification CNNs while being over 10 times faster.</li><li><a href='https://arxiv.org/pdf/1605.06431.pdf'>Network Pruning</a> is the technique of removing parts of the CNN in order to reduce run time and memory consumption, hopefully without reducing accuracy. In order to maintain accuracy, the parts that are removed should have little effect on the final result. The linked paper shows how easy this is to do with ResNets.</li></ul><p><a href='https://mp.weixin.qq.com/s/xTSLpFrBdKBgazCfjuLiwA'>CVPR 2018 | Spotlight论文：解耦神经网络DCNet，性能优于标准CNN</a></p><p>《Perturbative Neural Networks》F Juefei-Xu, V N Boddeti, M Savvides [CMU &amp; Michigan State University] (2018) <a href='http://t.cn/RBbhqGR' target='_blank' class='url'>http://t.cn/RBbhqGR</a> Home:<a href='http://t.cn/RBLQA88' target='_blank' class='url'>http://t.cn/RBLQA88</a> GitHub(PyTorch):<a href='http://t.cn/RBLQA8H' target='_blank' class='url'>http://t.cn/RBLQA8H</a></p><p>《Implicit Bias of Gradient Descent on Linear Convolutional Networks》S Gunasekar, J Lee, D Soudry, N Srebro [TTI Chicago &amp; USC Los Angeles] (2018) <a href='http://t.cn/RBbhn7k' target='_blank' class='url'>http://t.cn/RBbhn7k</a></p><p>《Deep Neural Networks with Multi-Branch Architectures Are Less Non-Convex》H Zhang, J Shao, R Salakhutdinov [CMU] (2018) <a href='http://t.cn/RBbzGtl' target='_blank' class='url'>http://t.cn/RBbzGtl</a></p><p>【学界 | DeepMind等机构提出「图网络」：面向关系推理】近日，由 DeepMind、谷歌大脑、MIT 和爱丁堡大学等公司和机构的 27 位科学家共同提交的论文引起了人们的关注。该研究提出了一个基于关系归纳偏置的 AI 概念：图网络。<a href='http://t.cn/RBSsGV4' target='_blank' class='url'>http://t.cn/RBSsGV4</a> </p><p>《Smallify: Learning Network Size while Training》G Leclerc, M Vartak, R C Fernandez, T Kraska, S Madden [MIT] (2018) <a href='http://t.cn/RBKpFtI' target='_blank' class='url'>http://t.cn/RBKpFtI</a> </p><p>【不使用残差连接，ICML新研究靠初始化训练上万层标准CNN】研究者通过信号传播的平均场等理论导出该初始化机制，并表明在关键线上初始化的网络信号能高效传播，因此即使不使用残差连接或密集型连接等方式，超深卷积网络也能有效地训练。<a href='http://t.cn/RBeye5s' target='_blank' class='url'>http://t.cn/RBeye5s</a> </p><p>Deep convolutional neural networks are great models of the visual system, but these static systems don&#39;t explain the temporal dynamics of real visual responses. So we built deep recurrent networks:  Paper: <a href='https://t.co/QpheOUU7Dl'>https://arxiv.org/abs/1807.00053 </a>   任务驱动的视觉系统卷积递归模型</p><p>这也是一篇把 CNN+RNN 结合的工作：<a href='https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650744717&idx=3&sn=fbca44e34eb75a480715b9587b634cde'>入门 | CNN也能用于NLP任务，一文简述文本分类任务的7个模型</a></p><p>【IJCAI 2018 | 让CNN跑得更快，腾讯优图提出全局和动态过滤器剪枝】网络剪枝是一种加速 CNN 的常用方法。厦门大学和腾讯优图的一项研究提出了一种全新的全局和动态过滤器剪枝方法，能够实现更好的剪枝效果且具有更好的适应性。<a href='http://t.cn/RduJkvh' target='_blank' class='url'>http://t.cn/RduJkvh</a> </p><p>卷积网络的问题及其解决方案CoordConv——CoordConv解决了坐标变换问题，具有更好的泛化速度，速度提高了150倍，参数比卷积少10-100倍《An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution》by Rosanne Liu, Joel Lehman, Piero Molino, Felipe Petroski Such, Eric Frank, Alex Sergeev and Jason Yosinski <a href='http://t.cn/RdBrBmB' target='_blank' class='url'>http://t.cn/RdBrBmB</a> 【改进版卷积CoordConv介绍视频】《An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution - YouTube》  <a href='http://t.cn/RdghW5c' target='_blank' class='url'>http://t.cn/RdghW5c</a> <a href='https://arxiv.org/pdf/1807.03247.pdf'>arxiv</a> 【卷积神经网络「失陷」，CoordConv来填坑】CoordConv 解决了坐标变换问题，具有更好的泛化能力，训练速度提高 150 倍，参数比卷积少 10-100 倍，并能极大提升多种视觉任务的表现。<a href='http://t.cn/RgvmXRU' target='_blank' class='url'>http://t.cn/RgvmXRU</a> Pytorch implementation of CoordConv GitHub:<a href='http://t.cn/RgyG5Te' target='_blank' class='url'>http://t.cn/RgyG5Te</a> 【深度剖析CoordConv论文】《Autopsy of a deep learning paper》by Filip Piekniewski <a href='http://t.cn/RgICGHy' target='_blank' class='url'>http://t.cn/RgICGHy</a> </p><p><a href='https://mp.weixin.qq.com/s/8uNBQwl3v9AmR_APE6K4qA'>学术 | 一种新的CNN网络可以更高效地区分自然图像&amp;生成图像</a></p><p><a href='http://www.sohu.com/a/216624750_651893'>学界 | CVPR 2017最佳论文作者黄高解析深度学习中的三大挑战</a></p><p><a href='https://mp.weixin.qq.com/s/_EoAA1SdK_-2WCiYq1GRmA'>卷积神经网络中十大拍案叫绝的操作</a></p><p>【基于进化算法的神经网络结构优化】Finding Better Topologies for Deep Convolutional Neural Networks by Evolution 本文通过用进化算法来做卷积神经网络的架构优化，最大的亮点是给出了影响架构性能的关键因素：1. 深度；2. 各节点之间的连接性。通过进化算法优化网络结构最大的瓶颈在于计算效率上，网络架构的效果评价是一个耗时的工作，生成和变异出的大量个体都需要评价。本文从一个最简单的架构作为初始个体，通过预设定的5种变异方式（添加边、节点、滤波器等操作）对原始个体进行变异优化，并通过可视化的方法对进化的过程进行了跟踪分析，找到了一些规律。完全自动化地去设计架构比较难，但通过自动设计分析出的一些结论可以帮助提高人工设计的效率。论文链接：<a href='http://t.cn/EvWjdJo' target='_blank' class='url'>http://t.cn/EvWjdJo</a></p><p>&nbsp;</p><p>&nbsp;</p><h2><a name='header-n422' class='md-header-anchor '></a>可视化</h2><p>Understanding Regularization to Visualize Convolutional Neural Networks 【<a href='https://arxiv.org/pdf/1805.00071.pdf' target='_blank' class='url'>https://arxiv.org/pdf/1805.00071.pdf</a>】</p><p>【动手玩：卷积网络可视化】《Fun With ConvNets (dataviz!) | Feedly Blog》by Kireet <a href='http://t.cn/RDExiQl' target='_blank' class='url'>http://t.cn/RDExiQl</a> GitHub:<a href='http://t.cn/RDExC4I' target='_blank' class='url'>http://t.cn/RDExC4I</a> </p><p>【通过可视化隐藏表示，更好地理解神经网络】本文介绍了如何利用隐藏表示可视化来更加直观地理解神经网络训练过程。本文使用的工具是 Neural Embedding Animator，大家可以利用该工具更好地理解模型行为、理解训练过程中数据表示的变化、对比模型、了解此词嵌入的变化。<a href='http://t.cn/RsR7veo' target='_blank' class='url'>http://t.cn/RsR7veo</a> </p><p>&nbsp;</p><h2><a name='header-n427' class='md-header-anchor '></a>卷积</h2><p><a href='http://ugastro.berkeley.edu/infrared09/PDF-2009/convolution2.pdf'>Convolution, Correlation, &amp;  Fourier Transforms</a> </p><p><a href='http://timdettmers.com/2015/03/26/convolution-deep-learning/'>Understanding Convolution in Deep Learning</a></p><p><a href='https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1'>Intuitively Understanding Convolutions for Deep Learning</a></p><p>《Deep Convolutional Networks as shallow Gaussian Processes》A Garriga-Alonso, L Aitchison, C E Rasmussen [University of Cambridge] (2018) <a href='http://t.cn/RkLEyYi' target='_blank' class='url'>http://t.cn/RkLEyYi</a> view:<a href='http://t.cn/RkLEyYI' target='_blank' class='url'>http://t.cn/RkLEyYI</a> GitHub:<a href='http://t.cn/RkLEyYJ' target='_blank' class='url'>http://t.cn/RkLEyYJ</a> </p><p>【卷积模型】《Convolutional Models》by Naila Murray <a href='http://t.cn/EvpiDcj' target='_blank' class='url'>http://t.cn/EvpiDcj</a> </p><p><a href='https://www.kaggle.com/shivamb/3d-convolutions-understanding-and-implementation'>3D Convolutions: Understanding and Implementation</a></p><p>&nbsp;</p><h2><a name='header-n434' class='md-header-anchor '></a>调参经验</h2><p><a href='https://medium.com/polyaxon/hyperparameters-tuning-with-polyaxon-9403f8ea85be'>Hyperparameters tuning with Polyaxon</a></p><blockquote><p>Look no further! Yoshua Bengio published one of my favorite applied papers, one that I recommend to all new machine learning engineers when they start training neural nets: <a href='http://arxiv.org/pdf/1206.5533v2.pdf'>Practical recommendations for gradient-based training of deep architectures.</a> To get his perspective on hyperparameter turning: including learning rate, learning rate schedule, early stopping, minibatch size, number of hidden layers, etc., see Section 3.</p></blockquote><p><a href='http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html#id13'>Hyperparameter optimization for Neural Networks</a></p><p>A Performance Evaluation of Convolutional Neural Networks for Face Anti Spoofing <a href='https://arxiv.org/abs/1805.04176'>arXiv:1805.04176</a></p><p>【DeepReplay超参优化实战】《Hyper-parameters in Action! Introducing DeepReplay》by Daniel Godoy <a href='http://t.cn/R3667TA' target='_blank' class='url'>http://t.cn/R3667TA</a> </p><p><a href='https://randomekek.github.io/deep/deeplearning.html'>Deep Learning for Beginners</a></p><p>【构建深度神经网络，我有20条「不成熟」的小建议】本文介绍了构建深度神经网络的一些基本技巧，从通用技巧、神经网络调试和案例研究三方面展开。<a href='http://t.cn/RdQcD1o' target='_blank' class='url'>http://t.cn/RdQcD1o</a> </p><p><a href='https://mp.weixin.qq.com/s/Xk1myDvYQxvKKyQ7RKqcyw'>Kaggle机器学习可重复性最佳实践</a></p><p>&nbsp;</p><p>Mixed precision training with MXNet <a href='https://www.youtube.com/watch?v=pR4KMh1lGC0' target='_blank' class='url'>https://www.youtube.com/watch?v=pR4KMh1lGC0</a></p><p>【混合精度神经网络训练实例】《Training Neural Networks with Mixed Precision: Real Examples》by Christian Sarofeen, Ben Barsdell, Michael Carilli, Michael Ruberry <a href='http://t.cn/RDNJuub' target='_blank' class='url'>http://t.cn/RDNJuub</a> </p><p>《S8923-Training Neural Networks with Mixed Precision: Theory and Practice》 <a href='http://t.cn/RDpM8Tq' target='_blank' class='url'>http://t.cn/RDpM8Tq</a> | Accelerating Deep Learning with Mixed Precision Arithmetic <a href='http://t.cn/RDpM8TX' target='_blank' class='url'>http://t.cn/RDpM8TX</a> | Mixed precision training with MXNet  <a href='http://t.cn/RDpM8Tb' target='_blank' class='url'>http://t.cn/RDpM8Tb</a></p><p>【模型调度：DNN训练过程中的超参调整】《Model Scheduling | Objective Funk》by Naomi Saphra <a href='http://t.cn/RDdBxUZ' target='_blank' class='url'>http://t.cn/RDdBxUZ</a> </p><p>【CNN问题排查清单】“Troubleshooting Convolutional Neural Networks” by Zeyad Emam GitHub:<a href='http://t.cn/Rkzqs8k' target='_blank' class='url'>http://t.cn/Rkzqs8k</a> </p><p>【神经网络调参经验分享】《How to make your model happy again》by Alessia Marcolini Part1: <a href='http://t.cn/Rk0vZAU' target='_blank' class='url'>http://t.cn/Rk0vZAU</a> pdf:<a href='http://t.cn/Rk0vZAA' target='_blank' class='url'>http://t.cn/Rk0vZAA</a> </p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h2><a name='header-n454' class='md-header-anchor '></a>Optimizing Hyperparameters</h2><p>&nbsp;</p><p><a href='https://nurture.ai/papers/drmad-distilling-reverse-mode-automatic-differentiation-for-optimizing-hyperparameters-of-deep-neural-networks/tldr'>Drmad: Distilling Reverse-mode Automatic Differentiation for Optimizing Hyperparameters of Deep Neural Networks</a></p><h2><a name='header-n457' class='md-header-anchor '></a>Transposed convolution</h2><p><a href='https://mp.weixin.qq.com/s/dnElNURJ6xfWHJVf_yeT8w'>理解多层CNN中转置卷积的反向传播（附代码）</a></p><p>&nbsp;</p><p>&nbsp;</p><h2><a name='header-n461' class='md-header-anchor '></a>空洞卷积技术 Dilated Convolutions</h2><p><a href='https://arxiv.org/pdf/1511.07122.pdf'>Dilated convolutions</a> </p><p>&nbsp;</p><p>&nbsp;</p><h2><a name='header-n465' class='md-header-anchor '></a>Activation</h2><p><a href='https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0'>Understanding Activation Functions in Neural Networks</a></p><p><a href='https://medium.com/@julsimon/a-quick-look-at-the-swish-activation-function-in-apache-mxnet-1-2-79d9ff9d1673'>Swish activation function</a></p><p><a href='https://mp.weixin.qq.com/s?src=11&timestamp=1525937594&ver=867&signature=760wHl-kvqtagEGd9dSL05DM5MurvpA5crTVt8hnT1fGuUvBrM8bc9T-RLcyyF46IdXux15qnwQHdWKWf1uniUoDIsstyKISqPAtCm8YMn-xpa9rH7vTR8IrzYwoELhB&new=1'>理解神经网络的激活函数</a></p><p><a href='https://blog.csdn.net/qq_20909377/article/details/79133981#elu'>ReLU、LReLU、PReLU、CReLU、ELU、SELU</a></p><p><a href='https://towardsdatascience.com/deep-study-of-a-not-very-deep-neural-network-part-2-activation-functions-fd9bd8d406fc'>Deep study of a not very deep neural network. Part 2: Activation functions</a></p><p>【神经网络基础：激活函数(Sigmoid, tanh, Softmax, ReLU, Leaky ReLU)通俗解析】《Activation Functions: Neural Networks》by SAGAR SHARMA <a href='http://t.cn/RYFMXep' target='_blank' class='url'>http://t.cn/RYFMXep</a> </p><p>&nbsp;</p><p>&nbsp;</p><h2><a name='header-n474' class='md-header-anchor '></a>Pooling</h2><blockquote><p>Pooling applied to reduce the number of parameters, improve invariance to certain distortions, and increase the receptive field size.</p></blockquote><ul><li><p>DPP (detail-preserving pooling) <a href='https://arxiv.org/pdf/1804.04076.pdf'>1804.04076</a></p><ul><li>DPP allows downscaling to focus on important structural detail; learnable parameters control the amount of detail preservation.</li></ul></li></ul><p>《Pooling is neither necessary nor sufficient for appropriate deformation stability in CNNs》A Ruderman, N C. Rabinowitz, A S. Morcos, D Zoran [DeepMind] (2018) <a href='http://t.cn/RmWn7Dm' target='_blank' class='url'>http://t.cn/RmWn7Dm</a> </p><p>&nbsp;</p><p>&nbsp;</p><h2><a name='header-n486' class='md-header-anchor '></a>Receptive Field</h2><p><a href='https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807'>A guide to receptive field arithmetic for Convolutional Neural Networks</a></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h2><a name='header-n491' class='md-header-anchor '></a>Kernel size</h2><p>Both <a href='https://arxiv.org/pdf/1512.03385.pdf'>ResNet</a> and <a href='https://arxiv.org/pdf/1409.1556.pdf'>VGGNet</a> explain and demonstrate this (kernel size) quite thoroughly.</p><h2><a name='header-n493' class='md-header-anchor '></a>Learning rate</h2><p><a href='https://www.jeremyjordan.me/nn-learning-rate/'>Setting the learning rate of your neural network.</a></p><p><a href='https://techburst.io/improving-the-way-we-work-with-learning-rate-5e99554f163b'>Improving the way we work with learning rate.</a></p><p><a href='https://mp.weixin.qq.com/s/B9nUwPtgpsLkEyCOlSAO5A'>观点 | 1cycle策略：实践中的学习率设定应该是先增再降</a>（<a href='https://sgugger.github.io/the-1cycle-policy.html'>原文</a>）</p><p>&nbsp;</p><h2><a name='header-n498' class='md-header-anchor '></a>Batch size</h2><p>最近一篇文章[1804.07612] revisit 这件事。简单说，就是 mini-batch-size 是很好的。</p><p>&nbsp;</p><h2><a name='header-n501' class='md-header-anchor '></a>Loss function</h2><p><img src='https://i.loli.net/2018/05/03/5aeac9bfb0acd.png' alt='Best slide award? [#**ICLR2018**](https://twitter.com/hashtag/ICLR2018?src=hash) progressive GANs by Kerras et al.' referrerPolicy='no-referrer' /></p><p>【损失函数详解】《Loss Functions Explained - YouTube》by Siraj Raval <a href='http://t.cn/Re7y5Pa' target='_blank' class='url'>http://t.cn/Re7y5Pa</a> GitHub:<a href='http://t.cn/Re7y5PS' target='_blank' class='url'>http://t.cn/Re7y5PS</a> </p><p>&nbsp;</p><h2><a name='header-n505' class='md-header-anchor '></a>Batch Normalization</h2><p><a href='https://mp.weixin.qq.com/s/VNyT_PH2smk69aN16RcxOA'>干货 | 北航博士生黄雷：标准化技术在训练深度神经网络中的应用</a></p><p><a href='https://arxiv.org/abs/1805.11604v1'>How Does Batch Normalization Help Optimization? (No, It Is Not About Internal Covariate Shift)</a> (arXiv:1805.11604v1)</p><p>《Towards a Theoretical Understanding of Batch Normalization》J Kohler, H Daneshmand, A Lucchi, M Zhou, K Neymeyr, T Hofmann [ETH Zurich &amp; University of Rostock] (2018) <a href='http://t.cn/R1Q6Por' target='_blank' class='url'>http://t.cn/R1Q6Por</a> </p><p>《Understanding Batch Normalization》J Bjorck, C Gomes, B Selman [Cornell University] (2018) <a href='http://t.cn/RB7DeQU' target='_blank' class='url'>http://t.cn/RB7DeQU</a> </p><p>The quest for optimal normalization in neural nets continues. SwitchNorm: add BatchNorm + InstanceNorm + GroupNorm with a learnable blend at each layer <a href='https://t.co/9hOQXnkk8T'>https://arxiv.org/abs/1806.10779 </a> fun plots; + code</p><p><a href='http://yeephycho.github.io/2016/08/03/Normalizations-in-neural-networks/' target='_blank' class='url'>http://yeephycho.github.io/2016/08/03/Normalizations-in-neural-networks/</a></p><p>&nbsp;</p><p>&nbsp;</p><h2><a name='header-n514' class='md-header-anchor '></a>Dropout</h2><p><a href='https://blog.csdn.net/stdcoutzyx/article/details/49022443'>理解dropout</a></p><p>《On the Implicit Bias of Dropout》P Mianjy, R Arora, R Vidal [Johns Hopkins University] (2018) <a href='http://t.cn/RrNIB3k' target='_blank' class='url'>http://t.cn/RrNIB3k</a> </p><p>【Dropout与神经网络深度复杂度】《Dropout and the Deep Complexity of Neural Networks》by Russell Cohen <a href='http://t.cn/RgWpcvX' target='_blank' class='url'>http://t.cn/RgWpcvX</a> </p><p>《Dropout is a special case of the stochastic delta rule: faster and more accurate deep learning》N Frazier-Logue, S J Hanson [Rutgers University] (2018) <a href='http://t.cn/RDmKMqO' target='_blank' class='url'>http://t.cn/RDmKMqO</a> view:<a href='http://t.cn/RDmKMqp' target='_blank' class='url'>http://t.cn/RDmKMqp</a> GitHub:<a href='http://t.cn/RDmKMq0' target='_blank' class='url'>http://t.cn/RDmKMq0</a> </p><p>【Hinton提出的经典防过拟合方法Dropout，只是SDR的特例】本文则提出，Dropout 中的按概率删除神经元的原则只是二项随机变量的特例。也就是说，研究者用神经元权重的连续分布替换了原先的二值（零/非零）分布，实现了广义的 Dropout——随机 delta 规则（SDR）。<a href='http://t.cn/RkFp5nf' target='_blank' class='url'>http://t.cn/RkFp5nf</a> </p><p>《A review of Dropout as applied to RNNs》by Adrian G <a href='http://t.cn/EvsGltP' target='_blank' class='url'>http://t.cn/EvsGltP</a>  <a href='https://mp.weixin.qq.com/s/c7XkzjLH1n5EtqdQik618g' target='_blank' class='url'>https://mp.weixin.qq.com/s/c7XkzjLH1n5EtqdQik618g</a></p><p>&nbsp;</p><p>&nbsp;</p><h2><a name='header-n523' class='md-header-anchor '></a>Overfitting</h2><p><a href='https://arxiv.org/pdf/1806.05161v1.pdf'>Overfitting or perfect fitting? Risk bounds for classification and regression rules that interpolate</a> </p><p>(Master Thesis)《Detecting Dead Weights and Units in Neural Networks》U Evci [New York University] (2018) <a href='http://t.cn/RrGYJaV' target='_blank' class='url'>http://t.cn/RrGYJaV</a> </p><p>&nbsp;</p><h2><a name='header-n527' class='md-header-anchor '></a>Optimization 梯度下降优化 &amp; 凸优化与近似</h2><p>（Adam）<a href='https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/'>Gentle Introduction to the Adam Optimization Algorithm for Deep Learning</a></p><p>《On the Convergence of Adaptive Gradient Methods for Nonconvex Optimization》D Zhou, Y Tang, Z Yang, Y Cao, Q Gu [University of California, Los Angele &amp; University of Virgini] (2018) <a href='http://t.cn/RkiMlZ9' target='_blank' class='url'>http://t.cn/RkiMlZ9</a> v</p><p><a href='https://github.com/kmkolasinski/deep-learning-notes/tree/master/max-normed-optimizer'>Notes on the application of the Normalized Gradient Descent approach to Deep Learning</a></p><p>【如何解释Gradient Boosting】《How to explain gradient boosting》by Terence Parr, Jeremy Howard <a href='http://t.cn/RrzumgT' target='_blank' class='url'>http://t.cn/RrzumgT</a> </p><p>【反向传播可视化解析】“Backpropagation explained via scrollytelling” by Daniel Smilkov <a href='http://t.cn/RrCRWJk' target='_blank' class='url'>http://t.cn/RrCRWJk</a> </p><p>【学霸笔记之梯度下降】《Machine Learning : Gradient Descent | Notespace》 <a href='http://t.cn/Rgge275' target='_blank' class='url'>http://t.cn/Rgge275</a> </p><p>《The “TerpreT problem” and the limits of SGD》 <a href='http://t.cn/Re6IxrJ' target='_blank' class='url'>http://t.cn/Re6IxrJ</a> GitHub:<a href='http://t.cn/Re6IxrM' target='_blank' class='url'>http://t.cn/Re6IxrM</a> </p><p>《Backprop Evolution》M Alber, I Bello, B Zoph, P Kindermans, P Ramachandran, Q Le [TU Berlin &amp; Google Brain] (2018) <a href='http://t.cn/RDShl2H' target='_blank' class='url'>http://t.cn/RDShl2H</a> </p><p>【新型反向传播算法】Backprop Evolution</p><p>ICML 2018 本文来自Google Brain，作者希望能够找到一种能够替代反向传播的方法。因此，他们设计了一种domain-specific language (DSL) 来函数式描述数学公式（例如反向传播），然后利用演化算法来发现新的传播算法，旨在找到泛化性能比BP更好的算法。最终通过实验，他们找到的算法能够在训练前期收敛得更快，但是收敛时并没有表现得更好。BP算法虽然取得了很大的成就，但是近年学界前沿也指出它的一些局限性，本文给这方面的研究探出了一小步。推荐人：@lunar（PaperWeekly社区用户）论文链接：<a href='http://t.cn/RkxyEcW' target='_blank' class='url'>http://t.cn/RkxyEcW</a></p><p>&nbsp;</p><p>【(Python)梯度下降动量可视化】《Visualizing Gradient Descent with Momentum in Python》by Henry Chang <a href='http://t.cn/Rkp1W58' target='_blank' class='url'>http://t.cn/Rkp1W58</a> GitHub:<a href='http://t.cn/Rkp1W5W' target='_blank' class='url'>http://t.cn/Rkp1W5W</a> pdf:<a href='http://t.cn/Rkp1W5l' target='_blank' class='url'>http://t.cn/Rkp1W5l</a> </p><p>《Don&#39;t Use Large Mini-Batches, Use Local SGD》T Lin, S U. Stich, M Jaggi [EPFL] (2018) <a href='http://t.cn/RkYLTUJ' target='_blank' class='url'>http://t.cn/RkYLTUJ</a> </p><p>《Neural Architecture Optimization》R Luo, F Tian, T Qin, T Liu [University of Science and Technology of China &amp; Microsoft Research] (2018) <a href='http://t.cn/RkYUOzo' target='_blank' class='url'>http://t.cn/RkYUOzo</a> </p><p><a href='https://towardsdatascience.com/recent-advances-for-a-better-understanding-of-deep-learning-part-i-5ce34d1cc914'>Recent Advances for a Better Understanding of Deep Learning − Part I</a></p><p><a href='https://twitter.com/intent/tweet?text=An%20overview%20of%20gradient%20descent%20optimization%20algorithms%20%C2%BB&hashtags=optimization,deep%20learning,sgd&url=http://ruder.io/optimizing-gradient-descent/'>An overview of gradient descent optimization algorithms</a></p><p>&nbsp;</p><p>Review：<a href='http://ruder.io/optimizing-gradient-descent/' target='_blank' class='url'>http://ruder.io/optimizing-gradient-descent/</a></p><p><a href='https://arxiv.org/pdf/1712.07628.pdf'></a></p><p><a href='https://arxiv.org/pdf/1712.07628.pdf'>this paper </a>found that switching from Adam to SGD mid-training achieves the best accuracy in the easiest way! </p><p>Great optimization lecture notes：<a href='https://ee227c.github.io' target='_blank' class='url'>https://ee227c.github.io</a> </p><p>《A Tutorial on Bayesian Optimization》P I. Frazier (2018) <a href='http://t.cn/RdEUPtd' target='_blank' class='url'>http://t.cn/RdEUPtd</a> </p><p>《A Unified Analysis of Stochastic Momentum Methods for Deep Learning》Y Yan, T Yang, Z Li, Q Lin, Y Yang [Southern University of Science and Technology &amp; The University of Iowa] (2018) <a href='http://t.cn/RFa3H3n' target='_blank' class='url'>http://t.cn/RFa3H3n</a></p><p><a href='https://mp.weixin.qq.com/s/m0FfYP-vBZv9cbAb6JhFZg'>博客 | 新的网络优化方法：随机权值平均</a></p><p>【高阶不变自然梯度加速】《Accelerating Natural Gradient with Higher-Order Invariance》by Yang Song <a href='http://t.cn/RsiAG45' target='_blank' class='url'>http://t.cn/RsiAG45</a> paper:<a href='http://t.cn/RsiAG44' target='_blank' class='url'>http://t.cn/RsiAG44</a> </p><p>《Hamiltonian Descent Methods》C J. Maddison, D Paulin, Y W Teh, B O&#39;Donoghue, A Doucet [University of Oxford &amp; DeepMind] (2018) <a href='http://t.cn/EvG89qE' target='_blank' class='url'>http://t.cn/EvG89qE</a>  哈密顿下降法——推广了优化的动量方法，大大扩展通过梯度实现指数收敛的凸函数族</p><p><a href='https://mp.weixin.qq.com/s/c1M5R3AYhIpJX0MHmp52_g'>246页《统计机器学习与凸优化》教程PPT下载</a></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n555' class='md-header-anchor '></a>GAN</h1><p><a href='https://medium.com/nurture-ai/keeping-up-with-the-gans-66e89343b46'>Keeping up with the GANs</a></p><blockquote><p>Guide to the key GAN papers for busy nerds.</p></blockquote><p>Goodfellow 曾专门针对谈 <a href='https://mp.weixin.qq.com/s/X8Q6RYsOSLYsYGBkAxaxuA'>GANs 相关paper评审</a>的感受，让我印象深刻的是提到了很多不良且功利的现象，也谈及了究竟怎么样的 GANs 实验模型讨论和设计是有逻辑，是可以说服人的。</p><p><a href='https://github.com/hindupuravinash/the-gan-zoo'>A list of all named GANs!</a></p><p><img src='https://i.loli.net/2018/05/03/5aeacb73c4342.png' alt='' referrerPolicy='no-referrer' /></p><p>&nbsp;</p><p><a href='http://nooverfit.com/wp/%E7%8B%AC%E5%AE%B6%EF%BD%9Cgan%E5%A4%A7%E7%9B%98%E7%82%B9%EF%BC%8C%E8%81%8A%E8%81%8A%E8%BF%99%E4%BA%9B%E5%B9%B4%E7%9A%84%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C-lsgan-wgan-cgan-info/'>独家 | GAN大盘点，聊聊这些年的生成对抗网络 : LSGAN, WGAN, CGAN, infoGAN, EBGAN, BEGAN, VAE</a></p><p>【GAN揭秘】《Demystifying Generative Adversarial Networks》by Stefan Hosein <a href='http://t.cn/R36JFOk' target='_blank' class='url'>http://t.cn/R36JFOk</a> </p><p>【生成对抗网络(GANs)/Wasserstein GANs综合指南】《Comprehensive Guide to Generative Adversarial Networks and Wasserstein GANs》by AI Journal <a href='http://t.cn/R1n8hrL' target='_blank' class='url'>http://t.cn/R1n8hrL</a></p><p><a href='https://mp.weixin.qq.com/s/e9wMKj8SgjtEWB9U7MM-9w'>生成式对抗网络模型综述</a></p><p>Ian Goodfellow 在推特上面发了一系列<a href='https://twitter.com/goodfellow_ian/status/996182175971131392'>评论</a>，关于神经网络的优化问题。 比如：给出了 GAN 论文的 eq2 是用啥推导的，最后还 bonus 了一本凸优化书。</p><p>Generative Adversarial Examples：<a href='https://arxiv.org/pdf/1805.07894.pdf' target='_blank' class='url'>https://arxiv.org/pdf/1805.07894.pdf</a></p><blockquote><p>This paper shows how to make adversarial examples with GANs. No need for a norm ball constraint. They look unperturbed to a human observer but break a model trained to resist large perturbations.  from: Goodfellow</p></blockquote><p>Self-Attention Generative Adversarial Networks：<a href='https://arxiv.org/abs/1805.08318' target='_blank' class='url'>https://arxiv.org/abs/1805.08318</a></p><blockquote><p>Self-attention for GANs. No more problems with losing track of how many faces the generator has drawn on the dog. </p><p>Simple Tensorflow implementation by Junho Kim GitHub:<a href='http://t.cn/R1kaw7n' target='_blank' class='url'>http://t.cn/R1kaw7n</a></p></blockquote><p>ExoGAN: Retrieving Exoplanetary Atmospheres Using Deep Convolutional Generative Adversarial Networks <a href='https://arxiv.org/abs/1806.02906' target='_blank' class='url'>https://arxiv.org/abs/1806.02906</a></p><p>【(NIPS 2016)如何训练对抗生成网络？GAN调试经验与技巧】’How to Train a GAN? Tips and tricks to make GANs work&quot; at NIPS2016&#39; by S Chintala, E Denton, M Arjovsky, M Mathieu GitHub: <a href='http://t.cn/RIzCeba' target='_blank' class='url'>http://t.cn/RIzCeba</a> </p><p>【GANs相关资料大全】“All about the GANs” by Jonathan Jeon <a href='http://t.cn/RrfFHmC' target='_blank' class='url'>http://t.cn/RrfFHmC</a> Readme style:<a href='http://t.cn/RrfFHmo' target='_blank' class='url'>http://t.cn/RrfFHmo</a> GitHub:<a href='http://t.cn/RrfFHmS' target='_blank' class='url'>http://t.cn/RrfFHmS</a> </p><p>《Convergence Problems with Generative Adversarial Networks (GANs)》S A. Barnett [University of Oxford] (2018) <a href='http://t.cn/Rda025g' target='_blank' class='url'>http://t.cn/Rda025g</a> </p><p>【GANs哪种训练方法能收敛？】《Which Training Methods for GANs do actually Converge? 》L Mescheder, A Geiger, S Nowozin [MPI Tübingen &amp; Microsoft Research] (2018) <a href='http://t.cn/RdanNIw' target='_blank' class='url'>http://t.cn/RdanNIw</a> GitHub:<a href='http://t.cn/RdanNI2' target='_blank' class='url'>http://t.cn/RdanNI2</a> </p><p>A practical “cookbook” for <a href='https://twitter.com/hashtag/GAN?src=hash'>#<strong>GAN</strong></a> research in 2018: <a href='https://t.co/ZSIZQILWG3'>https://arxiv.org/abs/1807.04720 </a></p><p><a href='https://mp.weixin.qq.com/s/IjlIT-3FVY7IfYzNDtkkgg'>谷歌大脑发布GAN全景图：看百家争鸣的生成对抗网络</a></p><p>【十篇GAN论文的数学分析】《Math Insights from 10 GAN papers. InfoGANs, VAEGANs, CycleGAN and more - YouTube》by Crazymuse AI <a href='http://t.cn/RgIO75r' target='_blank' class='url'>http://t.cn/RgIO75r</a> </p><p>【Background reading: 1. Summary of GAN tutorial (<a href='https://danieltakeshi.github.io/2017/03/05/understanding-generative-adversarial-networks/)' target='_blank' class='url'>https://danieltakeshi.github.io/2017/03/05/understanding-generative-adversarial-networks/)</a> - cross entropy between two distributions - understanding how gradient saturation may or may not adversely affect training. 2. Math behind GAN and WGAN ( <a href='https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html' target='_blank' class='url'>https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html</a> ) GAN paper roadmap: <a href='https://medium.com/nurture-ai/keeping-up-with-the-gans-66e89343b46' target='_blank' class='url'>https://medium.com/nurture-ai/keeping-up-with-the-gans-66e89343b46</a>,<a href='http://guimperarnau.com/blog/2017/03/Fantastic-GANs-and-where-to-find-them' target='_blank' class='url'>http://guimperarnau.com/blog/2017/03/Fantastic-GANs-and-where-to-find-them</a>】</p><p>四大生成模型优缺点比较：Autoregressive, VAE, Normalized, and GAN models via:David Duvenaud ：</p><p><img src='assets/image-20180801193947299.png' alt='image-20180801193947299' referrerPolicy='no-referrer' /></p><p>《From Adversarial Training to Generative Adversarial Networks》X Liu, C Hsieh [UC Davis] (2018) <a href='http://t.cn/ReOLwEE' target='_blank' class='url'>http://t.cn/ReOLwEE</a> </p><p>《How good is my GAN?》K Shmelkov, C Schmid, K Alahari [Inria] (2018) <a href='http://t.cn/RDhN2P4' target='_blank' class='url'>http://t.cn/RDhN2P4</a> </p><p>【GAN医学图像处理相关资料大列表】’Awesome GAN for Medical Imaging&#39; by Holger Caesar GitHub: <a href='http://t.cn/RDSVCfs' target='_blank' class='url'>http://t.cn/RDSVCfs</a> </p><p>《Skill Rating for Generative Models》C Olsson, S Bhupatiraju, T Brown, A Odena, I Goodfellow [Google Brain] (2018) <a href='http://t.cn/Rkz4Wuq' target='_blank' class='url'>http://t.cn/Rkz4Wuq</a> 今日焦点：生成模型评价方法——通过生成器和鉴别器之间打“比赛”判定“锦标赛胜率”和技能等级    <a href='https://mp.weixin.qq.com/s/btoCvQ3ysCgqzo9EdshdZg'>Ian Goodfellow：你的GAN水平我来打分</a></p><p>【Ian Goodfellow：你的GAN水平我来打分】Goodfellow 团队提出了一种全新生成模型评价方式，看来，GAN 的开山鼻祖终于坐不住了，他试图亲自解决这个问题。<a href='http://t.cn/Rk6l60A' target='_blank' class='url'>http://t.cn/Rk6l60A</a> </p><p>【不再使用人眼评估，你训练的GAN还OK吗？】本文认为现有指标不足以评估 GAN 模型，因此引入了两个基于图像分类的指标——GAN-train 和 GAN-test，分别对应 GAN 的召回率和精确率。研究者还基于这两个指标评估了最近的 GAN 方法并证明了这些方法性能的显著差异。<a href='http://t.cn/RkFM6L9' target='_blank' class='url'>http://t.cn/RkFM6L9</a> </p><p> <a href='https://arxiv.org/abs/1802.05957'>Spectral Normalization for Generative Adversarial Networks</a> <a href='https://medium.freecodecamp.org/dive-head-first-into-advanced-gans-exploring-self-attention-and-spectral-norm-d2f7cdb55ede'>Dive head first into advanced GANs: exploring self-attention and spectral norm</a></p><p>【GAN Lab：在浏览器里玩转GAN】“GAN Lab: Play with Generative Adversarial Networks in Your Browser!” <a href='http://t.cn/Rsw1scH' target='_blank' class='url'>http://t.cn/Rsw1scH</a>   <a href='http://minsuk.com/research/papers/kahng-ganlab-vast2018.pdf'>paper</a></p><p><a href='https://mp.weixin.qq.com/s/f93aCYrxlBFhRn0bgPDiTg'>微软剑桥研究院153页最新GAN教程（附代码）</a></p><p>【深度生成模型——基础、应用与开放问题】《(CCN 2018 Tutorial)Deep Generative Mode - Foundations, applications and open problrms》by Danilo J. Rezende <a href='http://t.cn/RskSGTG' target='_blank' class='url'>http://t.cn/RskSGTG</a> </p><p> See also: <a href='https://github.com/soumith/ganhacks' target='_blank' class='url'>https://github.com/soumith/ganhacks</a> for tips and tricks for trainings GANs</p><p>【本周GAN选：用神经网络生成音乐】《Music generation with Neural Networks — GAN of the week》by Alexander Osipenko <a href='http://t.cn/Ev73eL1' target='_blank' class='url'>http://t.cn/Ev73eL1</a> </p><p>【ECCV 2018 Best Paper Award】《GANimation: Anatomically-aware Facial Animation from a Single Image》A Pumarola, A Agudo, AM Martinez, A Sanfeliu… [CSIC-UPC &amp; The Ohio State University] (2018) <a href='http://t.cn/RefQJtt' target='_blank' class='url'>http://t.cn/RefQJtt</a> GitHub:<a href='http://t.cn/RefQ6aI' target='_blank' class='url'>http://t.cn/RefQ6aI</a> </p><p>【136页PPT-DeepMind 深度生成模型基础-应用与问题】<a href='https://docs.google.com/presentation/d/e/2PACX-1vSwRVxRHDarUx2mwXrsrlrtdTVTyEiFkWjJ9TvJ5ad6gbB3PDZSgD9yHAUiB6DcO1zP7LXBpxzc0SzC/pub?start=true&loop=true&delayms=3000&slide=id.gd9c453428_0_16'>链接：https://docs.google.com/presentation/d/e/2PACX-1vSwRVxRHDarUx2mwXrsrlrtdTVTyEiFkWjJ9TvJ5ad6gbB3PDZSgD9yHAUiB6DcO1zP7LXBpxzc0SzC/pub?start=true&amp;loop=true&amp;delayms=3000&amp;slide=id.gd9c453428_0_16</a></p><p>《ClusterGAN : Latent Space Clustering in Generative Adversarial Networks》S Mukherjee, H Asnani, E Lin, S Kannan [University of Washington] (2018) <a href='http://t.cn/EvXmoeP' target='_blank' class='url'>http://t.cn/EvXmoeP</a> </p><p>【GAN 实例教程】《GAN(MLSS 2018)》by Sebastian Nowozin [Microsoft Research Cambridge] <a href='http://t.cn/Ev9p89f' target='_blank' class='url'>http://t.cn/Ev9p89f</a> GitHub:<a href='http://t.cn/Ev9p89J' target='_blank' class='url'>http://t.cn/Ev9p89J</a> </p><p>《GANs for Medical Image Analysis》S Kazeminia, C Baur, A Kuijper, B v Ginneken, N Navab, S Albarqouni, A Mukhopadhyay [TU Darmstadt &amp; TU Munich] (2018) <a href='http://t.cn/EvYRGU0' target='_blank' class='url'>http://t.cn/EvYRGU0</a> </p><p><a href='https://mp.weixin.qq.com/s/4M0BDhgrB80weur_wbpdcg'>【GAN货】生成式对抗网络资料荟萃（原理/教程/报告/论文/实战/资料库）</a></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h2><a name='header-n604' class='md-header-anchor '></a>关于对抗性</h2><p><a href='https://www.youtube.com/watch?v=OTXEzJnzUV0'>深度神经网络安全性验证 Safety Verification for Deep Neural Networks (ICST2018)</a>（<a href='https://www.bilibili.com/video/av22112388/'>bilibili</a>）</p><p>【Kaggle NIPS&#39;17对抗样本挑战方案】’Submission to Kaggle NIPS&#39;17 competition on adversarial examples (non-targeted adversarial attack track)&#39; by iwiwi <a href='https://github.com/pfnet-research/nips17-adversarial-attack'>GitHub</a></p><p><a href='https://www.tinymind.cn/articles/126'>深度学习对抗样本的八个误解与事实</a> (<a href='https://www.kdnuggets.com/2015/07/deep-learning-adversarial-examples-misconceptions.html'>原英文</a> by <strong>By Ian Goodfellow (Google)</strong>)</p><p>【对抗鲁棒性工具箱:保护AI免受对抗(样本)威胁】《The Adversarial Robustness Toolbox: Securing AI Against Adversarial Threats》by Maria-Irina Nicolae and Mathieu Sinn <a href='http://t.cn/RmDXlmZ' target='_blank' class='url'>http://t.cn/RmDXlmZ</a> GitHub:<a href='http://t.cn/Rm1TiWB' target='_blank' class='url'>http://t.cn/Rm1TiWB</a> 《Closing the Backdoor in AI Security: Adversarial Robustness Toolbox v0.3.0.》 <a href='http://t.cn/RDNiSib' target='_blank' class='url'>http://t.cn/RDNiSib</a></p><blockquote><p>这是一个包含了各种反对抗样本方法的 library。其中也链接了各种反对抗性的方法，值得回溯查看（Supported attack and defense methods）！同时，作者还有一个 <a href='https://grehack.fr/data/2017/slides/GreHack17_Efficient%20Defenses_against_Adversarial_Examples_for_Deep_Neural_Networks.pdf'>slice</a> 是讲这个。</p></blockquote><p><img src='https://i.loli.net/2018/05/03/5aeacb9272781.jpeg' alt='' referrerPolicy='no-referrer' /></p><p><a href='https://www.rsipvision.com/ComputerVisionNews-2018May/6/'>Focus on：Adversarial Attacks on DL</a></p><p><a href='https://mp.weixin.qq.com/s/HSdhkazt1j5phMTLRMjFlQ'>ICASSP最佳学生论文：深度对抗声学模型训练框架</a>（这篇文章需要好好看看，应该可以用来构造引力波的降噪）</p><p>Together with <a href='https://twitter.com/goodfellow_ian'>@<strong>goodfellow_ian</strong></a> and Patrick McDaniel, we wrote a CACM article on making ML robust against adversarial inputs. It highlights the need for more verification to complement current testing practices (e.g., benchmarking w/ CleverHans). It&#39;s here: <a href='https://t.co/2dYSBkAe2l'>https://cacm.acm.org/magazines/2018/7/229030-making-machine-learning-robust-against-adversarial-inputs/fulltext …</a></p><p><a href='https://mp.weixin.qq.com/s/hKhsifnWKI-POeuGw8FbJQ'>清华朱军团队包揽三项冠军，NIPS 2017对抗样本攻防竞赛总结</a></p><p>【防御黑魔法：对抗样本安全研究现状及未来研究方向概述】《Defense Against the Dark Arts: An overview of adversarial example security research and future research directions》by Ian Goodfellow <a href='http://t.cn/R17Exsh' target='_blank' class='url'>http://t.cn/R17Exsh</a> CVPR 2018 version: <a href='http://t.cn/RryMWC2' target='_blank' class='url'>http://t.cn/RryMWC2</a></p><p>《Explainable Learning: Implicit Generative Modelling during Training for Adversarial Robustness》P Panda, K Roy [Purdue University] (2018) <a href='http://t.cn/RdjgvLv' target='_blank' class='url'>http://t.cn/RdjgvLv</a> </p><p>【用混淆梯度制造虚假安全感:绕过对抗样本防御】【ICML 2018 Best Paper Award】《Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples》[MIT &amp; UC Berkeley] (2018) <a href='http://t.cn/RdFyfwz' target='_blank' class='url'>http://t.cn/RdFyfwz</a> view:<a href='http://t.cn/RdFyfw7' target='_blank' class='url'>http://t.cn/RdFyfw7</a> GitHub: <a href='http://t.cn/R8ihLWm' target='_blank' class='url'>http://t.cn/R8ihLWm</a> </p><p>《Manifold Adversarial Learning》S Zhang, K Huang, J Zhu, Y Liu [Xi’an Jiaotong-Liverpool University &amp; Zhejiang University &amp; Alibaba Group] (2018) <a href='http://t.cn/RgmhZet' target='_blank' class='url'>http://t.cn/RgmhZet</a> </p><p>【对抗性重整探索】《Exploring Adversarial Reprogramming》by Rajat Vadiraj Dwaraknath <a href='http://t.cn/RgkiHze' target='_blank' class='url'>http://t.cn/RgkiHze</a> </p><p>&#39;adversarial-pytorch - Implementation of adversarial attacks and defences.&#39; by Sarath Chandra GitHub: <a href='http://t.cn/RDSykwJ' target='_blank' class='url'>http://t.cn/RDSykwJ</a> </p><p>《Training for Faster Adversarial Robustness Verification via Inducing ReLU Stability》K Y. Xiao, V Tjeng, N M Shafiullah, A Madry [MIT] (2018) <a href='http://t.cn/Rseb5wH' target='_blank' class='url'>http://t.cn/Rseb5wH</a> </p><p>《Are adversarial examples inevitable?》A Shafahi, W. R Huang, C Studer, S Feizi, T Goldstein (2018) <a href='http://t.cn/EvI50Vx' target='_blank' class='url'>http://t.cn/EvI50Vx</a> </p><p>《Adversarial Examples: Opportunities and Challenges》J Zhang, X Jiang [Hunan University] (2018) <a href='http://t.cn/Evn0HiT' target='_blank' class='url'>http://t.cn/Evn0HiT</a> </p><p>&nbsp;</p><h1><a name='header-n629' class='md-header-anchor '></a>Autoencoders</h1><p><a href='https://deeplearning4j.org/deepautoencoder#a-beginners-guide-to-deep-autoencoders'>A Beginner’s Guide to Deep Autoencoders</a></p><p>【自编码器解析：原理与实现】《How Autoencoders Work: Intro and Implementation | Kaggle》by Shivam Bansal <a href='http://t.cn/Ev5uhM7' target='_blank' class='url'>http://t.cn/Ev5uhM7</a> </p><p><a href='https://www.kaggle.com/shivamb/how-autoencoders-work-intro-and-usecases'>How Autoencoders Work: Intro and UseCases</a></p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n633' class='md-header-anchor '></a>变分自编码器（VAE）</h1><p><a href='https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650740857&idx=3&sn=d77b4f1231c2a0308e61b88109530631'>教程 | 如何使用变分自编码器VAE生成动漫人物形象</a>  <a href='https://medium.com/@wuga/generate-anime-character-with-variational-auto-encoder-81e3134d1439'>原文链接</a></p><p>《f-VAEs: Improve VAEs with Conditional Flows》J Su, G Wu [Sun Yat-sen University &amp; School of Hefei University of Technology] (2018) <a href='http://t.cn/EvYE3az' target='_blank' class='url'>http://t.cn/EvYE3az</a> </p><p>【(硕士论文)单[纯]自编码器——代数拓扑与概率模型的融合】《Simplicial AutoEncoders - A connection between Algebraic Topology and Probabilistic Modelling》by Jose Daniel Gallego Posada [University of Amsterdam] (2018) <a href='http://t.cn/EPICFpY' target='_blank' class='url'>http://t.cn/EPICFpY</a> </p><h2><a name='header-n3147' class='md-header-anchor '></a>Inception</h2><p>【Inception网络版本简要指南】《A Simple Guide to the Versions of the Inception Network》by Bharath Raj <a href='http://t.cn/R1ibM0L' target='_blank' class='url'>http://t.cn/R1ibM0L</a> </p><h1><a name='header-n637' class='md-header-anchor '></a>残差网络</h1><p><a href='https://arxiv.org/abs/1512.03385'>Resnet</a> (the great blog post “<a href='http://teleported.in/posts/decoding-resnet-architecture/'>Decoding the ResNet architecture</a>”), </p><p><a href='https://pythonmachinelearning.pro/understanding-advanced-convolutional-neural-networks/'>Understanding Advanced Convolutional Neural Networks</a> </p><p>上述链接来自：<a href='https://medium.com/@pierre_guillou/understand-how-works-resnet-without-talking-about-residual-64698f157e0c'>Understand how works Resnet… without talking about residual</a></p><p><a href='https://mp.weixin.qq.com/s/7fWh2dovmfbsF8afaX9UOg'>一文简述ResNet及其多种变体</a>（<a href='https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035'>原文</a>）</p><p>&nbsp;</p><h1><a name='header-n643' class='md-header-anchor '></a>目标检测算法</h1><p><a href='https://mp.weixin.qq.com/s/5zE78EU_NdV5ZeW5t1yV7A'>从RCNN到SSD，这应该是最全的一份目标检测算法盘点</a></p><p><a href='https://mp.weixin.qq.com/s/a1GFDzcR98b7pyJR1Gn-TA'>深度学习之目标检测网络学习总结（from RCNN to YOLO V3）</a></p><p><a href='https://mp.weixin.qq.com/s/l4HN0_VzaiO-DwtNp9cLVA'>【ICCV17论文笔记】循环注意力区域实现图像多标签分类</a></p><p>【目标检测相关资源(论文/代码)大列表】’Awesome Object Detection&#39; by Amusi GitHub: <a href='https://github.com/amusi/awesome-object-detection' target='_blank' class='url'>https://github.com/amusi/awesome-object-detection</a></p><p>《Tell Me Where to Look: Guided Attention Inference Network》K Li, Z Wu, K Peng, J Ernst, Y Fu [Northeastern University &amp; Siemens Corporate Technology] (2018) <a href='http://t.cn/REpSL1W' target='_blank' class='url'>http://t.cn/REpSL1W</a>  | Chainer implementation by Alok Kumar Bishoyi GitHub:<a href='http://t.cn/Rd52mvy' target='_blank' class='url'>http://t.cn/Rd52mvy</a></p><p>【目标检测综述：一阶段方法】《An overview of object detection: one-stage methods》by Jeremy Jordan <a href='http://t.cn/RdklQJT' target='_blank' class='url'>http://t.cn/RdklQJT</a> </p><p>【目标检测算法评价】’Metrics for object detection - Most popular metrics used to evaluate object detection algorithms&#39; by Rafael Padilla GitHub: <a href='http://t.cn/RgifiUd' target='_blank' class='url'>http://t.cn/RgifiUd</a> </p><p>【Faster R-CNN解析】《Faster R-CNN Explained》by Hao Gao <a href='http://t.cn/RFARXBA' target='_blank' class='url'>http://t.cn/RFARXBA</a> pdf:<a href='http://t.cn/RFARXBw' target='_blank' class='url'>http://t.cn/RFARXBw</a> </p><p><a href='https://medium.com/@jonathan_hui/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9'>What do we learn from region based object detectors (Faster R-CNN, R-FCN, FPN)?目标检测算法盘点</a></p><p><a href='https://mp.weixin.qq.com/s/BFL2PhAojZ5zHstgTrhlrw'>悉尼大学欧阳万里等人30页最新目标检测综述</a></p><p>《Recent Advances in Object Detection in the Age of Deep Convolutional Neural Networks》S Agarwal, J O D Terrail, F Jurie [Normandie Univ] (2018) <a href='http://t.cn/EvXgDFw' target='_blank' class='url'>http://t.cn/EvXgDFw</a> </p><p><a href='https://mp.weixin.qq.com/s/56bcjzUDm7V0oDknAk0Azw'>从R-CNN到RFBNet,深度目标检测5年纵览，文章+代码让你从入门</a></p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n656' class='md-header-anchor '></a>语义分割</h1><p><a href='https://www.jeremyjordan.me/semantic-segmentation/'>An overview of semantic image segmentation.</a></p><p><a href='https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650745511&idx=3&sn=af264ed1137b77340f1d4876889f709d&chksm=871aeed9b06d67cf230c326afb7dc6e66248d3463342b7a0507e069d71c77532a133d9fc0f98#rd'>教程 | 重新发现语义分割，一文简述全卷积网络</a></p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n661' class='md-header-anchor '></a>降噪</h1><p>Variational based Mixed Noise Removal with CNN Deep Learning Regularization <a href='https://arxiv.org/pdf/1805.08094.pdf' target='_blank' class='url'>https://arxiv.org/pdf/1805.08094.pdf</a></p><p>Adversarial Noise Layer: Regularize Neural Network By Adding Noise <a href='https://arxiv.org/pdf/1805.08000.pdf' target='_blank' class='url'>https://arxiv.org/pdf/1805.08000.pdf</a></p><p>《Wave-U-Net: A Multi-Scale Neural Network for End-to-End Audio Source Separation》D Stoller, S Ewert, S Dixon [Queen Mary University of London &amp; Spotify] (2018) <a href='http://t.cn/RBtpzQL' target='_blank' class='url'>http://t.cn/RBtpzQL</a> view:<a href='http://t.cn/RBtpzQA' target='_blank' class='url'>http://t.cn/RBtpzQA</a> GitHub:<a href='http://t.cn/RBtpzQ2' target='_blank' class='url'>http://t.cn/RBtpzQ2</a> </p><p><a href='https://github.com/ramarlina/DenoisingAutoEncoder'>Denoising AutoEncoder</a> </p><p><a href='http://deeplearning.net/tutorial/dA.html'>Denoising Autoencoders (dA)</a></p><p><a href='https://github.com/c1mone/Tensorflow-101/blob/master/notebooks/8_Denoising_Autoencoder.ipynb'>Denoising Autoencoder</a>（TF）</p><p><a href='https://www.cnblogs.com/tornadomeet/p/3261247.html'>Deep learning：四十二(Denoise Autoencoder简单理解)</a></p><p>《Learning Dynamics of Linear Denoising Autoencoders》A Pretorius, S Kroon, H Kamper [Stellenbosch University] (2018) <a href='http://t.cn/RrV40wG' target='_blank' class='url'>http://t.cn/RrV40wG</a> view:<a href='http://t.cn/RrV40w4' target='_blank' class='url'>http://t.cn/RrV40w4</a> </p><p>《Attentive Generative Adversarial Network for Raindrop Removal from a Single Image》R Qian, R T. Tan, W Yang, J Su, J Liu [Peking University &amp; National University of Singapore] (2017) <a href='https://arxiv.org/abs/1711.10098v4' target='_blank' class='url'>https://arxiv.org/abs/1711.10098v4</a>   GitHub:<a href='http://t.cn/RDfhFhN' target='_blank' class='url'>http://t.cn/RDfhFhN</a></p><p><a href='https://mp.weixin.qq.com/s/Vb0sIXC7s0yMRfhZFeC-wg'>如何基于生成对抗网络来进行图像盲去噪？（附论文）</a></p><p><a href='https://mp.weixin.qq.com/s/JZaWJzVHXShgTQUuiJlDVA'>ICML 2018 | 英伟达提出仅使用噪点图像训练的图像增强方法，可去除照片噪点</a>  <a href='https://news.developer.nvidia.com/ai-can-now-fix-your-grainy-photos-by-only-looking-at-grainy-photos/'>AI Can Now Fix Your Grainy Photos by Only Looking at Grainy Photos</a></p><p>《Toward Convolutional Blind Denoising of Real Photographs》S Guo, Z Yan, K Zhang, W Zuo, L Zhang [Harbin Institute of Technology &amp; The Hong Kong Polytechnic University] (2018) <a href='http://t.cn/Rgrv2L1' target='_blank' class='url'>http://t.cn/Rgrv2L1</a> view:<a href='http://t.cn/Rgrv2Ld' target='_blank' class='url'>http://t.cn/Rgrv2Ld</a> GitHub:<a href='http://t.cn/Rgrv2Lr' target='_blank' class='url'>http://t.cn/Rgrv2Lr</a> </p><p>【单图去雨(PyTorch)】’Recurrent Squeeze-and-Excitation Context Aggregation Net for Single Image Deraining&#39;  GitHub: <a href='http://t.cn/Rge6kT9' target='_blank' class='url'>http://t.cn/Rge6kT9</a> paper:《Recurrent Squeeze-and-Excitation Context Aggregation Net for Single Image Deraining》 [Peking University] (2018) <a href='http://t.cn/Rge6kTp' target='_blank' class='url'>http://t.cn/Rge6kTp</a>  </p><p>【最新可复现图像去噪算法汇总】’Collection of popular and reproducible image denoising works.&#39; by Bihan Wen GitHub: <a href='http://t.cn/RkREnEk' target='_blank' class='url'>http://t.cn/RkREnEk</a> another by Wenhan Yang <a href='http://t.cn/RkREeyJ' target='_blank' class='url'>http://t.cn/RkREeyJ</a> </p><p>&nbsp;</p><h1><a name='header-n677' class='md-header-anchor '></a>数据不均衡&amp;数据扩增</h1><p>Using more data has been shown to consistently increase performance, even up to an <a href='https://arxiv.org/pdf/1707.02968.pdf'>extreme amount</a>. </p><p><a href='https://www.datasciencecentral.com/profiles/blogs/dealing-with-imbalanced-datasets'>Dealing With Imbalanced Datasets</a> </p><p>这里有个小哥居然总结了个 <a href='https://github.com/aleju/imgaug'>data augmentation library</a></p><p><a href='https://petewarden.com/2018/05/28/why-you-need-to-improve-your-training-data-and-how-to-do-it/'>Why you need to improve your training data, and how to do it</a></p><p><a href='https://www.datasciencecentral.com/profiles/blog/show?id=6448529%3ABlogPost%3A387978'>Understanding basics of data science</a></p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n685' class='md-header-anchor '></a>数据预处理</h1><p>【如何(以及为何)创建好的验证集】《How (and why) to create a good validation set | fast.ai》by Rachel Thomas <a href='http://t.cn/RjfEs2J' target='_blank' class='url'>http://t.cn/RjfEs2J</a> </p><p><a href='https://mp.weixin.qq.com/s/YVNuuH0yyZx0_L4ch6gcbw'>【ECCV2018教程】220页深度神经网络训练归一化: 数学基础与理论、挑战(附pdf下载)</a></p><p><a href='https://www.datasciencecentral.com/profiles/blogs/feature-scaling-and-normalization'>Feature Scaling and Normalization</a></p><p>&nbsp;</p><h1><a name='header-n690' class='md-header-anchor '></a>权重初始化</h1><p><a href='https://mp.weixin.qq.com/s/mFA2PeO70o3HR6AQ74Lp3g'>深度学习最佳实践之权重初始化</a></p><p>【可穿戴设备(时序)数据的数据增广】’A sample code of data augmentation methods for wearable sensor data (time-series data)&#39; by Terry Taewoong Um GitHub: <a href='http://t.cn/RBbapp2' target='_blank' class='url'>http://t.cn/RBbapp2</a> </p><p><a href='https://arxiv.org/pdf/1806.04884.pdf'>Weight Initialization without Local Minima in Deep Nonlinear Neural Networks</a> </p><p><a href='https://arxiv.org/abs/1802.05957'>Spectral Normalization for Generative Adversarial Networks</a></p><p>Paper: </p><ul><li><strong>Understanding the difficulty of training deep feedforward neural networks</strong> by Glorot and Bengio, 2010</li><li><strong>Exact solutions to the nonlinear dynamics of learning in deep linear neural networks</strong> by Saxe et al, 2013</li><li><strong>Random walk initialization for training very deep feedforward networks</strong> by Sussillo and Abbott, 2014</li><li><strong>Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification</strong> by He et al., 2015</li><li><strong>Data-dependent Initializations of Convolutional Neural Networks</strong> by Krähenbühl et al., 2015</li><li><strong>All you need is a good init</strong>, Mishkin and Matas, 2015</li><li>...</li></ul><p><a href='https://nurture.us17.list-manage.com/track/click?u=64a0423ba27e56e68c24b4cc8&id=55a54af2d6&e=b1bf4f7a42'>Improving Transferability of Deep Neural Networks</a> This paper looks into the initial parameters that yield the best results during transfer learning.</p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n714' class='md-header-anchor '></a>可解释性</h1><p><a href='https://arxiv.org/pdf/1806.00069v2.pdf'>Explaining Explanations: An Approach to Evaluating Interpretability of Machine Learning</a> </p><p>传统的统计学分析下，构建的模型都是自顶向下的，其中可解释性就是整套方法的解释，它衔接了人既定下的规则和所产生的行为策略。而对于自底向上的模式而言，是将数据的潜在规则交给模型去挖掘，如果能够解释模型的发现，这就会有效的指导我们的工作，并使得数据科学的理解更加透彻。</p><p><a href='https://deepmind.com/blog/understanding-deep-learning-through-neuron-deletion/'>Understanding deep learning through neuron deletion</a></p><p><a href='https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650741674&idx=4&sn=8b27bc3a98455c8797ee257e961b86ac'>学界 | DeepMind论文：CNN的变形稳定性和池化无关，滤波器平滑度才是关键</a></p><p>如果不是看到大神 Goodfellow 是作者之一，我就还以为这是一片水文呢~ 结论说DNN的随机初始化下，不管从可视化还是量化的角度上看都和训练好后的很像。猜测可能这些“解释”都是与低层的表示相关联导致，影射了模型本身存在很强的先验。（<a href='https://openreview.net/forum?id=SJOYTK1vM'>paper</a>）</p><ul><li><p>为什么需要可解释性？From：<a href='https://towardsdatascience.com/interpretability-in-machine-learning-70c30694a05f'>Interpreting machine learning models</a>(<a href='https://mp.weixin.qq.com/s/MzWBkaGsFTtAs5zDMjvP6Q'>CN</a>)</p><ul><li>能够识别并减小模型偏差</li><li>帮助分析问题的前后联系，解释问题的背景（即映射的逻辑）</li><li>改善泛化性。可解释性越强，泛化性越强。</li><li>伦理和法律需要，审视模型的决策过程。</li></ul></li><li><p>如何解释模型？</p><ul><li><p>特征重要性。广泛见于传统机器学习算法中，如一般线性模型的特征系数，非线性的随机森林和 SVM 输出的特征重要性。在深度学习中，有两种方向：基于梯度的方法（利用方向传播梯度，如：<a href='https://arxiv.org/pdf/1610.02391.pdf'>Grad-CAM</a>）和基于注意力机制的方法（主要用于序列数据）</p></li><li><p><a href='https://github.com/marcotcr/lime'>LIME</a>（为了保持模型的独立性，LIME修改局域的输入将特别的测试用例输入模型并观察对预测造成的影响，通过一个个特定的样例来观察模型的可解释性）(more: <a href='https://medium.com/@lars.hulstaert/understanding-model-predictions-with-lime-a582fdff3a3b'>Understanding model predictions with LIME</a>)</p></li><li><p>信息论角度解释网络模型是 promising 的。18年4月就有篇从信息论去理解每个神经元的重要性的文章 <a href='https://arxiv.org/pdf/1804.06679.pdf'>ArXiv: 1804.06679</a>，里面有很多 insights 值得思考。紧随其后是另一篇信息论解释卷积神经网络的文章 <a href='https://arxiv.org/abs/1804.06537'> ArXiv: 1804.06537</a>，我还没有仔细的开始看。</p></li><li><p>信息几何学。《Fisher Information and Natural Gradient Learning of Random Deep Networks》S Amari, R Karakida, M Oizumi [RIKEN CBS &amp; AIST &amp; Araya Inc] (2018) <a href='http://t.cn/RkYLZ82' target='_blank' class='url'>http://t.cn/RkYLZ82</a>   ；《Statistical Neurodynamics of Deep Networks: Geometry of Signal Spaces》S Amari, R Karakida, M Oizumi [RIKEN CBS &amp; AIST &amp; Araya Inc] (2018) <a href='http://t.cn/RkYLo6M' target='_blank' class='url'>http://t.cn/RkYLo6M</a>  ；《An elementary introduction to information geometry》F Nielsen [Sony] (2018) <a href='http://t.cn/RFAqRVL' target='_blank' class='url'>http://t.cn/RFAqRVL</a></p></li><li><p>概率论角度的解释观点是很有意思的。我最开始看到的是这个博文 <a href='https://medium.com/nurture-ai/magic-behind-a-probabilistic-framework-for-deep-learning-explained-bef0f855fa16'>Medium</a>，它主要是针对2016年12月的一篇 paper：“<a href='https://arxiv.org/abs/1612.01936'>A Probabilistic Framework for Deep Learning</a>” 谈的。</p></li><li><p>物理理论观点的解释也是可圈可点的，虽然有灌水的可能性。比如最近上海交大的这篇：<a href='https://arxiv.org/abs/1805.08355v1'>Opening the black box of deep learning</a></p></li><li><p>微分几何角度的解释：<a href='https://arxiv.org/pdf/1805.10451.pdf'>Geometric Understanding of Deep Learning</a> ； 《Grassmannian Learning: Embedding Geometry Awareness in Shallow and Deep Learning》J Zhang, G Zhu, R W. H Jr., a K Huang [The University of Hong Kong] (2018) <a href='http://t.cn/RDxRODS' target='_blank' class='url'>http://t.cn/RDxRODS</a>  ； <a href='https://mp.weixin.qq.com/s/onqVbGBdS5pfM3itdBP8eQ'>深度学习的几何观点（老顾）</a>；这篇<a href='https://journals.aps.org/prx/pdf/10.1103/PhysRevX.8.031003'>文章</a>是怎样的观点还不确定</p></li><li><p>【通过拓扑数据分析理解卷积神经网络行为】《Using Topological Data Analysis to Understand the Behavior of Convolutional Neural Networks | Ayasdi》by Gunnar Carlsson <a href='http://t.cn/RrNWU96' target='_blank' class='url'>http://t.cn/RrNWU96</a> </p></li><li><p>【神经同源理论探索——用代数拓扑刻画神经网络容量】《Towards Neural Homology Theory - On Characterizing the Capacity of Neural Networks using Algebraic Topology - YouTube》by William Guss <a href='http://t.cn/Rnad6M7' target='_blank' class='url'>http://t.cn/Rnad6M7</a> </p></li><li><p><a href='https://mp.weixin.qq.com/s/a1r7MrP-T2Icphj8FSv2ag'>从傅里叶分析角度解读深度学习的泛化能力</a> [1]. Zhi-Qin J. Xu, Yaoyu Zhang, Yanyang Xiao. Training behavior of deep neural network in frequency domain, arXiv preprint arXiv: 1807.01251. (May 18, 2018 submitted to NIPS, first submitted to arXiv on Jul 3, 2018) </p><p>[2]. Nasim Rahaman, Devansh Arpit, Aristide Baratin, Felix Draxler, Min Lin, Fred A. Hamprecht, Yoshua Bengio, Aaron Courville. On the spectral bias of deep neural networks, arXiv preprint arXiv:1806.08734. (First submitted to arXiv Jun 22, 2018) </p><p>[3]. Zhi-Qin J. Xu. Understanding training and generalization in deep learning by Fourier analysis, arXiv preprint arXiv: 1808.04295. (First submitted to arXiv on Aug 14, 2018)</p></li></ul></li></ul><p>Cody Marie Wild 写过一篇<a href='https://towardsdatascience.com/tell-me-a-story-thoughts-on-model-interpretability-37a03ed41440'>博文</a>(<a href='https://mp.weixin.qq.com/s/k-BvSdu82O6N_Ev8vnyCrg'>译文</a>)探讨过模型的可解释性，她认为需要认清楚一个关键的概念：<strong>对于一项复杂模型的可解释性表示，通常被大体看做是其本身的一种压缩表示。</strong> 并且在文中，她将现在可解释模型的方法有一下两种分类方式：</p><ol start='' ><li><p><strong>Feature Attribution vs Internal Logic</strong>（特征归属 VS 内部逻辑）</p><ul><li>Shapley Values and LIME </li><li>layer template visualization</li></ul></li><li><p><strong>Knowledge Through Simulation vs Knowledge Through Introspection</strong>（模拟获取知识 VS 内省获取知识）</p><ul><li>LIME（它模拟局部数据样本，并使用局部内核）and Neuron Visualization（它以数值方法优化像素，把内部状态变成高激活值）</li><li>Basic feature importance in linear models (where the linearity and fixed number of terms mean you can just analytically compute FI), and also Gini-reduction feature importance in random forest ensembles</li></ul></li></ol><p>&nbsp;</p><p>讲 feature 的：《From handcrafted to deep local invariant features》G Csurka, M Humenberger [Naver Labs Europe] (2018) <a href='http://t.cn/RDhSYQ5' target='_blank' class='url'>http://t.cn/RDhSYQ5</a></p><p>【Lucid：神经网络可解释性研究工具集】“Lucid - a collection of infrastructure and tools for research in neural network interpretability.” GitHub:<a href='http://t.cn/RR4WAjI' target='_blank' class='url'>http://t.cn/RR4WAjI</a> </p><p>《Out of the Black Box: Properties of deep neural networks and their applications》N Ouarti, D Carmona [Sorbonne Universite] (2018) <a href='http://t.cn/RDFlzdy' target='_blank' class='url'>http://t.cn/RDFlzdy</a> view:<a href='http://t.cn/RDFlzdA' target='_blank' class='url'>http://t.cn/RDFlzdA</a> </p><p><a href='https://github.com/tensorflow/lucid#notebooks'>A collection of infrastructure and tools for research in neural network interpretability.</a></p><p><a href='https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650747137&idx=3&sn=ba6f60b0d96afea2dda69dd9186e5e32&chksm=871af57fb06d7c69cbdea25ed090016bc8f8a7e9dacb0afb313e5113edc731e0b4a6b3d5624f&token=1035066894&lang=zh_CN#rd'>前沿 | XNN：打开了自己黑箱的神经网络</a></p><p> <a href='https://mp.weixin.qq.com/s/iiAzQb5AxqsgcDD7EhWo-A'>【干货51页PPT】深度学习理论理解探索</a></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n783' class='md-header-anchor '></a>泛化能力</h1><p><a href='https://mp.weixin.qq.com/s/LE0-rDQXNpsOQA8SIx1Plg'>学界 | ICLR 最佳论文作者张驰原演讲全文：理解深度学习，为何我们需要重新思考泛化问题？（附视频）</a></p><p><a href='https://liam0205.me/2017/03/25/bias-variance-tradeoff/'>谈谈 Bias-Variance Tradeoff</a></p><p>【神经网络相似性如何帮助我们理解训练和泛化？】《How Can Neural Network Similarity Help Us Understand Training and Generalization? | Google AI Blog》 <a href='http://t.cn/Rrzn4F8' target='_blank' class='url'>http://t.cn/Rrzn4F8</a> paper:《Insights on representational similarity in neural networks with canonical correlation》A S. Morcos, M Raghu, S Bengio [DeepMind &amp; Google Brain] (2018) <a href='http://t.cn/Rrzn4FR' target='_blank' class='url'>http://t.cn/Rrzn4FR</a> <a href='https://mp.weixin.qq.com/s/GkZ8tbcBsXcFIjFUFbxKvg'>神经网络相似性如何帮助我们理解训练和泛化？</a></p><p>&nbsp;</p><p>《Generalization Error in Deep Learning》D Jakubovitz, R Giryes, M R. D. Rodrigues [Tel Aviv University &amp; University College London] (2018) <a href='http://t.cn/RD4d0td' target='_blank' class='url'>http://t.cn/RD4d0td</a> </p><p>《Importance of the Mathematical Foundations of Machine Learning Methods for Scientific and Engineering Applications》P J. Atzberger [University of California Santa Barbara] (2018) <a href='http://t.cn/RDxR41I' target='_blank' class='url'>http://t.cn/RDxR41I</a> </p><p>《Generalisation in humans and deep neural networks》R Geirhos, C R. M Temme, J Rauber, H H. Schuett, M Bethge, F A. Wichmann [University of Tübingen] (2018) <a href='http://t.cn/RFAq48f' target='_blank' class='url'>http://t.cn/RFAq48f</a> view:<a href='http://t.cn/RFAq48x' target='_blank' class='url'>http://t.cn/RFAq48x</a> GitHub:<a href='http://t.cn/RFAq48M' target='_blank' class='url'>http://t.cn/RFAq48M</a> </p><p>《Data Dropout: Optimizing Training Data for Convolutional Neural Networks》T Wang, J Huan, B Li [Austin Peay State University &amp; Baidu Research] (2018) <a href='http://t.cn/RsuAWxB' target='_blank' class='url'>http://t.cn/RsuAWxB</a> view:<a href='http://t.cn/RsuAWxr' target='_blank' class='url'>http://t.cn/RsuAWxr</a> </p><p>《Identifying Generalization Properties in Neural Networks》H Wang, N S Keskar, C Xiong, R Socher [Salesforce Research] (2018) <a href='http://t.cn/Evse2oJ' target='_blank' class='url'>http://t.cn/Evse2oJ</a> </p><p><a href='https://mp.weixin.qq.com/s/1A5KFpxeAyifI4o9ZnIpNQ'>针对神经算数逻辑单元（NALU）的简单指南：解释，出发点和代码</a></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n793' class='md-header-anchor '></a>RNN/LSTM</h1><p>【Back to Basics】<a href='https://towardsdatascience.com/back-to-basics-deriving-back-propagation-on-simple-rnn-lstm-feat-aidan-gomez-c7f286ba973d'>Deriving Back Propagation on simple RNN/LSTM</a> (feat. <a href='https://medium.com/@aidangomez?source=post_header_lockup'>Aidan Gomez</a>)</p><p><a href='https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650745597&idx=3&sn=1c2f167b46c558993e3b6aa8dc881628&chksm=871aee83b06d6795ba22f3547c6e9b677f022f8a46b7edb26f5294a9c87da3a21478d19e1fe5#rd'>入门 | 一文简述循环神经网络</a></p><p>《Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) Network》A Sherstinsky [Directly Software] (2018) <a href='http://t.cn/RDm9ZuD' target='_blank' class='url'>http://t.cn/RDm9ZuD</a> view:<a href='http://t.cn/RDm9Z3v' target='_blank' class='url'>http://t.cn/RDm9Z3v</a> </p><p>《深入讨论RNN》非常好的讨论递归神经网络的文章，覆盖了RNN的概念、原理、训练及优化等各个方面内容，强烈推荐！本文作者Nikhil Buduma，也是前两天推荐的《Deep Learning in a Nutshell》的作者，赞！ <a href='http://t.cn/RZKo42W' target='_blank' class='url'>http://t.cn/RZKo42W</a> </p><p>【RNN图解指南】《Illustrated Guide to Recurrent Neural Networks》by Michael Nguyen <a href='http://t.cn/EvgGDAi' target='_blank' class='url'>http://t.cn/EvgGDAi</a> </p><p>《A review of Dropout as applied to RNNs》by Adrian G <a href='http://t.cn/EvsGltP' target='_blank' class='url'>http://t.cn/EvsGltP</a>  <a href='https://mp.weixin.qq.com/s/c7XkzjLH1n5EtqdQik618g' target='_blank' class='url'>https://mp.weixin.qq.com/s/c7XkzjLH1n5EtqdQik618g</a></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n799' class='md-header-anchor '></a>PDE</h1><p>&nbsp;</p><p>《Are Efficient Deep Representations Learnable?》M Nye, A Saxe [MIT &amp; Harvard University] (2018) <a href='http://t.cn/RgCP8S3' target='_blank' class='url'>http://t.cn/RgCP8S3</a></p><h1><a name='header-n802' class='md-header-anchor '></a>NLP</h1><p>【自然语言处理(NLP)最新进展/相关资源跟踪大列表】’Tracking Progress in Natural Language Processing - Repository to track the progress in Natural Language Processing (NLP), including the datasets and the current state-of-the-art for the most common NLP tasks.&#39; by Sebastian Ruder GitHub: <a href='http://t.cn/RryQBAa' target='_blank' class='url'>http://t.cn/RryQBAa</a> Blog: <a href='http://t.cn/RryQBA6' target='_blank' class='url'>http://t.cn/RryQBA6</a> Home:<a href='http://t.cn/Rgk6Y6R' target='_blank' class='url'>http://t.cn/Rgk6Y6R</a></p><p>【文本分类数据准备/模型选择流程图】《Step 2.5: Choose a Model  |  ML Universal Guides  |  Google Developers》  <a href='http://t.cn/RevzgsB' target='_blank' class='url'>http://t.cn/RevzgsB</a> </p><p>回顾：追踪NLP最新技术进展的两个好地方：NLP-progress <a href='http://t.cn/Rgk6Y6R' target='_blank' class='url'>http://t.cn/Rgk6Y6R</a> 和 decaNLP <a href='http://t.cn/ReLzyoX' target='_blank' class='url'>http://t.cn/ReLzyoX</a> 感谢Sebastian Ruder, Bryan McCann </p><p>【文本风格迁移文献列表】’Paper List for Style Transfer in Text&#39; by Zhenxin Fu GitHub: <a href='http://t.cn/RDL2wqa' target='_blank' class='url'>http://t.cn/RDL2wqa</a> </p><p>【自然语言处理中的泛化问题，以及研究人员是如何着手解决的】《NLP’s generalization problem, and how researchers are tackling it》by Ana Marasović <a href='https://thegradient.pub/frontiers-of-generalization-in-natural-language-processing/' target='_blank' class='url'>https://thegradient.pub/frontiers-of-generalization-in-natural-language-processing/</a> </p><p>【任务驱动对话数据集列表】’Task-Oriented Dialogue Dataset Survey - A dataset survey about task-oriented dialogue, including recent datasets.&#39; by Atma GitHub: <a href='http://t.cn/RD6pp1d' target='_blank' class='url'>http://t.cn/RD6pp1d</a> </p><p><a href='https://link.zhihu.com/?target=http%3A//karpathy.github.io/2015/05/21/rnn-effectiveness/'>The Unreasonable Effectiveness of Recurrent Neural Networks</a></p><p>《Notes on Deep Learning for NLP》A J.-P. Tixier [École Polytechnique] (2018) <a href='http://t.cn/RF1Ola6' target='_blank' class='url'>http://t.cn/RF1Ola6</a> view:<a href='http://t.cn/RF1OlaN' target='_blank' class='url'>http://t.cn/RF1OlaN</a> GitHub:<a href='http://t.cn/RF1OlaX' target='_blank' class='url'>http://t.cn/RF1OlaX</a> </p><p>【文本情感转换】Learning Sentiment Memories for Sentiment Modification without Parallel Data #开源论文# #EMNLP 2018# 本文是北京大学发表于EMNLP 2018的工作，论文解决了一个非常有趣的问题——Sentiment Modification，将某种情感极性的文本转化成另外一种极性，比如将“这家店的服务很不错”（正向）变为“这家店的服务很差”（负向）。通过使用 attention weight 作为指示来去除情感词得到 neutralized context，随后根据情感词构建 sentiment memory，并通过该 memory 对 Seq2Seq 中 decoder 的 inital state 进行初始化，帮助其生成另外一种极性的文本。推荐人：tobiaslee（PaperWeekly社区用户）论文链接：<a href='http://t.cn/Rs4wimA' target='_blank' class='url'>http://t.cn/Rs4wimA</a> 源码链接：<a href='http://t.cn/Rs4wimw' target='_blank' class='url'>http://t.cn/Rs4wimw</a></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n816' class='md-header-anchor '></a>模型评估</h1><ul><li>ROC</li></ul><p><a href='https://machinelearningmastery.com/assessing-comparing-classifier-performance-roc-curves-2/'>Assessing and Comparing Classifier Performance with ROC Curves</a></p><p><a href='https://towardsdatascience.com/choosing-the-right-metric-for-machine-learning-models-part-1-a99d7d7414e4'>Choosing the Right Metric for Evaluating ML Models — Part 1</a></p><p><a href='https://towardsdatascience.com/choosing-the-right-metric-for-evaluating-machine-learning-models-part-2-86d5649a5428'>Choosing the Right Metric for Evaluating Machine Learning Models — Part 2</a></p><p>&nbsp;</p><p>&nbsp;</p><p>《Is Robustness the Cost of Accuracy? -- A Comprehensive Study on the Robustness of 18 Deep Image Classification Models》D Su, H Zhang... [IBM Research &amp; University of California, Davis &amp; MIT] (2018) <a href='http://t.cn/RDcbUIR' target='_blank' class='url'>http://t.cn/RDcbUIR</a> view:<a href='http://t.cn/RDcbUIE' target='_blank' class='url'>http://t.cn/RDcbUIE</a> GitHub:<a href='http://t.cn/RDcbUI8' target='_blank' class='url'>http://t.cn/RDcbUI8</a> </p><p>《How Complex is your classification problem? A survey on measuring classification complexity》A C. Lorena, L P. F. Garcia... [Instituto Tecnológico de Aeronáutica &amp; Universidade de São Paulo &amp; University of Bonn] (2018) <a href='http://t.cn/RDm9VNP' target='_blank' class='url'>http://t.cn/RDm9VNP</a> view:<a href='http://t.cn/RDm9VNh' target='_blank' class='url'>http://t.cn/RDm9VNh</a> GitHub:<a href='http://t.cn/RDm9VNZ' target='_blank' class='url'>http://t.cn/RDm9VNZ</a></p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n829' class='md-header-anchor '></a>稳定性</h1><p><a href='http://arxiv.org/abs/1804.11313v1'>How Robust are Deep Neural Networks?</a></p><p><a href='http://arxiv.org/abs/1804.11285v2'>Adversarially Robust Generalization Requires More Data</a></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n835' class='md-header-anchor '></a>推荐系统</h1><p><a href='https://arxiv.org/abs/1804.11192'>Explainable Recommendation: A Survey and New Perspectives</a></p><p>&nbsp;</p><h1><a name='header-n838' class='md-header-anchor '></a>变量相关性</h1><p><a href='https://mp.weixin.qq.com/s/HW29RaM9zF5yqupmNzH8MQ'>一文教你如何计算变量之间的相关性</a>（<a href='https://medium.freecodecamp.org/how-machines-make-predictions-finding-correlations-in-complex-data-dfd9f0d87889'>英文原文</a>）</p><p>&nbsp;</p><h1><a name='header-n841' class='md-header-anchor '></a>SVM</h1><p><a href='https://mp.weixin.qq.com/s/qVhRQr92gBkUjXGymkXGZw?scene=25#wechat_redirect'>用一张图理解SVM的脉络</a> by SigAI</p><p>&nbsp;</p><h1><a name='header-n844' class='md-header-anchor '></a>可视化</h1><p>【bokeh/plotly/seaborn/igraph数据可视化实战教程】’Tutorials on visualizing data using python packages like bokeh, plotly, seaborn and igraph&#39; by Neerja Doshi GitHub: <a href='https://github.com/neerjad/DataVisualization' target='_blank' class='url'>https://github.com/neerjad/DataVisualization</a> </p><p>【需要避免的数据可视化陷阱】《Data Visualization Pitfalls to Avoid》Tamara Munzner [University of British Columbia] <a href='http://t.cn/R3FVaRo' target='_blank' class='url'>http://t.cn/R3FVaRo</a> </p><p>【book】Visualization Analysis and Design</p><p><a href='http://datashader.org/index.html'>Datashader</a></p><p><a href='http://akuederle.com/matplotlib-zoomed-up-inset'>Create a zoomed-up inset plot in Matplotlib</a></p><p>【(Python)基于matplotlib的动画绘图库】’animatplot - A python package for animating plots build on matplotlib.&#39; by Tyler Makaro GitHub: <a href='http://t.cn/RDctp1r' target='_blank' class='url'>http://t.cn/RDctp1r</a> </p><p>【数据可视化速查表】《DataViz Cheatsheet | Policy Viz》by Jon Schwabish <a href='http://t.cn/RDcB4iF' target='_blank' class='url'>http://t.cn/RDcB4iF</a> </p><p>【(微软)发布的开源可视化交互定制工具】“Charticulator - Interactive Construction of Bespoke Chart Layouts” <a href='http://t.cn/Rk2bnBm' target='_blank' class='url'>http://t.cn/Rk2bnBm</a> </p><p><a href='https://pudding.cool' target='_blank' class='url'>https://pudding.cool</a></p><p>【(超大)数据集可视化工具】“Datashader - Turns even the largest data into images, accurately.” by Bokeh <a href='http://t.cn/Rktfv4A' target='_blank' class='url'>http://t.cn/Rktfv4A</a> GitHub:<a href='http://t.cn/RGqoEvG' target='_blank' class='url'>http://t.cn/RGqoEvG</a> </p><p>【Jupyter Notebook交互可视化】《Interactive Visualizations In Jupyter Notebook》by 5agado <a href='http://t.cn/RFAnzCg' target='_blank' class='url'>http://t.cn/RFAnzCg</a> pdf:<a href='http://t.cn/RFAnzC1' target='_blank' class='url'>http://t.cn/RFAnzC1</a> </p><p>【调色版搜索引擎】“Picular - Google, but for colors”   <a href='http://t.cn/RFqEfbV' target='_blank' class='url'>http://t.cn/RFqEfbV</a> </p><p>【数据可视化：最佳实践与应用基础】《Data Visualization — Best Practices and Foundations》by Cameron Chapman <a href='http://t.cn/RsHEqah' target='_blank' class='url'>http://t.cn/RsHEqah</a> pdf:<a href='http://t.cn/RsHEqXg' target='_blank' class='url'>http://t.cn/RsHEqXg</a> </p><p>&nbsp;</p><h1><a name='header-n859' class='md-header-anchor '></a>机器学习</h1><p>【Andrew NG的《Machine Learning Yearning》中文翻译版】via:xiaqunfeng <a href='http://t.cn/Rgb1s1E' target='_blank' class='url'>http://t.cn/Rgb1s1E</a> GitHub:<a href='http://t.cn/Rgb1s13' target='_blank' class='url'>http://t.cn/Rgb1s13</a> </p><p>【决策树(可视化)解析】《How decision trees work》by  <a href='http://t.cn/RgWa6DI' target='_blank' class='url'>http://t.cn/RgWa6DI</a> Slides:<a href='http://t.cn/RgWWJ7V' target='_blank' class='url'>http://t.cn/RgWWJ7V</a> GitHub:<a href='http://t.cn/RgWWJ7f' target='_blank' class='url'>http://t.cn/RgWWJ7f</a> <a href='http://t.cn/RgWWTDR' target='_blank' class='url'>http://t.cn/RgWWTDR</a> </p><p><a href='https://medium.com/pit-ai-technologies/https-medium-com-pit-ai-technologies-the-black-swans-in-your-market-neutral-portfolios-part-1-e17fc18a42a7'>Pearson’s Correlation, Linear Regression, And Why ‘Beta’ Grossly Underestimates Portfolio Sensitivity To Market Returns</a></p><p>&nbsp;</p><h1><a name='header-n864' class='md-header-anchor '></a>特征工程</h1><p>【书稿：特征工程与特征选择——实用预测模型方法】《Feature Engineering and Selection: A Practical Approach for Predictive Models》by Max Kuhn, Kjell Johnson <a href='http://www.feat.engineering/' target='_blank' class='url'>http://www.feat.engineering/</a> Code and Resources GitHub:<a href='http://t.cn/RB5i506' target='_blank' class='url'>http://t.cn/RB5i506</a></p><p>【(featuretools)自动特征工程实例】“Introduction: Automated Feature Engineering” <a href='http://t.cn/RrVjw5w' target='_blank' class='url'>http://t.cn/RrVjw5w</a> </p><p>【用CNN处理结构化银行客户数据】《Convolutional Neural Network on a structured bank customer data》by Carson Yan <a href='http://t.cn/Rsuy5Xr' target='_blank' class='url'>http://t.cn/Rsuy5Xr</a> pdf:<a href='http://t.cn/Rsuy5Xd' target='_blank' class='url'>http://t.cn/Rsuy5Xd</a> </p><p>&nbsp;</p><h1><a name='header-n869' class='md-header-anchor '></a>数学</h1><p>【数学相关资源大列表】’Awesome Math - A curated list of awesome mathematics resources&#39; by Siraj Raval GitHub: <a href='http://t.cn/RBskhH2' target='_blank' class='url'>http://t.cn/RBskhH2</a> </p><p>【什么是好的数学？】《What is good mathematics?》T Tao (2007) <a href='http://t.cn/RgWQ6PH' target='_blank' class='url'>http://t.cn/RgWQ6PH</a> 翻译版(via:卢昌海):<a href='http://t.cn/RgWQ6PO' target='_blank' class='url'>http://t.cn/RgWQ6PO</a> <a href='http://t.cn/RgWQ6P9' target='_blank' class='url'>http://t.cn/RgWQ6P9</a> <a href='http://t.cn/RgWQ6Pp' target='_blank' class='url'>http://t.cn/RgWQ6Pp</a> </p><p>ACM SIGACT News在1996年发布的这篇理论计算机“开卷救命稻草”共10页，我截图了前三页，看看你能翻过几页[允悲]全文PDF可以看这里：<a href='http://t.cn/RDkqK3C' target='_blank' class='url'>http://t.cn/RDkqK3C</a> </p><p>数学之美：前1,000,000个整数，表示成质数因子二进制向量(1,000,000x78,628二进制矩阵)，用UMAP降维聚类得到的可视化结果，展现出的结构耐人寻味 GitHub:<a href='http://t.cn/RkpkOuo' target='_blank' class='url'>http://t.cn/RkpkOuo</a> via:John Williamson </p><p>【AI知识分类关系图】《AI Knowledge Map: How To Classify AI Technologies》by Francesco Corea <a href='http://t.cn/RkTCdXB' target='_blank' class='url'>http://t.cn/RkTCdXB</a> </p><p>【音乐的数学基础】《The Mathematical Foundations of Music》by Karl Hiner Part1:<a href='http://t.cn/RkFBKN6' target='_blank' class='url'>http://t.cn/RkFBKN6</a> Part2:<a href='http://t.cn/RkFBKNK' target='_blank' class='url'>http://t.cn/RkFBKNK</a> </p><p>【写给程序员的矩阵乘法基础】《A Programmer’s Intuition for Matrix Multiplication》 <a href='http://t.cn/RcSNYWs' target='_blank' class='url'>http://t.cn/RcSNYWs</a> </p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n879' class='md-header-anchor '></a>Coding</h1><p><a href='https://hackernoon.com/6-simple-tips-on-how-to-start-writing-clean-code-d66c241aa268?source=email-6cc0f03343c7-1524268394193-digest.reader------1-3------------------e29e0da64f89-5&sectionName=recommended'>6 Simple Tips on How to Start Writing Clean Code</a></p><p><a href='https://mp.weixin.qq.com/s/rEA16k6zAqhPhWOaHr20YQ'>如何写一手漂亮的模型：面向对象编程的设计原则综述</a></p><p><a href='https://github.com/xingshaocheng/architect-awesome'>后端架构师技术图谱</a></p><p>《Competitive Programmer’s Handbook》 by Antti Laaksonen (2017) <a href='http://t.cn/RXb3Lxv' target='_blank' class='url'>http://t.cn/RXb3Lxv</a> </p><p>【最省心的程序开发环境：在线IDE大列表】’Awesome Online IDE Awesome - A list of awesome online development environments&#39; by Steven GitHub: <a href='http://t.cn/RBmS8Fb' target='_blank' class='url'>http://t.cn/RBmS8Fb</a> </p><p>【Tensorflow令人困惑的方方面面】《Tensorflow: The Confusing Parts》by Jacob Buckman Part1:<a href='http://t.cn/RrSqOjq' target='_blank' class='url'>http://t.cn/RrSqOjq</a> 
【Tensorflow令人困惑的方方面面(二)】《Tensorflow: The Confusing Parts (2) | Buckman&#39;s Homepage》by Jacob Buckman <a href='http://t.cn/EvOUHeG' target='_blank' class='url'>http://t.cn/EvOUHeG</a> </p><ul><li><p>HTML + CSS</p><ul><li><a href='https://learn.shayhowe.com/html-css/' target='_blank' class='url'>https://learn.shayhowe.com/html-css/</a></li><li><a href='http://www.w3school.com.cn/index.html' target='_blank' class='url'>http://www.w3school.com.cn/index.html</a></li><li><a href='http://zh.learnlayout.com/index.html' target='_blank' class='url'>http://zh.learnlayout.com/index.html</a></li></ul></li></ul><p><a href='https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650747129&idx=3&sn=4bef0dca7ed6d6cfc4994f897d77b75b&chksm=871af487b06d7d91434b80479d91cf8ab7f5cc006948efbcb573ff81eb1c0b696429081cc86b&token=1035066894&lang=zh_CN#rd'>入门 | 敲黑板！你和GitHub高手就差这三条规则······</a></p><p><a href='https://medium.freecodecamp.org/learn-to-code-the-hard-way-65dece5b0005'>Learn to code, the hard way</a></p><p>&nbsp;</p><h1><a name='header-n899' class='md-header-anchor '></a>Python</h1><p><a href='https://realpython.com/numpy-array-programming/'>【NumPy Arrays编程实例详解】《Look Ma, No For-Loops: Array Programming With NumPy》by Brad Solomon</a></p><p><a href='https://github.com/shik3519/machine-learning/blob/master/tutorials/003-python-basics-numpy-regex.ipynb'>003-python-basics-numpy-regex.ipynb</a></p><p><a href='https://realpython.com/python-git-github-intro/'>Introduction to Git and GitHub for Python Developers</a></p><p><a href='https://medium.freecodecamp.org/python-collection-of-my-favorite-articles-8469b8455939'>The best of Python: a collection of my favorite articles from 2017 and 2018 (so far)</a></p><p><a href='http://tomaugspurger.github.io/modern-1-intro.html'>&quot;Modern Pandas&quot; by Tom Augspurger</a></p><p><a href='https://github.com/cuttlefishh/python-for-data-analysis'>An introduction to data science using Python and Pandas with Jupyter notebooks.</a></p><p><a href='https://github.com/mm-mansour/Fast-Pandas'>Fast-Pandas</a></p><blockquote><p>Benchmark for different operations in pandas against various dataframe sizes.</p><p>这哥们厉害了，专门做 pandas 里一些相同实现功能操作下的性能对比。</p></blockquote><ul><li><p>Python 环境</p><p><img src='https://imgs.xkcd.com/comics/python_environment.png' alt='' referrerPolicy='no-referrer' /></p></li></ul><p><a href='https://speakerd.s3.amazonaws.com/presentations/530206f2752e4260bb96be0dad212848/PyCon2018_Talk__2_.pdf'>7 Strategies for Optimizing Your Numerical Code</a></p><p><a href='https://github.com/ssanderson/foundations-of-numerical-computing'>Foundations of Numerical Computing</a>【数值计算基础】</p><p>【高效使用NumPy】《Using NumPy efficiently》by cournape <a href='http://t.cn/R3MdQ5h' target='_blank' class='url'>http://t.cn/R3MdQ5h</a> </p><p><a href='https://github.com/jackfrued/Python-100-Days'>Python - 100天从新手到大师</a></p><p><a href='https://github.com/zhiwehu/Python-programming-exercises'>100+ Python challenging programming exercises</a></p><p>【面向Numpy用户的PyTorch数值计算指南(速查)】’PyTorch for Numpy users.&#39; by Kentaro Wada GitHub: <a href='http://t.cn/R1rUdJd' target='_blank' class='url'>http://t.cn/R1rUdJd</a> </p><p><a href='https://blog.usejournal.com/python-vs-and-r-for-data-science-833b48ccc91d'>Python vs (and) R for Data Science</a></p><p>【Python异常检测工具包】’Python Outlier Detection (PyOD) - A Python Toolkit for Outlier Detection (Anomaly Detection)&#39; by Yue Zhao GitHub: <a href='http://t.cn/R38DVt5' target='_blank' class='url'>http://t.cn/R38DVt5</a> </p><p>【面向科学计算和计算机视觉的Python代码运行调试工具箱】“Box-X - Tool-box for Efficient Build and Debug in Python” GitHub:<a href='http://t.cn/Rrz38IZ' target='_blank' class='url'>http://t.cn/Rrz38IZ</a> </p><p>【(Python3)小巧<em>可用</em>的Google搜索库】’gle - A tiny but functional google searcher lib.&#39; by Iury de oliveira gomes figueiredo GitHub: <a href='http://t.cn/RdWVrG7' target='_blank' class='url'>http://t.cn/RdWVrG7</a> </p><p>【Python编程入门“必读”指南】《Essential Reads for Any Python Programmer》by salimm <a href='http://t.cn/Rde86uW' target='_blank' class='url'>http://t.cn/Rde86uW</a> </p><p>【Python 3教学课程(Jupyter notebooks)】’Jupyter notebooks for teaching/learning Python 3&#39; by Jerry Pussinen GitHub: <a href='http://t.cn/RgyGkcF' target='_blank' class='url'>http://t.cn/RgyGkcF</a> </p><p>【Kaggle的免费Python教程】“Python - Learn the most important language for Data Science | Kaggle”  <a href='http://t.cn/RgMaxx4' target='_blank' class='url'>http://t.cn/RgMaxx4</a> </p><p>【Python“黑魔法”实现集锦】’sorcery - Dark magic delights in Python&#39; by Alex Hall GitHub: <a href='http://t.cn/RgYSIU8' target='_blank' class='url'>http://t.cn/RgYSIU8</a></p><p>【面向科学家的Python编程指南】《Python for scientists who code: An opinionated introduction》by neurohackweek <a href='http://t.cn/ReGm09s' target='_blank' class='url'>http://t.cn/ReGm09s</a> </p><p>【用哈利波特世界解释Python语言特性】’Awesome Python features explained using the world of Harry Potter&#39; by zotroneneis GitHub: <a href='http://t.cn/RD221gr' target='_blank' class='url'>http://t.cn/RD221gr</a> </p><p>&#39;关于Python的面试题&#39; by hackerxu GitHub: <a href='http://t.cn/Ryi9R1z' target='_blank' class='url'>http://t.cn/Ryi9R1z</a> </p><p><a href='http://mortada.net/easily-profile-python-code-in-jupyter.html'>Easily Profile Python Code in Jupyter</a></p><p>&nbsp;</p><p>【Python图像操作函数库】’imutils - A series of convenience functions to make basic image processing operations such as translation, rotation, resizing, skeletonization, and displaying Matplotlib images easier with OpenCV and Python.&#39; by Adrian Rosebrock GitHub: <a href='http://t.cn/R5NapJv' target='_blank' class='url'>http://t.cn/R5NapJv</a></p><p>【Python进化算法工具箱】’Evolute - Evolutionary algorithm toolbox&#39; by csxeba GitHub: <a href='http://t.cn/RktqA5N' target='_blank' class='url'>http://t.cn/RktqA5N</a> </p><p>【fastai出品效果很赞的(Python)进度条组件(Jupyter Notebook/console可用)】’fast_progress - Simple and flexible progress bar for Jupyter Notebook and console&#39; by fastai GitHub: <a href='http://t.cn/Rka9a1E' target='_blank' class='url'>http://t.cn/Rka9a1E</a> </p><p>【23段代码掌握Pandas主要用法】《23 great Pandas codes for Data Scientists》by George Seif <a href='http://t.cn/Rk0OFL9' target='_blank' class='url'>http://t.cn/Rk0OFL9</a> pdf:<a href='http://t.cn/Rk0OFLo' target='_blank' class='url'>http://t.cn/Rk0OFLo</a> </p><p><a href='https://github.com/s0md3v/Photon' target='_blank' class='url'>https://github.com/s0md3v/Photon</a> 爬虫</p><p>【Python为啥那么慢？GIL &amp; 解释非编译 &amp; 动态类型】《Why is Python so slow?》by Anthony Shaw <a href='http://t.cn/RgYJafK' target='_blank' class='url'>http://t.cn/RgYJafK</a> pdf:<a href='http://t.cn/RkqYdBP' target='_blank' class='url'>http://t.cn/RkqYdBP</a> </p><p>【指南：如何用Python代替Bash脚本】’Guide on using using python for administrative scripting&#39; by Aaron Christianson GitHub: <a href='http://t.cn/Rkcw8PR' target='_blank' class='url'>http://t.cn/Rkcw8PR</a> </p><p>【A-Z Python编程技巧总结】《An A-Z of useful Python tricks》by Peter Gleeson <a href='http://t.cn/RFbYlD1' target='_blank' class='url'>http://t.cn/RFbYlD1</a> pdf:<a href='http://t.cn/RFbYlDr' target='_blank' class='url'>http://t.cn/RFbYlDr</a> </p><p>【Facebook出品：安全的大规模Python代码重构工具】“Bowler · Safe code refactoring for modern Python” by Facebook Incubator <a href='http://t.cn/RFxuQoQ' target='_blank' class='url'>http://t.cn/RFxuQoQ</a> GitHub:<a href='http://t.cn/RFxuQoH' target='_blank' class='url'>http://t.cn/RFxuQoH</a> </p><ul><li>Python专业性能优化技巧：用 lru_cache LRU缓存修饰器实现加速 </li></ul><p>【这些Python代码技巧，你肯定还不知道】被人工智能捧红的 Python 已是一种发展完善且非常多样化的语言，其中肯定有一些你尚未发现的功能。本文或许能够让你学到一些新技巧。<a href='http://t.cn/RFBcMNH' target='_blank' class='url'>http://t.cn/RFBcMNH</a> </p><p>【Python程序采样可视化性能分析工具】’Py-Spy: A sampling profiler for Python programs.&#39; by Ben Frederickson GitHub: <a href='http://t.cn/RsLecxs' target='_blank' class='url'>http://t.cn/RsLecxs</a> </p><p>【Python轻量命令行交互shell应用开发框架】’python-nubia - A command-line and interactive shell framework.&#39; by Facebook Incubator GitHub: <a href='http://t.cn/Rs5SQtJ' target='_blank' class='url'>http://t.cn/Rs5SQtJ</a> </p><p>【Scipy在线教程】”Scipy Lecture Notes - One document to learn numerics, science, and data with Python” <a href='http://t.cn/RyCYM4I' target='_blank' class='url'>http://t.cn/RyCYM4I</a> pdf:<a href='http://t.cn/RyCYM4f' target='_blank' class='url'>http://t.cn/RyCYM4f</a> Github:<a href='http://t.cn/RyCYM4M' target='_blank' class='url'>http://t.cn/RyCYM4M</a> </p><p>【用Python创建动态图】《How to Create Animated Graphs in Python》by Viviane <a href='http://t.cn/RsSdWqv' target='_blank' class='url'>http://t.cn/RsSdWqv</a> pdf:<a href='http://t.cn/RsSdWGc' target='_blank' class='url'>http://t.cn/RsSdWGc</a> </p><p>All algorithms implemented in Python (for education) |  <a href='http://t.cn/RtIpHx7' target='_blank' class='url'>http://t.cn/RtIpHx7</a>   <a href='http://t.cn/RINyM8z' target='_blank' class='url'>http://t.cn/RINyM8z</a> </p><p><a href='https://mp.weixin.qq.com/s/WntwsT53KlGgBLzxJUqJFA'>你想要的Python编程技巧，我都给你整理好了</a></p><p>【Python实例教学：lambda, map 和 filter】《lambda, map and filter in Python》by Rupesh Mishra <a href='http://t.cn/EPGuOXT' target='_blank' class='url'>http://t.cn/EPGuOXT</a></p><p>&nbsp;</p><h2><a name='header-n954' class='md-header-anchor '></a>PyTorch</h2><p>【PyTorch指南：使用、思考、技巧与陷阱】’Grokking PyTorch - The Hitchiker&#39;s Guide to PyTorch&#39; by Kai Arulkumaran GitHub: <a href='http://t.cn/Ref3nMu' target='_blank' class='url'>http://t.cn/Ref3nMu</a> </p><p>&nbsp;</p><h1><a name='header-n957' class='md-header-anchor '></a>Shell</h1><p><a href='https://medium.com/@kadek/command-line-tricks-for-data-scientists-c98e0abe5da'>数据科学家命令行技巧集</a></p><p>【纯bash脚本圣经：用bash代替外部工具】’pure bash bible - A collection of pure bash alternatives to external processes.&#39; by Dylan Araps GitHub: <a href='http://t.cn/RBlgpd8' target='_blank' class='url'>http://t.cn/RBlgpd8</a> </p><p>【把命令行操作过程录制成gif】’Terminalizer - Record your terminal and generate animated gif images&#39; by Mohammad Fares GitHub: <a href='http://t.cn/ReIuyJz' target='_blank' class='url'>http://t.cn/ReIuyJz</a> </p><h2><a name='header-n961' class='md-header-anchor '></a>Emacs</h2><h2><a name='header-n962' class='md-header-anchor '></a>Vim</h2><p>【寓教于乐的Vim使用教程小游戏】“PacVim - a game that teaches you vim commands” by Jamal Moon GitHub:<a href='http://t.cn/RZTNrvW' target='_blank' class='url'>http://t.cn/RZTNrvW</a> </p><h2><a name='header-n964' class='md-header-anchor '></a>正则表达式</h2><p><a href='https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650740934&idx=1&sn=b9c01afdf944fa4a44d53a99b9d3e92e'>数据科学入门必读：如何使用正则表达式？</a> <a href='https://www.dataquest.io/blog/regular-expressions-data-scientists/'>原文链接</a></p><h1><a name='header-n966' class='md-header-anchor '></a>Jupyter</h1><p><a href='http://www.nirantk.in/best-of-jupyter/'>Making the best of Jupyter</a>: Tips, Tricks, Best Practices with Sample Code for Productivity Boost —</p><p><a href='https://paulromer.net/jupyter-mathematica-and-the-future-of-the-research-paper/'>Jupyter, Mathematica, and the Future of the Research Paper</a></p><p>【打造出版级的Python Notebooks】《<a href='http://blog.juliusschulz.de/blog/ultimate-ipython-notebook'>Making publication ready Python Notebooks</a>》</p><p>【Jupyter Notebooks多参配置、运行、分析工具】“papermill - tool for parameterizing, executing, and analyzing Jupyter Notebooks.” GitHub:<a href='http://t.cn/RktcDT2' target='_blank' class='url'>http://t.cn/RktcDT2</a> </p><p>【Jupyter notebooks的Markdown语法速查】《Markdown for Jupyter notebooks cheatsheet》by Inge Halilovic <a href='http://t.cn/RkCAStI' target='_blank' class='url'>http://t.cn/RkCAStI</a> pdf:<a href='http://t.cn/RkCAStc' target='_blank' class='url'>http://t.cn/RkCAStc</a> </p><p>【Jupyter Notebooks下的Python可视化调试器PixieDebugger】《The Visual Python Debugger for Jupyter Notebooks You’ve Always Wanted》by David Taieb <a href='http://t.cn/RrsPy0r' target='_blank' class='url'>http://t.cn/RrsPy0r</a> pdf:<a href='http://t.cn/RkC23Ql' target='_blank' class='url'>http://t.cn/RkC23Ql</a> <a href='http://t.cn/RkC2gaM' target='_blank' class='url'>http://t.cn/RkC2gaM</a> </p><p>【基于Jekyll/Jupyter的在线写书平台】’Textbooks with Jupyter and Jekyll - A template repository to quickly build an online textbook using Jekyll&#39; by Chris Holdgraf GitHub: <a href='http://t.cn/Rgr0eMM' target='_blank' class='url'>http://t.cn/Rgr0eMM</a> </p><p>【JupyterCon摘要：关于Jupyter Notebooks的新鲜事儿】《The Coolest Things I Learned at JupyterCon》by caitlinhudon <a href='http://t.cn/RFAaZxs' target='_blank' class='url'>http://t.cn/RFAaZxs</a> </p><p>【Jupyter Notebook交互可视化】《Interactive Visualizations In Jupyter Notebook》by 5agado <a href='http://t.cn/RFAnzCg' target='_blank' class='url'>http://t.cn/RFAnzCg</a> pdf:<a href='http://t.cn/RFAnzC1' target='_blank' class='url'>http://t.cn/RFAnzC1</a> </p><p>【Jupyter Notebooks的diffing/merging比较/合并组件】“nbdime – diffing and merging of Jupyter Notebooks” <a href='http://t.cn/RFA1JHS' target='_blank' class='url'>http://t.cn/RFA1JHS</a> </p><p>【Jupytext：可以让Jupyter读写纯文本文件(Julia，Python，R scripts，Markdown或R Markdown文档)的插件】《Introducing Jupytext》by Marc Wouts <a href='http://t.cn/RsHdoJl' target='_blank' class='url'>http://t.cn/RsHdoJl</a> pdf:<a href='http://t.cn/RsHdoJQ' target='_blank' class='url'>http://t.cn/RsHdoJQ</a> GitHub:<a href='http://t.cn/RsHdoJR' target='_blank' class='url'>http://t.cn/RsHdoJR</a> </p><p>【用ag-Grid作为Jupyter数据表格显示方案】《Harnessing the power of ag-Grid in Jupyter》by Olivier Borderies <a href='http://t.cn/EvIXCjs' target='_blank' class='url'>http://t.cn/EvIXCjs</a> </p><p><strong>A Jupyter extensions that turns notebooks into web applications.</strong> <a href='https://github.com/oschuett/appmode' target='_blank' class='url'>https://github.com/oschuett/appmode</a></p><p>&nbsp;</p><h1><a name='header-n981' class='md-header-anchor '></a>Time series analysis</h1><p><a href='https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-9-time-series-analysis-in-python-a270cb05e0b3'>Open Machine Learning Course. Topic 9. Time series analysis in Python</a></p><p>【(Python &amp; R) Prophet时序预测实践】《<a href='https://www.analyticsvidhya.com/blog/2018/05/generate-accurate-forecasts-facebook-prophet-python-r/'>Time Series Forecasts using Facebook&#39;s Prophet (with Python &amp; R codes)</a>》by Ankit Choudhary</p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n986' class='md-header-anchor '></a>Black Holes</h1><p>&nbsp;</p><p><a href='https://www.black-holes.org/' target='_blank' class='url'>https://www.black-holes.org/</a></p><p>&nbsp;</p><ol start='' ><li>每个打算写作一部比较重要著作的人都应该善待自己，每写完一点都不要克制自己任何对继续写作不会有不良影响的想法。</li><li>如果你想谈谈自己已经写完的部分，那是可以的。但是，写作过程中不要将已写完的部分读给别人听。你由此获得的每一次满足都将妨碍你的写作速度。如果遵循这个原则，想说给别人听的欲望会越积越多，但那最终会成为圆满完成作品的动力。</li><li>进入写作状态时要避免接触日常平庸的事情，带有细细声响的不完全宁静是难以忍受的。相反，一段肖邦或李斯特的练习曲或工作时发出的絮絮嘈杂声，则与深夜感受到的宁静同样重要。如果说后者使内在听觉变得敏锐，那么，前者就会成为文体的试金石，文体一旦出现，它就会淹没那些外在的声音。</li><li>不要随意使用写作工具。刻板地坚持使用某种纸和笔墨是有好处的。这不是奢侈，但是，使这样的器具应有尽有是必须的。</li><li>不要让你的任何思想隐姓埋名地流逝而过，要在小本子里仔细记录下你的每一个思想，就像当局登记外国人那样严格。</li><li>让你的笔在灵感面前矜持些，灵感会借助磁力将笔吸引到自己身边来。对于是否马上写下突然想到的东西，你越是持审慎的态度，它就越会以成熟的样态走向你。演说征服思想，但文字统治思想。</li><li>永远不要因为你没有什么可写了而停止写作，这是文学荣耀的一条戒律。只有必须遵守的时辰（如进餐、约会）或者在作品完成之时，才可以中止写作。</li><li>工工整整地抄写你已写好的东西，以此填补灵感暂时的空白，直觉将会在此过程中觉醒。</li><li>每天至少写一点 —— 但也可能若干星期。</li><li>从不要将没有通宵达旦写作过的作品视为完美的。</li><li>不要再你熟悉的书房写一部作品的结尾，你在那里可能找不到写结尾的勇气。</li><li>写作的几个阶段：思想 —— 风格 —— 文字。眷写的意义在于：必须眷写清楚和漂亮。思想扼杀灵感；风格束缚思想；文字报偿风格。</li><li>写成的作品是构想死去时的面容。</li></ol><p>&nbsp;</p><p>“作家写作技巧十三则” —— 《单行道》本雅明</p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n1021' class='md-header-anchor '></a>强化学习</h1><p><a href='https://github.com/suragnair/alpha-zero-general'>Alpha Zero General (any game, any framework!)</a></p><p><a href='https://mp.weixin.qq.com/s/gwPUeoaHuzuv8VuT6JiEcA'>呵，我复现一篇深度强化学习论文容易吗</a></p><p><a href='https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8'>Reinforcement Learning from scratch</a></p><p><a href='https://mp.weixin.qq.com/s/NuBcrNJDRDoEmFTpK8-ayQ'>「AlphaGo 之父」David Silver最新演讲，传授强化学习的十大原则</a></p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n1028' class='md-header-anchor '></a>PhD thesis</h1><p>(Doctor Thesis)《Neural Networks Regularization Through Representation Learning》S Belharbi [Normandie Université] (2018) <a href='http://t.cn/Rgmvw2i' target='_blank' class='url'>http://t.cn/Rgmvw2i</a> </p><p>&nbsp;</p><h1><a name='header-n1031' class='md-header-anchor '></a>Kaggle &amp; Competitions for DS</h1><ul><li><a href='https://www.kaggle.com/c/data-science-bowl-2018/discussion/54741'>(Kaggle)2018 Data Science Bowl夺冠方案分享</a>（<a href='https://mp.weixin.qq.com/s/0aXic7yagNMnDIA4EdFczg'>2018 Data Science Bowl 第一名方案新鲜出炉，鉴定细胞核新技能 get</a>）</li><li>【Kaggle Data Science Bowl 2018第四名方案分享】《<a href='https://www.kaggle.com/c/data-science-bowl-2018/discussion/55118'>Our solution, 4th place on the private LB | Kaggle</a>》by Dmytro Poplavskiy</li><li>【Kaggle Google地标检索比赛第一名方案】《1st Place Solution Summary: CVSSP &amp; Visual Atoms (0.627) | Google Landmark Retrieval Challenge》by anokas <a href='http://t.cn/R1i7Xiy' target='_blank' class='url'>http://t.cn/R1i7Xiy</a> </li><li>【路透社新闻数据集“深度”探索性分析(词向量/情感分析)】《<a href='https://www.kaggle.com/hoonkeng/deep-eda-word-embeddings-sentiment-analysis/notebook'>DEEP EDA (Word Embeddings &amp; Sentiment Analysis) | Kaggle</a>》</li><li>【Kaggle Google地标检索比赛第14名方案分享】《14th place solution for Kaggle Google Landmark Retrieval Challenge》by Dmytro Mishkin <a href='http://t.cn/R1nQriY' target='_blank' class='url'>http://t.cn/R1nQriY</a></li><li>【Owen Zhang访谈：Kaggle制胜的秘密】《How To Win Kaggle: Hear Owen Zhang Spill His Secrets - YouTube》 <a href='http://t.cn/RBzPcUF' target='_blank' class='url'>http://t.cn/RBzPcUF</a> <a href='http://t.cn/RBzPcyg' target='_blank' class='url'>http://t.cn/RBzPcyg</a> </li></ul><p>【IJCAI 2018 CTR估计比赛前三方案分享】’This 2018 IJCAI alimama Top3 Code&#39; by luobinli GitHub: <a href='http://t.cn/RBhwoQN' target='_blank' class='url'>http://t.cn/RBhwoQN</a> </p><p>【IJCAI 2018 CTR估计比赛前二方案分享】复赛第二名单模型方案，没有特征选择没有调参单模型857个特征 <a href='http://t.cn/RBhVAah' target='_blank' class='url'>http://t.cn/RBhVAah</a></p><p>【IJCAI 2018 CTR估计比赛冠军方案分享】’This 2018 IJCAI alimama Top1 solution&#39; GitHub:  <a href='http://t.cn/RBcbJId' target='_blank' class='url'>http://t.cn/RBcbJId</a></p><p><a href='https://www.datasciencecentral.com/profiles/blogs/how-to-compete-for-zillow-prize-at-kaggle'>How to Compete for Zillow Prize at Kaggle</a></p><p>【Lyft感知挑战赛第四名(最快)方案】&quot;Lyft Perception Challenge | Self-Driving Cars Lab&quot;  <a href='http://t.cn/RBtrJcE' target='_blank' class='url'>http://t.cn/RBtrJcE</a> <a href='http://t.cn/RBtrMdw' target='_blank' class='url'>http://t.cn/RBtrMdw</a> GitHub:<a href='http://t.cn/RBJnlug' target='_blank' class='url'>http://t.cn/RBJnlug</a></p><p>【2018对抗挑战优胜经验分享】《Playing with adversarial attacks on Machines Can See 2018 competition》by snakers41 <a href='http://t.cn/RBMaq4y' target='_blank' class='url'>http://t.cn/RBMaq4y</a>  GitHub:<a href='http://t.cn/RBMlfBH' target='_blank' class='url'>http://t.cn/RBMlfBH</a></p><p>【Kaggle植物幼苗图像分类挑战赛冠军方案分享】《Kaggle #1 Winning Approach for Image Classification Challenge》by Kumar Shridhar <a href='http://t.cn/RBssjf6' target='_blank' class='url'>http://t.cn/RBssjf6</a> </p><p><a href='http://blog.kaggle.com/2018/06/19/tales-from-my-first-year-inside-the-head-of-a-recent-kaggle-addict/'>Profiling Top Kagglers: Martin Henze (AKA Heads or Tails), World&#39;s First Kernels Grandmaster</a></p><p>【Kaggle数据科学词汇表】《Data Science Glossary on Kaggle !!》by sban <a href='http://t.cn/Rdx72Cn' target='_blank' class='url'>http://t.cn/Rdx72Cn</a> </p><p>【Kaggle比赛优胜方案汇总】《Winning solutions of kaggle competitions》by SRK <a href='http://t.cn/Rdkj3Co' target='_blank' class='url'>http://t.cn/Rdkj3Co</a> </p><p>【Kaggle比赛实战教程(Pandas, Matplotlib, XGBoost/Colab)】《Kaggle Challenge (LIVE) - YouTube》by Siraj Raval <a href='http://t.cn/ReIJOX0' target='_blank' class='url'>http://t.cn/ReIJOX0</a> GitHub:<a href='http://t.cn/ReIJOXK' target='_blank' class='url'>http://t.cn/ReIJOXK</a> “Kaggle比赛实战教程” #bilibili#搬运：<a href='http://t.cn/ReI1WvT' target='_blank' class='url'>http://t.cn/ReI1WvT</a></p><p>【Kaggle看照片猜相机比赛心得分享】《IEEE’s camera identification challenge — different approach to teaming up》by Dbrain <a href='http://t.cn/Rkz5Q9y' target='_blank' class='url'>http://t.cn/Rkz5Q9y</a> pdf:<a href='http://t.cn/Rkz5Q9L' target='_blank' class='url'>http://t.cn/Rkz5Q9L</a> </p><p>【腾讯2018广告算法挑战赛第三名方案】’This repository maintains codes for tencent advertisement algorithm competition 2018. Our codes ranked the 3rd place in the final round.&#39;  GitHub: <a href='http://t.cn/Rk9sWy3' target='_blank' class='url'>http://t.cn/Rk9sWy3</a> </p><p><a href='http://benanne.github.io/2014/04/05/galaxy-zoo.html'>My solution for the Galaxy Zoo challenge</a>APRIL 05, 2014 </p><p>【Kaggle在线分类广告需求预测比赛优胜方案分享：如何将分类、数字、图像和文本特征集成到单个网络中，无需堆叠杀入前10名】《”Dance with Ensemble&quot; Sharing Thread | Kaggle》by Little Boat <a href='http://t.cn/RFpQg9O' target='_blank' class='url'>http://t.cn/RFpQg9O</a> </p><p>【Kaggle Home Credi违约风险预测比赛优胜方案】《Overview of the 5th solution [+0.004 to CV/Private LB of your model] | Kaggle》by narsil <a href='http://t.cn/RFjpngW' target='_blank' class='url'>http://t.cn/RFjpngW</a> </p><p>【Kaggle Google AI Open Images竞赛第15名方案】’Code for 15th place in Kaggle Google AI Open Images - Object Detection Track&#39; by ZFTurbo GitHub: <a href='http://t.cn/RF1jnis' target='_blank' class='url'>http://t.cn/RF1jnis</a> </p><p>【Kaggle Home Credit违约风险预测比赛夺冠方案】《1st Place Solution | Kaggle》by Bojan Tunguz <a href='http://t.cn/RFsoHgv' target='_blank' class='url'>http://t.cn/RFsoHgv</a> </p><p>Kaggle | Winner Interview | Particle Tracking Challenge first runner-up, Pei-Lien Chou 一位台湾小哥的励志鸡汤。。。 <a href='http://blog.kaggle.com/2018/09/14/pei-lien-chou/' target='_blank' class='url'>http://blog.kaggle.com/2018/09/14/pei-lien-chou/</a></p><p><a href='https://github.com/moneyDboat/data_grand'>达观杯文本智能处理挑战赛 Top10解决方案</a></p><p>第三届阿里云安全算法挑战赛冠军代码 <a href='https://github.com/poteman/Alibaba-3rd-Security-Algorithm-Challenge' target='_blank' class='url'>https://github.com/poteman/Alibaba-3rd-Security-Algorithm-Challenge</a></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><ul><li>DataSet</li></ul><p>【开放数据集大列表】《Open Datasets | Skymind》 <a href='http://t.cn/RFAoweW' target='_blank' class='url'>http://t.cn/RFAoweW</a> </p><p>【数据集搜索引擎：Google启动新搜索引擎帮助科学家找到需要的数据集】《Dataset Search: Google launches new search engine to help scientists find datasets | The Verge》 <a href='http://t.cn/RsAHucP' target='_blank' class='url'>http://t.cn/RsAHucP</a> ref:《Making it easier to discover datasets》 <a href='https://www.blog.google/products/search/making-it-easier-discover-datasets/' target='_blank' class='url'>https://www.blog.google/products/search/making-it-easier-discover-datasets/</a> Dataset Search:<a href='http://t.cn/RsAHuch' target='_blank' class='url'>http://t.cn/RsAHuch</a></p><h1><a name='header-n1072' class='md-header-anchor '></a>GWs news</h1><ul><li>Daniel George  获奖的新闻采访：<a href='https://brucelandonblog.wordpress.com/2018/03/14/http-blog-wolfram-com-2018-03-14-user-research-deep-learning-for-gravitational-wave-detection-with-the-wolfram-language/'>User Research: Deep Learning for Gravitational Wave Detection with the Wolfram Language</a></li><li><a href='https://images.nvidia.com/content/pdf/ncsa-gravity-group-iter-success-story.pdf'>SEEING GRAVITY IN REAL-TIME WITH DEEP LEARNING</a> </li><li>We are delighted to see, for example, how the LIGO Collaboration, awarded the <a href='https://www.nobelprize.org/nobel_prizes/physics/laureates/2017/press.html'>2017 Nobel Prize in Physics</a> for the observation of gravitational waves, offers their data and analysis code for the public in the form of Jupyter Notebooks hosted on Binder at their <a href='https://losc.ligo.org/tutorials'>Open Science Center</a>.</li></ul><p><img src='https://cdn-images-1.medium.com/max/1600/1*Msgqb8LKmLJSKLLOXZs7Bw.png' alt='img' referrerPolicy='no-referrer' /></p><ul><li>Measurement and prediction of gravitational waves formed by two black holes merging. Adapted from <a href='https://github.com/minrk/ligo-binder' target='_blank' class='url'>https://github.com/minrk/ligo-binder</a>.</li><li><a href='http://www.isgrg.org/index.php'>ISGRG</a> 其中有职位信息可以搜索</li><li><a href=''>Gravitational Wave Detectors and Sources</a></li><li><a href='https://github.com/gwoptics/SpacePyQuest'>Space Py Quest 1.0.0</a></li><li><a href='https://hub.mybinder.org/user/gwastro-gwapps-v6sk5uiv/apps/gw150914.ipynb'>What Gravitational wave Template fits GW150914 the best?</a></li><li><a href='https://www.researchgate.net/publication/324786772_Prospects_for_observing_and_localizing_gravitational-wave_transients_with_Advanced_LIGO_Advanced_Virgo_and_KAGRA/fulltext/5ae28c03458515c60f681e65/324786772_Prospects_for_observing_and_localizing_gravitational-wave_transients_with_Advanced_LIGO_Advanced_Virgo_and_KAGRA.pdf?_sg%5B0%5D=p4gFZ9SUc8LYFD8fzIMeKiIcemumaezH2C_9g5X8gZObEMKoMxNy0HgbPf9jPG5SLScIKxlQemfT-8Wcpk_ztQ.H1VK515hzNUyPnwTUcODh4T5fg1z003cKi4TpT3_FjHv7v4Bn1bJR22dqpGqy5H1reL7oizyWwf3LurnqL0VvA&_sg%5B1%5D=V02dftVg0X9CVsV41N10sNWcQkLkZzPQrEEDjf6Hu1Inmp05FTCHYbzjczJrmfHaLd5L8cB7CMOSiRXP9N34uGOhXzryklAJIly3p4vaxmMY.H1VK515hzNUyPnwTUcODh4T5fg1z003cKi4TpT3_FjHv7v4Bn1bJR22dqpGqy5H1reL7oizyWwf3LurnqL0VvA&_iepl='>Prospects for observing and localizing gravitational-wave transients with Advanced LIGO, Advanced Virgo and KAGRA</a> </li></ul><p>&nbsp;</p><p><a href='https://qscan.ligo.org'>Web-based Qscan for LIGO data</a></p><p><a href='http://havewedetectedgravitationalwavesyet.com' target='_blank' class='url'>http://havewedetectedgravitationalwavesyet.com</a></p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n1099' class='md-header-anchor '></a>Physics</h1><p><a href='https://mp.weixin.qq.com/s/a65IAWsFO-UqW-3YYerEew'>AI+ | 深度学习在高能物理领域中的应用</a></p><p><a href='https://mp.weixin.qq.com/s/OGM81QEFbmbIm8BLKpkCtw'>下一秒火焰如何燃烧？机器学习成功预测混沌</a></p><p><a href='https://towardsdatascience.com/deep-learning-meets-physics-restricted-boltzmann-machines-part-i-6df5c4918c15'>Deep Learning meets Physics: Restricted Boltzmann Machines Part I</a></p><p><a href='https://towardsdatascience.com/deep-learning-meets-physics-restricted-boltzmann-machines-part-ii-4b159dce1ffb'>Deep Learning meets Physics: Restricted Boltzmann Machines Part II</a></p><p>《A Deep Neural Network for Pixel-Level Electromagnetic Particle Identification in the MicroBooNE Liquid Argon Time Projection Chamber》(2018) <a href='http://t.cn/Rkeq9jm' target='_blank' class='url'>http://t.cn/Rkeq9jm</a></p><p>&nbsp;</p><h1><a name='header-n1106' class='md-header-anchor '></a>信号处理</h1><p><a href='https://jakevdp.github.io/blog/2013/08/28/understanding-the-fft/'>Understanding the FFT Algorithm</a></p><p>【图卷积网络相关文献汇总】’Graph-based Neural Networks - Graph Convolutional Networks (GCNs)&#39; by Sungyong Seo GitHub: <a href='http://t.cn/R1wr7dP' target='_blank' class='url'>http://t.cn/R1wr7dP</a> </p><p>【图卷积神经网络】《Graph Convolutional Neural Network》by Stephenhky Part1:<a href='http://t.cn/RDFH1gT' target='_blank' class='url'>http://t.cn/RDFH1gT</a> Part2:<a href='http://t.cn/RDFH1gY' target='_blank' class='url'>http://t.cn/RDFH1gY</a> </p><p>Signal Convolution Logic：<a href='https://arxiv.org/abs/1806.00238' target='_blank' class='url'>https://arxiv.org/abs/1806.00238</a></p><p>《Sampling and Super-resolution of Sparse Signals Beyond the Fourier Domain》A Bhandari, Y C. Eldar [MIT] (2018) <a href='http://t.cn/RBbwKhk' target='_blank' class='url'>http://t.cn/RBbwKhk</a> </p><p>Spectral Representations for Convolutional Neural Networks <a href='https://arxiv.org/pdf/1506.03767.pdf' target='_blank' class='url'>https://arxiv.org/pdf/1506.03767.pdf</a></p><p><a href='https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650745273&idx=4&sn=3a843eef986994d1268bedc3e8ac44e6&chksm=871aedc7b06d64d18563f05310ed876e8653043f7383d76ef2c07a4def160c90301a358909de#rd'>学界 | 深度神经网络为什么不易过拟合？傅里叶分析发现固有频谱偏差</a></p><p><a href='https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650746708&idx=4&sn=93521d9b5074d43fc611768c47302570&chksm=871aeb2ab06d623ca0ebf0f3037099f0a8e7c9678c4df514a8f8d33a9b90d63857f88a48cc1f#rd'>前沿 | GAN用于材料设计：哈佛大学新研究登上Science</a></p><p> Digital Signal Processing： <a href='https://www.youtube.com/channel/UCf-VdHm0OyV_TKD5BU9yIXw' target='_blank' class='url'>https://www.youtube.com/channel/UCf-VdHm0OyV_TKD5BU9yIXw</a></p><p><a href='https://arxiv.org/abs/1802.05957'>Spectral Normalization for Generative Adversarial Networks</a></p><p>《Bayesian Nonparametric Spectral Estimation》F Tobar [Universidad de Chile] (2018) <a href='http://t.cn/Rsu2CrO' target='_blank' class='url'>http://t.cn/Rsu2CrO</a> view:<a href='http://t.cn/Rsu2CrK' target='_blank' class='url'>http://t.cn/Rsu2CrK</a> </p><p>BayesLine: Bayesian Inference for Spectral Estimation of Gravitational Wave Detector
Noise</p><p>《Deep learning for time series classification: a review》H I Fawaz, G Forestier, J Weber, L Idoumghar, P Muller [Université Haute Alsace] (2018) <a href='http://t.cn/Ev2ycRb' target='_blank' class='url'>http://t.cn/Ev2ycRb</a> </p><p>&nbsp;</p><h1><a name='header-n1121' class='md-header-anchor '></a>会议</h1><p>【CVPR 2018笔记】《CVPR 2018 notes》by Erika Menezes day 1:<a href='http://t.cn/RrJbAQD' target='_blank' class='url'>http://t.cn/RrJbAQD</a> day 2:<a href='http://t.cn/RrJbAQd' target='_blank' class='url'>http://t.cn/RrJbAQd</a> </p><p>【CVPR 2018印象 &amp; 十五篇有趣论文】《CVPR 2018. Impressions and 15 interesting papers》by Dmytro Mishkin <a href='http://t.cn/RdyzOnX' target='_blank' class='url'>http://t.cn/RdyzOnX</a></p><p>【CVPR 2018十大最酷论文】《The 10 coolest papers from CVPR 2018》by George Seif <a href='http://t.cn/RrF55QA' target='_blank' class='url'>http://t.cn/RrF55QA</a> </p><p>“Accepted talks and papers - AutoML 2018 @ ICML/IJCAI-ECAI”  <a href='http://t.cn/RgYHlwf' target='_blank' class='url'>http://t.cn/RgYHlwf</a> </p><p>【AI/CV/DM/NLP最新国际会议列表】“2018-2019 International Conferences in Artificial Intelligence, Computer Vision, Data Mining and Natural Language Processing” by Jackie Tseng <a href='http://t.cn/RrAeBmr' target='_blank' class='url'>http://t.cn/RrAeBmr</a> GitHub:<a href='http://t.cn/RD2m6cd' target='_blank' class='url'>http://t.cn/RD2m6cd</a> </p><p>【各大AI会议论文接收率统计表】’Statistics of acceptance rate for AI conference - Statistics of acceptance rate for the main AI conference&#39; by LI XIN GitHub: <a href='http://t.cn/Rk46719' target='_blank' class='url'>http://t.cn/Rk46719</a> </p><p>【ECCV 2018论文列表】“Accepted papers | ECCV 2018”  <a href='http://t.cn/RF3GGSl' target='_blank' class='url'>http://t.cn/RF3GGSl</a> </p><p>【撰写会议和论文提案(开题)：实用策略和成功案例】《Writing Conference, Thesis, and Dissertation Proposals》 <a href='http://t.cn/Ev2qmRn' target='_blank' class='url'>http://t.cn/Ev2qmRn</a> </p><p>【ECCV 2018 Best Paper Award】《Group Normalization》Y Wu, K He [Facebook AI Research (FAIR)] (2018) <a href='http://t.cn/RnKoktR' target='_blank' class='url'>http://t.cn/RnKoktR</a> </p><p><a href='https://mp.weixin.qq.com/s/kHna-1QW1GRWKHtzIfpdTg'>何恺明ECCV 2018教程41页PPT一深度表示学习的视觉识别</a></p><p>【ICML2018与ECCV2018亮点回顾】《ICML’18 and ECCV’18 highlights》by Tetianka Martyniuk <a href='http://t.cn/EvNBLJY' target='_blank' class='url'>http://t.cn/EvNBLJY</a> </p><p>【ECCV 2018总结】《ECCV 2018 Recap》by Maria Dobko <a href='http://t.cn/EvpM7qe' target='_blank' class='url'>http://t.cn/EvpM7qe</a> </p><p>【从ECCV 2018看超分辨率研究趋势】《Super-Resolution trends at ECCV’18》by Tetianka Martyniuk <a href='http://t.cn/EPf1F3f' target='_blank' class='url'>http://t.cn/EPf1F3f</a> </p><p>&nbsp;</p><h1><a name='header-n1135' class='md-header-anchor '></a>写作</h1><p>【论文文献综述写作指南】《A Guide to Writing the Dissertation Literature Review》J J. Randolph <a href='http://t.cn/RP6k2z0' target='_blank' class='url'>http://t.cn/RP6k2z0</a> </p><p>【文献综述：目标，常见问题和过程+指南+思维导图模板】《Literature review - Student Services | The University of Queensland, Australia》 <a href='http://t.cn/R1xDtZk' target='_blank' class='url'>http://t.cn/R1xDtZk</a> （<a href='http://uq.edu.au/student-services/pdf/learning/lit-review-generic-focus-Qs-mind-map-v2.pdf'>Generic Mind Map of Focus Ques ons for a Literature Review</a>）</p><p>【文献综述简明指南】《Reviewing the Literature: A Short Guide for Research Students》<a href='http://t.cn/RBT5ZOv' target='_blank' class='url'>http://t.cn/RBT5ZOv</a> </p><p>【如何写出全面、连贯和令人信服的研究计划】“How to produce a comprehensive, coherent &amp; convincing candidacy or research proposal” video:<a href='http://t.cn/R1msDIi' target='_blank' class='url'>http://t.cn/R1msDIi</a> Slides:<a href='http://t.cn/R1msDI6' target='_blank' class='url'>http://t.cn/R1msDI6</a> </p><p>【研究生科研写作指南：如何撰写博硕士论文，期刊文章，资助申请，研究计划及其他(大量样例)】《Writing Science For The Graduate School》by Robert Roseberry <a href='http://t.cn/RBviwLh' target='_blank' class='url'>http://t.cn/RBviwLh</a> pdf:<a href='http://t.cn/RBviw2F' target='_blank' class='url'>http://t.cn/RBviw2F</a> </p><p>【研究生学术写作指南：提高标题、问题、目的和研究的一致性，提高研究计划和报告质量】“Writer&#39;s Forum: Building consistency between title, problem, purpose and research questions to improve the quality of research plans and reports” <a href='http://t.cn/RBzzu3i' target='_blank' class='url'>http://t.cn/RBzzu3i</a> </p><p>【科研写作实用指南】“Write Your Research – Practical guides for researchers in the School of Technology, University of Cambridge” <a href='http://t.cn/RBMWvxi' target='_blank' class='url'>http://t.cn/RBMWvxi</a> </p><p>【写论文的十条简单规则】《Ten simple rules for structuring papers》KP Kording, B Mensh (2017) <a href='http://t.cn/RW3jYgY' target='_blank' class='url'>http://t.cn/RW3jYgY</a> </p><p>【阅读与笔记指南：如何在阅读、做笔记时更具选择性；如何更好地利用时间，做质量更高，真正有用的笔记】“Reading and note-making” <a href='http://t.cn/RB9jJyM' target='_blank' class='url'>http://t.cn/RB9jJyM</a> </p><p>【阅读与笔记指南】《Reading and note making - YouTube》 <a href='http://t.cn/RB9YSyy' target='_blank' class='url'>http://t.cn/RB9YSyy</a> ref:<a href='http://t.cn/RB9YSy2' target='_blank' class='url'>http://t.cn/RB9YSy2</a> <a href='http://t.cn/RB9YSAR' target='_blank' class='url'>http://t.cn/RB9YSAR</a> </p><p>【“一次成功”写作：如何更有效地写作，草拟接近“一次成功”的论文，更容易获得期刊发表机会】《Write Right First Time》by Robert Brown <a href='http://t.cn/RB0DYt9' target='_blank' class='url'>http://t.cn/RB0DYt9</a> pdf:<a href='http://t.cn/RB0DYtN' target='_blank' class='url'>http://t.cn/RB0DYtN</a> </p><p>【有的放矢、影响力先行：如何有目的地写作、发表、宣传——想象写作内容、组织和规划、专注高效、过程分享、出版与展示】《Write with Purpose, Publish for Impact | MethodSpace》by Janet Salmons <a href='http://t.cn/RBR1nHC' target='_blank' class='url'>http://t.cn/RBR1nHC</a> </p><p>《MIT数学英语写作指南》《Mathematical Writing》by Donald E. Knuth, Tracy Larrabee, Paul M. Roberts <a href='http://t.cn/aeM6mS' target='_blank' class='url'>http://t.cn/aeM6mS</a> </p><p>【科研论文引言如何写：好的引言用未知吊足读者的胃口，强调了研究内容是最急迫要解决的问题】《How to write an Introduction for a Research Paper》<a href='http://t.cn/Rr4vt4n' target='_blank' class='url'>http://t.cn/Rr4vt4n</a> </p><p>【如何编辑、校对期刊论文】“Editing and proofreading your journal paper” <a href='http://t.cn/RrlYdhB' target='_blank' class='url'>http://t.cn/RrlYdhB</a> Slides:<a href='http://t.cn/RrlYdh3' target='_blank' class='url'>http://t.cn/RrlYdh3</a> </p><p>【如何写好科研论文】《How to write a good research paper》Bill Freeman <a href='http://t.cn/RrlHXeu' target='_blank' class='url'>http://t.cn/RrlHXeu</a> </p><p>【如何写出好论文】《How to write a good paper》by Jitendra Malik <a href='http://t.cn/RrlHsRg' target='_blank' class='url'>http://t.cn/RrlHsRg</a>  Bilibili：<a href='https://www.bilibili.com/video/av25953652' target='_blank' class='url'>https://www.bilibili.com/video/av25953652</a></p><p>【论文高效写作指南】《Developing Effective Writing Practices》by Michael Azariadis <a href='http://t.cn/RdNgwhC' target='_blank' class='url'>http://t.cn/RdNgwhC</a> </p><p>【论文写作之如何打草稿】《Academic Writing in Practice: Drafting》by Michael Azariadis <a href='http://t.cn/RdY0oSX' target='_blank' class='url'>http://t.cn/RdY0oSX</a> </p><p>【如何写好论文摘要】《Writing Your Abstract》by Michael Azariadis <a href='http://t.cn/RdnInCk' target='_blank' class='url'>http://t.cn/RdnInCk</a> </p><p>【学术写作原则之衔接策略】《Principles of Academic Writing III: Cohesion Strategies》by Michael Azariadis <a href='http://t.cn/RgMXYtX' target='_blank' class='url'>http://t.cn/RgMXYtX</a></p><p>【学术写作指南：有效利用资源——充分利用引用】《Effctive Use of Sources: Making the Most of Citations》by Michael Azariadis <a href='http://t.cn/RgXt90t' target='_blank' class='url'>http://t.cn/RgXt90t</a> </p><p>【学术论文编辑技巧】《Editing Techniques for Academic Writing》by Michael Azariadis <a href='http://t.cn/RgW0z20' target='_blank' class='url'>http://t.cn/RgW0z20</a> </p><p>【如何写好期刊文章：步骤与阶段指南】《Writing a Journal Article》<a href='http://t.cn/RgmZdAa' target='_blank' class='url'>http://t.cn/RgmZdAa</a> </p><p>【研究生论文结构指南】《Thesis Structures》<a href='http://t.cn/RgrL9pU' target='_blank' class='url'>http://t.cn/RgrL9pU</a> </p><p>【脚踏实地学术论文写作】《Writing a scientific paper, step by painful step》by Kevin D. Lafferty <a href='http://t.cn/Rge351O' target='_blank' class='url'>http://t.cn/Rge351O</a> </p><p>【学术写作：如何开始，将想法合理表达、易于读者理解】《Academic Writing》<a href='http://t.cn/RgkXmrt' target='_blank' class='url'>http://t.cn/RgkXmrt</a> </p><p>【如何选择论文投稿的期刊？】《Where should I publish?》 <a href='http://t.cn/Ref37Gc' target='_blank' class='url'>http://t.cn/Ref37Gc</a> </p><p>【论文写作指南之学术观点的挖掘与沟通】“how to develop &amp; communicate academic argument | A Visual Guide to Essay Writing” <a href='http://t.cn/ReHzGpz' target='_blank' class='url'>http://t.cn/ReHzGpz</a> </p><p>【论文写作指南之：关于独创性(如何对知识作出重大贡献)】《Developing originality》<a href='http://t.cn/RenRX0W' target='_blank' class='url'>http://t.cn/RenRX0W</a> </p><p>【论文写作指南：如何写摘要】《Writing an abstract - Understanding and developing abstracts》<a href='http://t.cn/RerIFLf' target='_blank' class='url'>http://t.cn/RerIFLf</a> </p><p>【如何写毕业论文】《Write the thesis》 <a href='http://t.cn/R3vms7t' target='_blank' class='url'>http://t.cn/R3vms7t</a> </p><p>【如何发表期刊文章】《Publish your research》 <a href='http://t.cn/RDAOkpB' target='_blank' class='url'>http://t.cn/RDAOkpB</a> </p><p>【如何写研究计划书】《Research proposal guidelines》 <a href='http://t.cn/RD5RqAT' target='_blank' class='url'>http://t.cn/RD5RqAT</a> </p><p><a href='https://mp.weixin.qq.com/s/J6lut5uB7l_x35HJZi8S7g'>论文被拒的原因……以及我们能做些什么</a></p><p><a href='https://mp.weixin.qq.com/s/hdxDf5tEnb4dRsRDSaAYQQ'>如何写好一篇出色的研究论文</a></p><p>【Google Scholar, Web of Science与Scopus：252个主题类别引文的系统比较——GS基本上是WoS(95％包含在GS中)和Scopus(92％包含在GS中)的超集，具有显著的额外覆盖率】《Google Scholar, Web of Science, and Scopus: a systematic comparison of citations in 252 subject categories》<a href='http://t.cn/Rkz0gS1' target='_blank' class='url'>http://t.cn/Rkz0gS1</a></p><p>【撰写发表文章的艺术与科学】《art and science of writing a publishable article | Journal of Urban Ecology | Oxford Academic》by Steward T A Pickett, Mark J McDonnell <a href='http://t.cn/RkipCa9' target='_blank' class='url'>http://t.cn/RkipCa9</a> </p><p><a href='https://medium.com/@kesiparker/how-to-use-the-oxford-comma-in-technical-writing-5d03bb39b966'>How to Use the “Oxford Comma” in Technical Writing</a></p><p>【论文发表指南：发什么，何时，在哪】《Publishing Know-How: What, When and Where》by Claire Aitchison <a href='http://t.cn/RkeoM0G' target='_blank' class='url'>http://t.cn/RkeoM0G</a> </p><p>【手把手：学术期刊文章30步发表指南 &amp; 影响力打造策略】《A Step-by-Step Guide to Publishing Journal Articles and Strategies for Securing Impactful Publications》Anthony J. Onwuegbuzie <a href='http://t.cn/RksGMwh' target='_blank' class='url'>http://t.cn/RksGMwh</a> </p><p>【写给新手的文章发表指南(10个关键问题帮你入门、确定关键信息和想法)】《Writing for Publication - a Guide for New Authors》Nancy Dixon <a href='http://t.cn/RFApnD9' target='_blank' class='url'>http://t.cn/RFApnD9</a> </p><p>【如何在标题、问题、目标和研究问题间保持一致性，提高研究计划和报告质量】《Building consistency between title, problem, purpose and research questions to improve the quality of research plans and reports》by Isadore Newman, Duane Covrig <a href='http://t.cn/RBzzu3i' target='_blank' class='url'>http://t.cn/RBzzu3i</a> pdf:<a href='http://t.cn/RFUJenQ' target='_blank' class='url'>http://t.cn/RFUJenQ</a> </p><p>【简要指南：学术写作如何提高】《Improving your scientific writing: a short
guide》by Frederic D. Bushman <a href='http://t.cn/RF0m8PI' target='_blank' class='url'>http://t.cn/RF0m8PI</a> pdf:<a href='http://t.cn/RF0m8Pf' target='_blank' class='url'>http://t.cn/RF0m8Pf</a> </p><p>【学术期刊论文撰写基础指南】《Writing articles for scientific journals: a basic guide》by J.W. Stirling <a href='http://t.cn/RFndTr2' target='_blank' class='url'>http://t.cn/RFndTr2</a> </p><p>【学术写作的细节分析】《Nuts &amp; Bolts of Scientific Writing》 by D. Baldwin <a href='http://t.cn/RFsSYLU' target='_blank' class='url'>http://t.cn/RFsSYLU</a> </p><p>【如何规划、撰写成功的期刊文章+提高效率、对抗拖延的技巧】《Writing Successful Research Articles - Handout I》by Constance D. Baldwin <a href='http://t.cn/Rshm2ZB' target='_blank' class='url'>http://t.cn/Rshm2ZB</a> </p><p>【数据科学写作实用建议】《Practical Advice for Data Science Writing》by William Koehrsen <a href='http://t.cn/Rs50Sup' target='_blank' class='url'>http://t.cn/Rs50Sup</a> pdf:<a href='http://vdisk.weibo.com/s/AoN5oNkBMPgM' target='_blank' class='url'>http://vdisk.weibo.com/s/AoN5oNkBMPgM</a> </p><p>【如何撰写和提交成功的学术期刊文章：论文各部分应包括什么，编辑回应如何处理】《Successful Scientific Writing: Step by Step》 by Paul Z. Siegel <a href='http://t.cn/Rs5jgfD' target='_blank' class='url'>http://t.cn/Rs5jgfD</a> </p><p>【为影响而写作：如何准备期刊文章】《Writing for Impact: How to Prepare a Journal Article》by Andrew M. Ibrahim, Justin B. Dimick <a href='http://t.cn/RsYO6Xo' target='_blank' class='url'>http://t.cn/RsYO6Xo</a> </p><p>【撰写文献综述】《Writing Literature Reviews》<a href='http://t.cn/Rsen44z' target='_blank' class='url'>http://t.cn/Rsen44z</a> </p><p>【如何写摘要】《Writing an Abstract》 <a href='http://t.cn/EvP1hKe' target='_blank' class='url'>http://t.cn/EvP1hKe</a> </p><p>【论文发表指南之修订——如何提交稿件、回复审稿意见，撰写回复信、修改草稿】《Revising  for  Publication》<a href='http://t.cn/EvqQ5CP' target='_blank' class='url'>http://t.cn/EvqQ5CP</a></p><p><a href='http://view.zsxq.com/view/5b9f146a2540ed224c01306d'>How to write a great  research paper</a></p><p>【如何写好科研论文】《How to write a great research paper》Nando de Freitas, Ulrich Paquet, Stephan Gouws, Martin Arjovsky, Kyunghyun Cho <a href='http://t.cn/EvpX4SV' target='_blank' class='url'>http://t.cn/EvpX4SV</a> </p><p>【把(毕业)论文变成可发表的期刊文章】《Turning Your Dissertation Into a Publishable Journal Article》Tribe, R. &amp; Tunariu <a href='http://t.cn/EvnnIVD' target='_blank' class='url'>http://t.cn/EvnnIVD</a> </p><p>【推荐信怎么写】《How to write a letter of recommendation》by Michael Ernst <a href='http://t.cn/RVZYjCM' target='_blank' class='url'>http://t.cn/RVZYjCM</a> </p><p>【如何撰写出色的学术论文】《How to Write a Great Research Paper - YouTube》by Simon Peyton Jones <a href='http://t.cn/R9xzY7a' target='_blank' class='url'>http://t.cn/R9xzY7a</a> Slides:<a href='http://t.cn/R9xzY7i' target='_blank' class='url'>http://t.cn/R9xzY7i</a> pdf:<a href='http://t.cn/R9xzY7x' target='_blank' class='url'>http://t.cn/R9xzY7x</a> #bilibili#搬运：<a href='http://t.cn/R9xzY7X' target='_blank' class='url'>http://t.cn/R9xzY7X</a> </p><p>【科研写作过程总览】《Navigating the research writing process》<a href='http://t.cn/EPG1q9K' target='_blank' class='url'>http://t.cn/EPG1q9K</a> </p><p>【《非英语母语者科研论文撰写指南》样章：如何写引言】《How to Write an Introduction》<a href='http://t.cn/EPqSzVn' target='_blank' class='url'>http://t.cn/EPqSzVn</a> </p><p>【论文写作时间管理技巧】《Time Management Tips for Dissertation Writing》<a href='http://t.cn/EPfenUt' target='_blank' class='url'>http://t.cn/EPfenUt</a> </p><p>&nbsp;</p><p>&nbsp;</p><p>每篇发表的科研论文，最好都能配有一篇摘要博客文章。我试图对博士后发表的所有文章做到这一点，(有时一篇博客会包含几篇文章) 我鼓励学生们也这样做，有十倍甚至上百倍的人会阅读博文。 via:Philip Guo </p><p><img src='assets/image-20180721005220977.png' alt='image-20180721005220977' referrerPolicy='no-referrer' /></p><h1><a name='header-n1195' class='md-header-anchor '></a>PhD</h1><p>【读博生存指南：17条简单策略】《17 Simple Strategies To Survive Your PhD》by Julio Peironcely <a href='http://t.cn/RBtYVeL' target='_blank' class='url'>http://t.cn/RBtYVeL</a> </p><p>【博士生科研精要之概念框架】《Overlooking the conceptual framework》<a href='http://t.cn/RB2EQGs' target='_blank' class='url'>http://t.cn/RB2EQGs</a> </p><p>【读博“起步”资源集】“resources I wish <em>I</em> had when I started a PhD” by Matt Hauer <a href='http://t.cn/RgeuURU' target='_blank' class='url'>http://t.cn/RgeuURU</a> </p><p><a href='https://www.zhihu.com/question/21446695'>学术界的潜台词</a></p><p>【博士论文怎么写】《How to write a PhD》 <a href='http://t.cn/R1eAuUy' target='_blank' class='url'>http://t.cn/R1eAuUy</a> </p><p>“世界杯 vs. 读博士” via:PhdComics </p><p><img src='https://i.loli.net/2018/06/12/5b1eaddab21b4.png' alt='' referrerPolicy='no-referrer' /></p><p><img src='https://i.loli.net/2018/06/12/5b1eadff9addc.png' alt='' referrerPolicy='no-referrer' /></p><p>“一大步 vs. 一小步” via:PhdComics </p><p><img src='https://i.loli.net/2018/06/12/5b1ead96f25a5.png' alt='' referrerPolicy='no-referrer' /></p><p>【给博士生的一些建议：选导师先认清自己兴趣；根据问题而不是技术选择实验室；读博士不是野餐，你决定用生命中的5 - 6年当学徒，务必确认对正在做的事感兴趣……】“Advice to PhD students” by Jayant Udgaonkar <a href='http://t.cn/RrMJxm3' target='_blank' class='url'>http://t.cn/RrMJxm3</a> </p><p><a href='https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650746674&idx=3&sn=aec6f9bff3e215244d22a7b95268d256'>观点 | 博士离开学术界算不算失败？牛津大学博士有话要说</a></p><p>【考虑读博之前你需要了解的那些事：关于机会成本、必要性、心理健康到环境等各方面考虑因素】《What You Need to Know Before Considering a PhD | fast.ai》by Rachel Thomas <a href='http://t.cn/RFh6jBl' target='_blank' class='url'>http://t.cn/RFh6jBl</a> </p><p>【观点 | 读博有风险，入坑需谨慎】AI 学术界的「排外」现象到底是由于开放性还是有先来者在守门，近日在 Reddit 上就出现了这样的讨论。但该话题仅聚焦于学术研究，读博其实是个人发展的一部分，学术研究也是整个 AI 行业的一部分，Rachel Thomas 在这里就向我们提供了更广的视角。<a href='http://t.cn/RFn6aKL' target='_blank' class='url'>http://t.cn/RFn6aKL</a></p><p>【完成论文时使用资源分享】《One year to dissertate》by Lucy D&#39;Agostino McGowan <a href='http://t.cn/EvlWh9I' target='_blank' class='url'>http://t.cn/EvlWh9I</a> GitHub:<a href='http://t.cn/EvlWh9c' target='_blank' class='url'>http://t.cn/EvlWh9c</a> </p><p>【如何写好博士论文】《How to write a good PhD thesis and survive the viva》by Stefan R¨uger <a href='http://t.cn/zYTLpPe' target='_blank' class='url'>http://t.cn/zYTLpPe</a> </p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n1214' class='md-header-anchor '></a>Papers</h1><p>&nbsp;</p><p>《Learning deep representations by mutual information estimation and maximization》R D Hjelm, A Fedorov, S Lavoie-Marchildon, K Grewal, A Trischler, Y Bengio [MILA &amp; MRN &amp; U Toronto] (2018) <a href='http://t.cn/RkpMETN' target='_blank' class='url'>http://t.cn/RkpMETN</a> </p><p>【专栏 | 上海纽约大学张峥教授：2017年影响力论文推荐】上海举办「世界 AI 大会」，找到我作为评委之一，推荐和大会关联的、2017 以来有影响的工作。我把推荐文章和一些补充材料和想法整理一下，在这里抛砖引玉。<a href='http://t.cn/RkFKulu' target='_blank' class='url'>http://t.cn/RkFKulu</a> </p><p>&nbsp;</p><p>&nbsp;</p><h1><a name='header-n1220' class='md-header-anchor '></a>杂</h1><p>【如何为演讲做准备：20小时精品打磨计划】《<a href='https://www.deconstructconf.com/blog/how-to-prepare-a-talk'>How to Prepare a Talk</a>》by Gary Bernhardt</p><p><a href='https://mp.weixin.qq.com/s?src=11&timestamp=1525577375&ver=859&signature=0BgQOUu4N2AR9iMC8QeXwo-fwFLu4akOpWpXqSlkVlONZhkCC5VRKHYzu-RAO9TWR2OJpn8bDRgMDoPr3QRwdfPj9ibEJk0S7nbj35wQx11-tlR5FexnEN7sxUbHgBHL&new=1'>五大顶尖研究院的116篇ICLR 2018录用论文，七大趋势全解读</a></p><p><a href='http://everware.xyz' target='_blank' class='url'>http://everware.xyz</a></p><p><a href='http://www.timeseriesclassification.com/index.php' target='_blank' class='url'>http://www.timeseriesclassification.com/index.php</a></p><p class='md-math-block'><div contenteditable="false" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n1225" cid="n1225" mdtype="math_block">
			
		<div class="md-rawblock-container md-math-container" tabindex="-1"><span style="white-space:pre;"><span class="MathJax_Preview"></span><span class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="15.837ex" height="3.221ex" viewBox="0 -942.4 6818.8 1386.9" role="img" focusable="false" style="vertical-align: -1.032ex;"><defs><path stroke-width="0" id="E2-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="0" id="E2-MJMATHI-52" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path><path stroke-width="0" id="E2-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E2-MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path><path stroke-width="0" id="E2-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="0" id="E2-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path stroke-width="0" id="E2-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(55.317) matrix(1 0 0 -1 0 0)">参</text><g transform="translate(799,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(55.317) matrix(1 0 0 -1 0 0)">数</text></g><use xlink:href="#E2-MJMAIN-3D" x="1876" y="0"></use><g transform="translate(2932,0)"><use xlink:href="#E2-MJMATHI-52" x="0" y="0"></use><g transform="translate(759,412)"><use transform="scale(0.707)" xlink:href="#E2-MJMATHI-6E" x="0" y="0"></use><g transform="translate(424,-107)"><use transform="scale(0.5)" xlink:href="#E2-MJMATHI-6C" x="0" y="0"></use><use transform="scale(0.5)" xlink:href="#E2-MJMAIN-2B" x="298" y="0"></use><use transform="scale(0.5)" xlink:href="#E2-MJMAIN-31" x="1076" y="0"></use></g><use transform="scale(0.707)" xlink:href="#E2-MJMAIN-2C" x="1814" y="0"></use><g transform="translate(1479,0)"><use transform="scale(0.707)" xlink:href="#E2-MJMATHI-6E" x="0" y="0"></use><use transform="scale(0.5)" xlink:href="#E2-MJMATHI-6C" x="848" y="-213"></use></g><use transform="scale(0.707)" xlink:href="#E2-MJMAIN-2B" x="3003" y="0"></use><use transform="scale(0.707)" xlink:href="#E2-MJMAIN-31" x="3781" y="0"></use></g></g></g></svg></span></span><script type="math/tex; mode=display" id="MathJax-Element-2">参数 = R^{n_{l+1}, n_l+1}</script></span></div></div></p><p>HOW to write README: <a href='https://open-source-guide.18f.gov/making-readmes-readable/' target='_blank' class='url'>https://open-source-guide.18f.gov/making-readmes-readable/</a></p><p>开源macOS应用大列表：<a href='https://github.com/serhii-londar/open-source-mac-os-apps'>List of open source applications for macOS.</a></p><p><a href='https://www.datasciencecentral.com/profiles/blogs/25-timeless-data-science-articles'>25 Timeless Data Science Articles</a></p><p>PythonRobotics: Excellent collection of robotics algorithms (mapping, SLAM, path planning and tracking, control) by <a href='https://twitter.com/Atsushi_twi'>@<strong>Atsushi_twi</strong></a> <img src='https://abs.twimg.com/emoji/v2/72x72/1f916.png' alt='🤖' referrerPolicy='no-referrer' /> <a href='https://t.co/Ou5O4lpTDM'>https://atsushisakai.github.io/PythonRobotics/ </a></p><p>【达芬奇手稿在线浏览器】《Explore Leonardo da Vinci&#39;s notebook: Codex Forster I》 <a href='http://t.cn/RDhQfUF' target='_blank' class='url'>http://t.cn/RDhQfUF</a> </p><p>【实用！针对双盲评审的GitHub匿名化服务】“Anonymous GitHub for Open-Science” <a href='http://t.cn/RDzIogD' target='_blank' class='url'>http://t.cn/RDzIogD</a> </p><p><a href='https://www.exordo.com/blog/the-best-academic-blogs/'>The best academic blogs</a></p><p>【(彭博社)Geoff Hinton传记短片】《Meet the Godfather of AI - YouTube》 <a href='http://t.cn/RrSj4L2' target='_blank' class='url'>http://t.cn/RrSj4L2</a> </p><p>【Bengio访谈：如何组建研究实验室】《Q&amp;A with Yoshua Bengio》 <a href='http://t.cn/RD9eXjg' target='_blank' class='url'>http://t.cn/RD9eXjg</a> </p><p>【电影台词搜索(定位)引擎】“Subzin.com - Find quotes in movies and series”  <a href='http://t.cn/hoDmB' target='_blank' class='url'>http://t.cn/hoDmB</a> </p><p>【黑客艺术】’The Art of Hacking Series - This repository includes resources related to ethical hacking / penetration testing, digital forensics and incident response (DFIR), vulnerability research, exploit development, reverse engineering, and more.&#39;  GitHub: <a href='http://t.cn/R1jCGqJ' target='_blank' class='url'>http://t.cn/R1jCGqJ</a> </p><p>【深度张量网络与非线性的本质】《On Tensor Networks and the Nature of Non-Linearity》 <a href='http://t.cn/RrvfUbj' target='_blank' class='url'>http://t.cn/RrvfUbj</a> </p><p>【交互式火焰图可视化浏览器】’speedscope - A web-based viewer for sampling profiles&#39; by Jamie Wong <a href='https://www.speedscope.app/' target='_blank' class='url'>https://www.speedscope.app/</a> GitHub: <a href='http://t.cn/RknoDhW' target='_blank' class='url'>http://t.cn/RknoDhW</a> </p><p><img src='http://wx3.sinaimg.cn/large/5396ee05ly1furh1cqe4yg20cs0aa7wh.gif' alt='' referrerPolicy='no-referrer' /></p><p><a href='https://blog.csdn.net/simple_the_best/article/details/52821132'>使用pelican搭建一个Jupyter Notebook数据科学博客</a></p><p>【云端GPU(租用)服务大全】’Cloud GPU Vendors - This repository contains information about Cloud GPU offerings for Machine Learning practitioners.&#39; by Phani Srikanth GitHub: <a href='http://t.cn/RkyQoe7' target='_blank' class='url'>http://t.cn/RkyQoe7</a> </p><p>【精品怀旧：在浏览器里玩经典DOS(中文)游戏】“在线 DOS 游戏”  <a href='http://t.cn/RFdZRMb' target='_blank' class='url'>http://t.cn/RFdZRMb</a> GitHub:<a href='http://t.cn/RFel2wg' target='_blank' class='url'>http://t.cn/RFel2wg</a> </p><p>【Java神经网络开发框架】’Neuroph - Java Neural Network Platform Neuroph&#39;  GitHub: <a href='http://t.cn/RsqkIWh' target='_blank' class='url'>http://t.cn/RsqkIWh</a> </p><p>【Git工作流速查】《My Git Workflow》by Oliver Steele <a href='http://t.cn/RsHDtFI' target='_blank' class='url'>http://t.cn/RsHDtFI</a> </p><p>【颜色起名的艺术】《Werner’s Nomenclature of Colours》by P. Syme <a href='http://t.cn/Rs1fgJ5' target='_blank' class='url'>http://t.cn/Rs1fgJ5</a> </p><p>《汉语中的词频及笔画数分布规律探析》by metaquant <a href='http://t.cn/EvI68tb' target='_blank' class='url'>http://t.cn/EvI68tb</a> GitHub:<a href='http://t.cn/EvI68tq' target='_blank' class='url'>http://t.cn/EvI68tq</a> </p><p>【CNN 数字识别原理可视化】“Sinapsis - Visualize the computations inside a convolutional neural network trained for digit recognition”  <a href='http://t.cn/EvIWLYC' target='_blank' class='url'>http://t.cn/EvIWLYC</a> </p><p><a href='https://latexonline.cc'>LaTeX Cloud Compiler</a></p><p><a href='http://www.icst.pku.edu.cn/course/icb/struct.html'>STRUCT</a></p><p><a href='http://tanrobby.github.io/index.html'>Robby T. Tan</a></p><p><a href='https://ece.illinois.edu/directory/profile/t-huang1'>THOMAS S. HUANG</a></p><p>【从零开始创建操作系统】“os-tutorial - How to create an OS from scratch” by Carlos Fenollosa GitHub:<a href='http://t.cn/RL03Jfd' target='_blank' class='url'>http://t.cn/RL03Jfd</a> </p><p>【搭建自己的 Youtube 视频下载服务】’ytdl-webserver - Webserver for downloading youtube videos. Ready for docker.&#39; by Algram GitHub: <a href='http://t.cn/EPU7BqK' target='_blank' class='url'>http://t.cn/EPU7BqK</a> </p><p>【异常检测相关资源大列表】’awesome anomaly detection - A curated list of awesome anomaly detection resources&#39; by Lee hoseong GitHub: <a href='http://t.cn/EP5THkp' target='_blank' class='url'>http://t.cn/EP5THkp</a> </p><p>【图像标记(标注)工具VIA】“VGG Image Annotator (VIA) - an image annotation tool that can be used to define regions in an image and create textual descriptions of those regions”  <a href='http://t.cn/EPfBGZW' target='_blank' class='url'>http://t.cn/EPfBGZW</a> sourcecode:<a href='http://t.cn/EPfBGZl' target='_blank' class='url'>http://t.cn/EPfBGZl</a> </p><p>【科学家应该知道的那些事(建设中)】’Things a scientist is suppposed to know(work-in-progress)’ by Philipp Bayer GitHub: <a href='http://t.cn/EPIv42B' target='_blank' class='url'>http://t.cn/EPIv42B</a> </p><p>&nbsp;</p><p>【用心整理的论文-代码实现列表(w/stars)】“Papers with code. Sorted by stars. Updated weekly.” by Zaur Fataliyev GitHub:<a href='http://t.cn/RssQ7vZ' target='_blank' class='url'>http://t.cn/RssQ7vZ</a> </p><p>&nbsp;</p><h1><a name='header-n1256' class='md-header-anchor '></a>并行计算 &amp; 计算天文</h1><p><a href='http://www.astropython.org'>Python for Astronomers</a></p><p><a href='https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/index.html'>Python并行编程</a></p><p>&nbsp;</p><p>&nbsp;</p><p>books：</p><p>《Parallel Scientific Computing in C++ and MPI》</p><p>《Python High Performance》</p><p>《Statistics, Data Mining, and Machine Learning in Astronomy》</p><p>《Bayesian Logical Data Analysis for the Physical Sciences: A Comparative Approach with Mathematica Support》</p><p>&nbsp;</p><p>&nbsp;</p><div class='footnotes-area'  ><hr/>
<div class='footnote-line'><span class='md-fn-count'>1</span> zouxy09博客原创性博文导航<a name='dfref-footnote-1' href='#ref-footnote-1' title='回到文档' class='reversefootnote' >↩</a></div>
<div class='footnote-line'><span class='md-fn-count'>2</span> An Intuitive Explanation of Convolutional Neural Networks<a name='dfref-footnote-2' href='#ref-footnote-2' title='回到文档' class='reversefootnote' >↩</a><a name='dfref-footnote-2-1' href='#ref-footnote-2-1' title='回到文档' class='reversefootnote' >↩</a></div></div></div>
</body>
</html>