[返回到首页](../index.html)

------



#  #APaperADay AI Reading Challenge

https://apaperaday.nurture.ai



## July 23 - July 29

- **[PAPER OF THE WEEK]**  ***Neural Best-Buddies: Sparse Cross-Domain Correspondence*** ***([2-min summary](https://apaperaday.nurture.ai/clkn/https/nurture.ai/papers/neural-best-buddies-sparse-cross-domain-correspondence/tldr))*** **Why read:** Well-written paper that presents a way to relate two images from different categories, leading to image morphing applications. **Key concept**: finding pairs of neurons (one from each image) that are "buddies" (nearest neighbors). [ArXiv: 1805.04140](https://arxiv.org/abs/1805.04140)

  > MyTweet:  
  >
  > (MARK: **Image correspondence** tasks involve finding a set of points in one image which can be identified as the same points in another image) A key concept in their method is the search for **Neural Best Buddies** (NBB), i.e pairs of neurons (one from each image) that are mutual nearest neighbors. The idea may be helpful for us to interpret or measure the similarity of any inputs.

- **[TOP RECENT]**  **The GAN Landscape: Losses, Architectures, Regularization, and Normalization ([paper](https://apaperaday.nurture.ai/clkn/https/nurture.ai/papers/the-gan-landscape-losses-architectures-regularization-and-normalization/info), [prereq & dependencies](https://apaperaday.nurture.ai/clkn/https/nurture.ai/papers/the-gan-landscape-losses-architectures-regularization-and-normalization/annotations))**  **Why read:** Evaluation of GAN loss functions, optimization schemes and architectures using latest empirical methods. **Interesting takeaway:** authors wrote that most tricks applied in the ResNet style architectures lead to marginal changes and incurs high computational cost. [arXiv:1807.04720](https://arxiv.org/abs/1807.04720)

  > MyTweet:
  >
  > Really impressed by the performance of **Spectral Normalization**(SN) in the paper"The GAN Landscape: Losses, Architectures, Regularization, and Normalization", I think, which may contain an unknown but fundamental concept in **spectral** space.

- **[HIDDEN GEM]**  **A Meta-Learning Approach to One-Step Active-Learning ([paper](https://apaperaday.nurture.ai/clkn/https/nurture.ai/papers/a-meta-learning-approach-to-one-step-active-learning/info),[prereqs & dependencies](https://apaperaday.nurture.ai/clkn/https/nurture.ai/papers/a-meta-learning-approach-to-one-step-active-learning/annotations))**  **Why read:** An under-discussed method to deal with scarce labelled data: a classification model that learns how to label its own training data. **The novelty.** It combines one-shot learning (learning from one or few training examples) with active learning (choosing the appropriate data points to be labelled).  

  > MyTweet:

- **[MOST POPULAR]**  **Visual Reinforcement Learning with Imagined Goals ([paper](https://apaperaday.nurture.ai/clkn/https/nurture.ai/papers/visual-reinforcement-learning-with-imagined-goals/info))**  **Why read:** An interesting way of teaching a model to acquire general-purpose skills. The model performs a self-supervised “practice” phase where it imagines goals and attempts to achieve them. **The novelty:** a goal relabelling method that improves sampling efficiency.   

  > MyTweet:

- **[MUST READ]**  **Universal Language Model Fine-tuning for Text Classification ([paper](https://apaperaday.nurture.ai/clkn/https/nurture.ai/papers/universal-language-model-fine-tuning-for-text-classification/info))**  **Why read:** Transfer Learning has not been widely explored in NLP problems until this paper, which explores the benefits of using a pre-trained model on text classification. **Key result:** Along with various fine-tuning tricks, this method outperforms the state-of-the-art on six text classification tasks. 

  > MyTweet:

- **[MUST READ]**   **Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors ([2-min summary](https://apaperaday.nurture.ai/clkn/https/nurture.ai/papers/interpretability-beyond-feature-attribution-quantitative-testing-with-concept-activation-vectors-tcav/tldr))Why read:** A new method that helps us to interpret NN decisions and also reveal unintended gender and racial biases in NN models. **The novelty.** Gauges the sensitivity of ML predictions to changes in inputs towards the direction of a concept. 

  > MyTweet:

- [MY OWN CHOICE]

  > MyTweet: