---
title: CS231n Lecture.5
date: 2018-08-24
---

[è¿”å›žåˆ°ä¸Šä¸€é¡µ](./index.html)

---

[TOC]

> CS231n è¯¾ç¨‹çš„å®˜æ–¹åœ°å€ï¼šhttp://cs231n.stanford.edu/index.html
>
> è¯¥ç¬”è®°æ ¹æ®çš„è§†é¢‘è¯¾ç¨‹ç‰ˆæœ¬æ˜¯ [Spring 2017](https://www.bilibili.com/video/av17204303/?p=9)(BiliBili)ï¼ŒPPt èµ„æºç‰ˆæœ¬æ˜¯ [Spring 2018](http://cs231n.stanford.edu/syllabus.html).
>
> å¦æœ‰è¯¥ Lecture 5. æ‰©å±•è®²ä¹‰èµ„æ–™ï¼š
>
> -  [ConvNet notes](http://cs231n.github.io/convolutional-networks/) ï¼ˆ[ä¸­è¯‘ç‰ˆ](./CS231n_ConvNet_notes.html)ï¼‰
>



# Lecture 5. Convolutional Neural Networks



## A bit of history...

è¿™éœ€è¦è¿½æº¯åˆ° 1957å¹´ã€‚ã€‚ã€‚ Frank RosenBlatt å‘æ˜Žäº†ç¬¬ä¸€ä»£æ„ŸçŸ¥æœºå™¨ï¼Œé¦–æ¬¡å®žçŽ°äº†æ‰€è°“çš„æ„ŸçŸ¥å™¨ç®—æ³•ã€‚å®ƒåœ¨æ€æƒ³ä¸Šè·Ÿå¾—åˆ°è¯„åˆ†å‡½æ•°çš„è¿‡ç¨‹ç±»ä¼¼ã€‚ä¹Ÿæœ‰æ‰€è°“çš„å‚æ•°æ›´æ–°è§„åˆ™ï¼Œçœ‹ä¼¼å’Œåå‘ä¼ æ’­ç®—æ³•å¾ˆåƒï¼Œä½†æ­¤æ—¶ BP è¿˜æ²¡æœ‰è¢«å‘æ˜Žå‡ºæ¥ã€‚ã€‚ã€‚

åœ¨ 1960 å¹´ï¼ŒWidrow å’Œ Hoff å‘æ˜Žäº† Adaline å’Œ Madalineã€‚è¿™æ˜¯é¦–æ¬¡å°è¯•æŠŠçº¿æ€§å±‚å åŠ æ•´åˆä¸ºå¤šå±‚æ„ŸçŸ¥å™¨ç½‘ç»œã€‚çŽ°åœ¨å¥½åƒä¸Žç¥žç»ç½‘ç»œçš„å±‚çš„è®¾è®¡æ¯”è¾ƒæŽ¥è¿‘ï¼Œä½†åå‘ä¼ æ’­æˆ–è€…å…¶ä»–çš„è®­ç»ƒæ–¹æ³•ä»æœªå‡ºçŽ°ã€‚

åˆ° 1986 å¹´ï¼ŒRumelhart æ‰é¦–æ¬¡æå‡ºäº†åå‘ä¼ æ’­ç®—æ³•ã€‚ä»Žè¿™é‡Œå¼€å§‹æˆ‘ä»¬æœ‰äº†æœ€æ ¸å¿ƒçš„è®­ç»ƒæ–¹æ³•ã€‚

ä¸è¿‡å†å¾ˆé•¿ä¸€æ®µæ—¶é—´å†…ï¼Œæˆ‘ä»¬ä»ç„¶æ— æ³•è®­ç»ƒè¶…å¤§åž‹ç¥žç»ç½‘ç»œã€‚æ‰€è°“çš„ç¥žç»ç½‘ç»œé¢†åŸŸæ›¾ç»å¸¸å¹´æ— äººé—®æ´¥ï¼Œå¹¶ä¸ç”¨è¯´å¤§è§„æ¨¡åº”ç”¨äº†ã€‚ä½†åœ¨ 2000 å¹´å·¦å³ï¼Œäº‹æƒ…å¼€å§‹æœ‰äº†å˜åŒ–ã€‚

åœ¨ 2006 å¹´ï¼ŒGeoff. Hinton ä¸Ž Ruslan Salakhutdinov åˆä½œçš„ä¸€ç¯‡è®ºæ–‡ï¼Œè¡¨æ˜Žæ·±åº¦ç¥žç»ç½‘ç»œä¸ä»…å¯ä»¥è®­ç»ƒå¹¶ä¸”å¯ä»¥é«˜æ•ˆè®­ç»ƒã€‚è¿™ä»ç„¶ä¸æ˜¯ç¥žç»ç½‘ç»œçŽ°åœ¨çš„æ ·å­ã€‚æ­¤æ—¶çš„ç½‘ç»œéœ€è¦è°¨æ…Žçš„åˆå§‹åŒ–æ‰èƒ½è¿è¡Œåå‘ä¼ æ’­ã€‚ä»–ä»¬çš„æ–¹æ³•å°±æ˜¯å…ˆç»è¿‡ä¸€ä¸ªé¢„è®­ç»ƒé˜¶æ®µï¼Œå¯¹æ¯ä¸€ä¸ªéšå±‚ä½¿ç”¨å—é™çŽ»å°”å…¹æ›¼æœºï¼ˆrestricted Boltzmann machineï¼‰æ¥å»ºæ¨¡ã€‚è¿™æ ·é€šè¿‡è¿­ä»£è®­ç»ƒæ¯ä¸€å±‚å¯ä»¥å¾—åˆ°ä¸€äº›åˆå§‹åŒ–æƒé‡ï¼Œå¾—åˆ°æ‰€æœ‰çš„éšå±‚ä¹‹åŽï¼Œä»¥æ­¤æ¥åˆå§‹åŒ–ä¸€ä¸ªå®Œæ•´çš„ç¥žç»ç½‘ç»œã€‚ç„¶åŽåå‘ä¼ æ’­ï¼Œå¾®è°ƒå‚æ•°ã€‚

å®žé™…ä¸Šï¼Œç›´åˆ° 2012 å¹´ã€‚ç¥žç»ç½‘ç»œæ‰ç¬¬ä¸€æ¬¡å–å¾—äº†æƒŠäººçš„æˆæžœã€‚æ·±åº¦ç¥žç»ç½‘ç»œçš„ç‹‚æ½®ç”±æ­¤çˆ†å‘ã€‚ç¬¬ä¸€ä¸ªè¢«æ”»ç ´çš„é¢†åŸŸæ˜¯è¯­éŸ³è¯†åˆ«ï¼ŒGeoff. Hinton ç»„åˆ©ç”¨æ·±åº¦ç¥žç»ç½‘ç»œè¿›è¡Œå£°å­¦å»ºæ¨¡å’Œè¯­éŸ³è¯†åˆ«ã€‚ç„¶åŽæ˜¯å›¾åƒè¯†åˆ«ï¼Œåœ¨ 2012 å¹´ï¼ŒGeoff. Hinton åŒä¸€ä¸ªå®žéªŒå®¤çš„ Alex Krizhevsky å‘è¡¨äº†é‡Œç¨‹ç¢‘å¼çš„[è®ºæ–‡](../paper_summary/ImageNet Classification with Deep Convolutional Neural Networks.html)ï¼Œé¦–æ¬¡è®©å·ç§¯ç¥žç»ç½‘ç»œçš„æ¡†æž¶åœ¨ ImageNet åˆ†ç±»å¤§èµ›ä¸­å–å¾—äº†æƒŠäººçš„æˆç»©ã€‚CNN æ ‘ç«‹äº† ImageNet å›¾åƒåˆ†ç±»ä»»åŠ¡çš„æ ‡æ†ï¼Œå¹¶ä¸”å¤§å¹…é™ä½Žäº†è¯¯å·®ã€‚æ­¤åŽï¼Œå·ç§¯ç¥žç»ç½‘ç»œå¼€å§‹å¾—åˆ°å¹¿æ³›çš„åº”ç”¨ã€‚



æŽ¥ä¸‹æ¥ï¼Œæ‰¯çš„æ˜¯è§†è§‰ä»»åŠ¡çš„åŽ†å²ã€‚ã€‚ã€‚å’Œ Lecture.1 åŸºæœ¬å·®ä¸å¤šã€‚

è¿œçš„ä¸è¯´ï¼Œç›´æŽ¥ä»Ž 1998 å¹´è¯´èµ·ã€‚Yann LeCun é¦–æ¬¡ç®€å•å±•ç¤ºäº†ç¬¬ä¸€ä¸ªå®žä¾‹ï¼šåº”ç”¨åå‘ä¼ æ’­å’ŒåŸºäºŽæ¢¯åº¦çš„å­¦ä¹ æ–¹æ³•ï¼Œæ¥è®­ç»ƒå·ç§¯ç¥žç»ç½‘ç»œã€‚è¿™å¯¹æ–‡æ¡£è¯†åˆ«éžå¸¸æœ‰æ•ˆï¼Œå°¤å…¶å¯¹é‚®æ”¿ç¼–ç è¯†åˆ«æ•ˆæžœæžå¥½ã€‚å› æ­¤è¿™äº›æ–¹æ³•åœ¨é‚®æ”¿æœåŠ¡ä¸­è¢«å¹¿æ³›ç”¨äºŽé‚®æ”¿ç¼–ç è¯†åˆ«ã€‚ç„¶è€Œå®ƒå¹¶ä¸èƒ½æ‰©å±•åˆ°æ›´å…·æœ‰æŒ‘æˆ˜ã€æ›´å¤æ‚çš„æ•°æ®ã€‚æ•°å­—éžå¸¸å®¹æ˜“è¯†åˆ«ï¼Œä½†è¯†åˆ«ä¹Ÿæ˜¯æœ‰å±€é™æ€§çš„ã€‚

äºŽæ˜¯åœ¨ 2012 å¹´ï¼ŒAlex Krizhevsky  æå‡ºäº†ä¸€ç§çŽ°ä»£åŒ–çš„å·ç§¯ç¥žç»ç½‘ç»œã€‚ä»–æå‡ºçš„ç½‘ç»œï¼Œæˆ‘ä»¬ä¸€èˆ¬ç§°ä¸º [AlexNet](../paper_summary/ImageNet Classification with Deep Convolutional Neural Networks.html)ã€‚ä½†ä»–çš„ç½‘ç»œå’Œ Yann LeCun æå‡ºçš„å·ç§¯ç¥žç»ç½‘ç»œç›¸æ¯”ï¼Œçœ‹ä¸ŠåŽ»å¹¶æ²¡æœ‰å¤šå¤§å·®å¼‚ã€‚å®ƒä»¬åªæ˜¯æ‰©å±•çš„æ›´å¤§æ›´æ·±ã€‚æ›´é‡è¦çš„ä¸€éƒ¨åˆ†æ˜¯å®ƒä»¬å¯ä»¥å……åˆ†åˆ©ç”¨å¤§é‡æ•°æ®å¯å¾—åˆ°çš„å›¾åƒï¼ˆImageNet æ•°æ®é›†ï¼‰ã€‚åŒæ—¶ä¹Ÿå……åˆ†å‘æŒ¥äº† GPU å¹¶è¡Œè®¡ç®—èƒ½åŠ›çš„ä¼˜åŠ¿ã€‚

çŽ°åœ¨ï¼ŒConvNets å·²ç»è¢«å¹¿æ³›åº”ç”¨ã€‚

æŽ¥ä¸‹æ¥ï¼Œå°å§å§ä»‹ç»äº†å„ç§å„æ ·å•Šçš„åº”ç”¨ï¼Œåªæœ‰ä¸€ä¸ªæ˜Ÿç³»åˆ†ç±»å’Œæˆ‘çš„é¢†åŸŸç•¥æœ‰ç›¸å…³ï¼š[https://arxiv.org/pdf/1503.07077.pdf]

![](https://i.loli.net/2018/08/24/5b8010a5b474b.png)





## Convolutional Neural Networks
(First without the brain stuff)

æˆ‘ä»¬ä»Žå‡½æ•°çš„è§’åº¦æ¥è®¨è®ºå·ç§¯ç¥žç»ç½‘ç»œã€‚ï¼ˆæˆ‘è¿™é‡Œçœç•¥æŽ‰äº†å·ç§¯çš„æ“ä½œç»†èŠ‚ï¼‰

- å‰é¢å‡ å±‚çš„å·ç§¯æ ¸ä¸€èˆ¬ä»£è¡¨äº†ä¸€äº›ä½Žé˜¶çš„å›¾åƒç‰¹å¾ï¼Œæ¯”å¦‚è¯´ä¸€äº›è¾¹ç¼˜ç‰¹å¾ã€‚ä¹‹åŽå‡ å±‚çš„ç‰¹å¾ä¼šæ›´åŠ çš„å¤æ‚ï¼Œå®ƒçš„å†…å®¹çœ‹èµ·æ¥å¯èƒ½æ›´åŠ ä¸°å¯Œã€‚å¯¹äºŽé‚£äº›é«˜é˜¶çš„ç‰¹å¾ï¼Œå¯ä»¥èŽ·å¾—ä¸€äº›æ¯”æ–‘ç‚¹ä¹‹ç±»çš„æ›´åŠ ä¸°å¯Œçš„å†…å®¹ã€‚

  ![](https://i.loli.net/2018/08/25/5b8039ac4863d.png)





- ä¿¡å·å¤„ç†ä¸­çš„äºŒç»´å·ç§¯ï¼š
  $$
  f[x,y]*g[x,y]=\sum^\infty_{n_1=-\infty}\sum^\infty_{n_2=-\infty}f[n_1,n_2]\cdot g[x-n_1,y-n_2]
  $$
  ï¼ˆelementwise multiplication and sum of a filter and the signalï¼‰



å·´æ‹‰å·´æ‹‰ã€‚ã€‚ã€‚è¯´äº†å¾ˆå¤šï¼Œæ€»ä¹‹å°±æ˜¯ä¸‹é¢ðŸ‘‡æ€»ç»“çš„å¥½ä¸œè¥¿ï¼šï¼ˆå…¶å®žè¿˜ä¸å…¨~ï¼‰

### Summary. To summarize, the Conv Layer:

- Accepts a volume of size $W_1\times H_1\times D_1$
- Requires four hyperparameters:
  - Number of filters $K$. (powers of 2, e.g. 32, 64, 128, 512)
  - their spatial extent $F$.
  - the stride $S$.
  - the amount of zero padding $P$.
- Produces a volume of size $W_2\times H_2\times D_2$ where:
  - $W_2=(W_1-F+2P)/2+1$
  - $H_2=(H_1-F+2P)/2+1$ (i.e. width and height are computed equally by symmetry)
  - $D_2=K$
- With parameter sharing, it introduces $F\cdot F\cdot D_1$ weights per filter, for a total of $(F\cdot F\cdot D_1)\cdot K$ weights  and $K$ biases.
- In the output volume, the $d$-th depth slice (of size $W_2\times H_2$) is the result of performing a valid convolution of the $d$-th filter over the input volume with a stride of $S$, and then offset by $d$-th bias.



ç¥žç»å…ƒè§’åº¦çš„è§£è¯»å°±ç•¥è¿‡äº†ï¼Œæ²¡å•¥æ„æ€ã€‚ã€‚ã€‚å”¯ç‹¬ä¸€ä¸ªæ„Ÿå—é‡Žï¼ˆreceptive fieldï¼‰ è¿™ä¸ªæ¦‚å¿µæ˜¯å¾ˆé‡è¦çš„ï¼Œä½†æ˜¯è¿™ä¸ªè®²ä¹‰è¿˜æ²¡è®²æ¸…æ¥šè®²å…¨ã€‚

å¯¹äºŽæ± åŒ–å±‚ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥æ€»ç»“ä¸€ä¸‹ï¼š

### Summary. To summarize, the Pooling Layer:

- Accepts a volume of size $W_1\times H_1\times D_1$
- Requires three hyperparameters: (Common settings: $F=2,S=2$ or $F=3, S=3$)
  - their spatial extent $F$,
  - the stride $S$,
- Produces a volume of size $W_2\times H_2\times D_2$ where:
  - $W_2=(W_1-F)/S+1$
  - $H_2=(H_1-F)/S+1$
  - $D_2=D_1$
- Introduces zero parameters since it computes a fixed function of the input
- Note that it is not common to use zero-padding for Pooling layers



### Demo

æœ€æœ€åŽï¼Œshow å‡ºäº†ä¸€ä¸ª demo å¯ä»¥åœ¨ CIFAR-10æ•°æ®é›†ä¸Šè§‚å¯Ÿè®­ç»ƒè¿‡ç¨‹ä»¥åŠè®­ç»ƒåŽçš„å¯è§†åŒ–æ•ˆæžœã€‚

> https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html







---

[è¿”å›žåˆ°ä¸Šä¸€é¡µ](./index.html) | [è¿”å›žåˆ°é¡¶éƒ¨](./cs231n_5.html)

---
<br>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
<br>

<script type="application/json" class="js-hypothesis-config">
  {
    "openSidebar": false,
    "showHighlights": true,
    "theme": classic,
    "enableExperimentalNewNoteButton": true
  }
</script>
<script async src="https://hypothes.is/embed.js"></script>