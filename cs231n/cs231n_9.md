---
title: CS231n Lecture.9
date: 2018-08-31
---

[返回到上一页](./index.html)

---

[TOC]

> CS231n 课程的官方地址：http://cs231n.stanford.edu/index.html
>
> 该笔记根据的视频课程版本是 [Spring 2017](https://www.bilibili.com/video/av17204303/?p=16)(BiliBili)，PPt 资源版本是 [Spring 2018](http://cs231n.stanford.edu/syllabus.html).
>
> 另有该 Lecture 9. 扩展讲义资料：
>
> - [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) ([我的笔记](../paper_summary/ImageNet Classification with Deep Convolutional Neural Networks.html))
> - [VGGNet](https://arxiv.org/abs/1409.1556), [GoogLeNet](https://arxiv.org/abs/1409.4842), [ResNet](https://arxiv.org/abs/1512.03385)





# Lecture 9. CNN Architectures



## Review: LeNet-5

[LeCun et al., 1998]

![](https://i.loli.net/2018/08/31/5b88ad25c0691.png)



## Case Studies



### AlexNet

[Krizhevsky et al. 2012]

第一个在 ImageNet 的分类比赛中获得成功的大型卷积神经网络。

![](https://i.loli.net/2018/08/31/5b88b01428447.png)

![](https://i.loli.net/2018/08/31/5b88af9fcdd5d.png)



### ZFNet

[Zeiler and Fergus, 2013]

- ImageNet Large Scale Visual Recognition Challenge (ILSVRC) winners

![image-20180831111001702](assets/image-20180831111001702.png)

![](https://i.loli.net/2018/08/31/5b88b1e037102.png)

![](https://i.loli.net/2018/08/31/5b88b1eeb5222.png)





### VGG

[Simonyan and Zisserman, 2014]

- ImageNet Large Scale Visual Recognition Challenge (ILSVRC) winners

![](https://i.loli.net/2018/08/31/5b88b2470f784.png)

![](https://i.loli.net/2018/08/31/5b88d02227e00.png)

- Q：Why use smaller fileters? (3x3 conv)
  - Stack of three 3x3 conv (stride 1) layers has same **effective receptive field** as one 7x7 conv layer
  - But deeper, more non-linearities
  - And fewer parameters: $3 * (3^2C^2)$ vs. $7^2C^2$ for C channels per layer
- Q: What is the effective receptive field of three 3x3 conv (stride 1) layers?
  - See this post: [关于感受野 (Receptive field) 你该知道的事](../posts/关于感受野 (Receptive field) 你该知道的事.html)
- 

![image-20180831132749679](assets/image-20180831132749679.png)



- Details
  - ILSVRC'14 2nd in classification, 1st in localization
  - Similar training procedure as Krizhevsky 2012
  - No Local Response Normalisation (LRN)
  - Use VGG16 or VGG19 (VGG19 only slightly better, more memory)
  - Use ensembles for best results
  - FC7 features generalize well to other tasks







### GoogLeNet

[Szegedy et al., 2014]

**Deeper networks, computational efficiency**

![](https://i.loli.net/2018/08/31/5b88d51bc5a0d.png)

- **"Inception module"**

  - design a good local network topology (network within a network) and then stack these modules on top of each other
  - Apply parallel filter operations on the input from previous layer:
    - Multiple receptive field sizes for convolution (1x1, 3x3, 5x5)
    - Pooling operation (3x3)
  - Concatenate all filter outputs together depth-wise

  ![](https://i.loli.net/2018/08/31/5b88d5a685ca6.png)

  - Q：What is the problem with this?![](https://i.loli.net/2018/08/31/5b88f569ebfd3.png)

    - **Solutions：**"bottlenect" layers that use 1x1 convolutions to reduce feature depth

      ![](https://i.loli.net/2018/08/31/5b88f5e0b6157.png)

最后，

![](https://i.loli.net/2018/08/31/5b88f72d1c3fb.png)





### ResNet

- **ImageNet Large Scale Visual Recognition Challenge (ILSVRC) winners**

![](https://i.loli.net/2018/08/31/5b88f815598e8.png)

- [He et al., 2015]

  ![](https://i.loli.net/2018/08/31/5b88fa8036961.png)

- What happens when we continue stacking deeper layers on a "plain" convolutional neural networks?

  - The deeper model performs worse, but it’s not caused by overfitting!

- **Hypothesis:** the problem is an optimization problem, deeper models are harder to optimize.

  - The deeper model should be able to perform at least as well as the shallower model.
  - A solution by construction is copying the learned layers from the shallower model and setting additional layers to identity mapping.

- **Solution：**Use network layers to fit a residual mapping instead of directly trying to fit a desired underlying mapping.

  ![](https://i.loli.net/2018/08/31/5b88fbc5ab843.png)

最后，

![](https://i.loli.net/2018/08/31/5b88fd4da4820.png)

也用瓶颈层：

![](https://i.loli.net/2018/08/31/5b88fda293fac.png)

最后给出实践表现：

![](https://i.loli.net/2018/08/31/5b88fde953b33.png)





## An Analysis of Deep Neural Network Models for Practical Applications, 2017

![](https://i.loli.net/2018/08/31/5b890a7f2d6d1.png)

![](https://i.loli.net/2018/08/31/5b890a9db96a0.png)







## Other architectures to know...

### NiN (Network in Network)

[Lin et al. 2014]

![](https://i.loli.net/2018/08/31/5b891e99aad5f.png)





## Improving ResNets... 

### Identity Mappings in Deep Residual Networks

[He et al. 2016]

![](https://i.loli.net/2018/08/31/5b891f098f7f7.png)



### Wide ResNet

[Zagoruyko et al. 2016]

![](https://i.loli.net/2018/08/31/5b891f3549cfe.png)



### ResNeXT

[Xie et al. 2016]

![](https://i.loli.net/2018/08/31/5b891f81e4362.png)



### Stochastic Depth

[Huang et al. 2016]

![](https://i.loli.net/2018/08/31/5b891fb1d7dd1.png)

### "Good Practices for Deep Feature Fusion"

[Shao et al. 2016]

![](https://i.loli.net/2018/08/31/5b89202b18894.png)

![](https://i.loli.net/2018/08/31/5b89204a2b7ae.png)

### Squeeze-and-Excitation Network (SENet)

[Hu et al. 2017]

![](https://i.loli.net/2018/08/31/5b892057bab0c.png)

![](https://i.loli.net/2018/08/31/5b8921579f2d7.png)



## Beyond ResNets... 

### FractalNet: Ultra-Deep Neural Networks without Residuals

[Larsson et al. 2017]

![](https://i.loli.net/2018/08/31/5b8921999d9ae.png)



### DenseNet: Densely Connected Convolutional Networks

[Huang et al. 2017]

![](https://i.loli.net/2018/08/31/5b8921f208d21.png)

## Efficient networks...

### SqueezeNet: AlexNet-level Accuracy With 50x Fewer Parameters and <0.5Mb Model Size

[landola et al. 2017]

![](https://i.loli.net/2018/08/31/5b89225540064.png)



## Meta-learning: Learning to learn network architectures...

### NASNet (Neural Architecture Search with Reinforcement Learning)

[Zoph et al. 2016]

![](https://i.loli.net/2018/08/31/5b8922d461ee2.png)

### Learning Transferable Architectures for Scalable Image Recognition

[Zoph et al. 2017]

![](https://i.loli.net/2018/08/31/5b892320a3d26.png)





---

[返回到上一页](./index.html) | [返回到顶部](./cs231n_9.html)

---
<br>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
<br>

<script type="application/json" class="js-hypothesis-config">
  {
    "openSidebar": false,
    "showHighlights": true,
    "theme": classic,
    "enableExperimentalNewNoteButton": true
  }
</script>
<script async src="https://hypothes.is/embed.js"></script>


