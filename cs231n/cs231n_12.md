---
title: CS231n Lecture.12
date: 2018-08-31
---

[返回到上一页](./index.html)

---

[TOC]

> CS231n 课程的官方地址：http://cs231n.stanford.edu/index.html
>
> 该笔记根据的视频课程版本是 [Spring 2017](https://www.bilibili.com/video/av17204303/?p=29)(BiliBili)，PPt 资源版本是 [Spring 2018](http://cs231n.stanford.edu/syllabus.html).
>


# Lecture 12. Generative Models

## Supervised vs Unsupervised Learning

![](https://i.loli.net/2018/08/31/5b892f9693267.png)

## Generative Models

生成式模型是无监督学习范畴下的一类模型。在给定训练数据的情况下，我们任务的目标是从相同的数据分布中生成新的样本。那么我们有一些训练数据是由某种分布 $p_{\text{data}}(x)$ 中生成的，然后我们想从中习得一个模型 $p_{\text{model}}(x)$ 来以相同的分布生成样本。也就是说，我们想**要 $p_{\text{model}}$ 能学得和 $p_{\text{data}}$ 尽可能地相似**。

![](https://i.loli.net/2018/08/31/5b89329910a71.png)

生成式模型可以解决密度估计问题，也就是我们之前看到的**估计训练数据的潜在分布**的任务。这也是无监督学习的 核心问题。同时，我们将会看到该问题的一些特点：

- 我们可以用生成式模型来做显式的密度估计。在这种情况下我们会显式地定义并求解出目标模型 $p_{\text{model}}$ 。
- 我们也可以进行隐式的密度估计。这种情况下我们会习得一个能够从 $p_{\text{model}}$ 中生成样本的模型而不需要显式地定义它。



- Why Generative Models?
  1. 我们能够从数据分布中创造出我们想要的真实样本。
  2. 我们还可以用时间序列数据的生成式模型来进行仿真和规划，这样一来就能在强化学习应用中派上用场。
  3. 隐式表征的推断成为可能。学习隐式特征对于下游任务（在这里可以作为一般特征）来说是非常有用的。



![](https://i.loli.net/2018/08/31/5b8934dfb07d6.png)





### PixelRNN and PixelCNN

[van der Oord et al. 2016]

PixelRNN 和 PixelCNN 都属于全可见信念网络（fully visible belief networks），它们要做的就是对一个密度分布显式建模。那么在这种情况下，我们有图像数据 $x$，同时我们想要对该图像的概率分布或者似然 $p(x)$ 建模。对于这几种模型，我们使用链式法则将这一似然分解为一维分布的乘积。那么这里我们有每个像素 $x_i$ 的条件概率，其条件是给定所有下标小于 i 的像素 $(x_1,\dots,x_{i-1})$ 。这时图像中所有像素的概率或者联合概率就是所有这些像素点——所有这些似然的乘积。

![](https://i.loli.net/2018/08/31/5b89385d9b707.png)

一旦我们定义好这一似然，为了训练这一模型我们只要在该定义下最大化我们的训练数据的似然。

那么如果我们观察下右边的像素值概率分布，也就是给定所有在 $x_i$ 之前的像素值条件下的条件概率 $p(x_i)$ ，那么我们该如何建模呢？

我们之前已经了解到如果想要进行一些复杂的变换，我们可以利用神经网络实现这一切。神经网络是一种表达复杂变换的很好的方法。所以我们家下来会做的就是我们会只用一个神经网络来表达这一关于概率分布的复杂函数。

不过在这里你会遇到的一个问题是：即使我们打算用神经网络解决问题，我们也必须考虑如何对这些像素排序。我们曾说过在这一任务中我们有一个给定所有之前的像素，关于 $x_i$ 的分布 $p$ ，但是究竟什么是所有之前的像素呢？

- PixelRNN

  ![](https://i.loli.net/2018/08/31/5b893a00af09a.png)

- PixelCNN

  ![](https://i.loli.net/2018/08/31/5b893a7845dbf.png)



- Summary for PixelRNN and PixelCNN

  ![](https://i.loli.net/2018/08/31/5b893bc7d9993.png)

- So for...

  ![](https://i.loli.net/2018/09/08/5b932b6610442.png)






### Variational Autoencoders (VAE)

对于 VAEs（变分自编码器），我们将会定义一个不易处理的密度函数，我们要通过附加的隐变量 z 对其（密度函数）建模。我们的数据的似然 $p(x)$ 现在是下面等式右边的积分形式，也就是对所有可能的 z 值取期望：
$$
p_\theta(x) = \int p_\theta(z)p_\theta(x|z) dz
$$
这时我们就看到问题了，我们不能直接优化它，所以我们只能转而找出一个似然函数的下界，然后再对该下界进行优化。

接下来，先回顾下什么是自动编码器（Autoencoders）。



#### Autoencoders

- Encoder

  ![](https://i.loli.net/2018/08/31/5b893f5e82340.png)

- Decoder

  ![](https://i.loli.net/2018/08/31/5b8940b55d49a.png)

记得把 L2 损失用起来。。。。

事实上解码器可以用一个监督模型作为训练起始：

![](https://i.loli.net/2018/09/08/5b932de1bb4c3.png)

既然自编码器能重构数据，也可以从一个监督模型起始学习到特征，那么可以用它生成新数据么？



#### Variational Autoencoders

此处一篇 paper：

> Kingma and Welling, “Auto-Encoding Variational Bayes”, ICLR 2014

变分自编码器！这是通过向自编码器中加入随机因子获得的一种模型。这样一来我们就能从该模型中采样从而生成新数据。

![](https://i.loli.net/2018/09/08/5b933185cdbdc.png)

我们有 x 而 i 的范围是从 1 到 N。该数据是从某种潜在的不可观测的隐式表征 z 中生成的。那么从直观上讲，z 的元素要捕捉的信息是在训练数据中某种变化因子的多少。那么这就像是在说它们（z 中的元素）可能是某种类似于属性的东西，比如说我们打算生成一些面孔（图像），那这时候它（z 的元素）就有可能指代脸上有几分笑意，也可以指代眉毛或者头发的位置，也可以是头部的朝向。这些都有可能隐变量学习的。那么我们的生成过程就是要从关于 z 的先验分布中采样，对于某种属性，比如有几分笑。我们都可以假设一个我们觉得它应该是怎样一个先验分布，高斯分布就是一个对 z 中每个元素的一个自然的先验假设。同时我们将会通过从在给定 z 的条件下，x 的条件概率分布中 p(x|z) 中采样。那么我们先对 z 采样，也就是对每个隐变量采样，接下来我们就可以利用它并从这里对图像 x 采样。

---

![](https://i.loli.net/2018/09/08/5b9331a150020.png)

对于上述采样过程，真实的参数是 theta*。我们有关于先验假设和条件概率分布的参数。同时我们的目的在于获得一个生成式模型，从而利用它来生成新的数据。真实参数中的这些参数是我们想要估计并得出的。

我们先来谈谈该如何表示上述模型。如果我们要对该生成过程建模，事实上我们之前已经说过我们可以选一个简单的关于 z 的先验分布，比如高斯分布什么的，同时隐变量也选的合理。对于给定 z 的 x 的条件概率分布 p(x|z)，事实上它更复杂一些，因为我们要用它来生成一个图像。那么 p(x|z) 像我们之前看到的那样，当我们需要想要表示一个复杂函数的时候，我们可以用神经网络来表示，也就是说，用神经网络来对 p(x|z) 建模是一个很自然的选择。

---

![](https://i.loli.net/2018/09/08/5b93331e80ee3.png)

这时候，我们就要调用该解码器网络了。那就是说，我们想要选取隐式表征并将其解码为它所表示的图像。

那我们要如何训练这个模型呢？我们想要训练好该模型，这样一来就能习得一个对于这些参数的估计。如果你还记得训练生成式模型的策略，也就是回到那些完全可见信念网络（fully visible belief networks），如我们的 pixelRNNs 和 CNNs，一个直接且自然的策略就是通过最大化训练数据的似然函数来寻找这些模型的参数。之前我们看到过，在这种情况下在已经给定隐变量 z 的情况下，我们需要写出 x 的分布 p 并对所有可能的 z 值取期望。因为 z 是连续的，所以这里我们有这样一个表达式。在隐变量 z 下，我们的公式是这样的。

现在我们想要最大化它的似然，那么会有什么问题呢？我们可以直接通过求导来最大化似然吗？不。这个积分不会很好解。那咋整？



#### Variational Autoencoders: Intractability

![](https://i.loli.net/2018/09/10/5b95b875e6c32.png)

上面是我们的数据似然项，第一项是 z 的分布 p(z)，这里我们之前说过可以直接把它设定为简单的高斯分布；对于 p(x|z) 我们之前说要指定一个神经网络解码器，这样一来，任意给定一个 z，我们就能获得 p(x|z)，这也就是神经网络的输出。但是！我们想要对每一个 z 值计算 p(x|z)，现在还是很困难的，所以我们无法计算该积分。

---

![](https://i.loli.net/2018/09/10/5b95ba1503403.png)

那么数据的似然函数是难解的，结果就是它直接导致了模型的其他项。我们来看后验密度分布，也就是 p(z|x)，（根据贝叶斯公式）也就等于 p(x|z) 乘以 p(z) 再除以 p(x)，这也是难解的，我们现在有 p(x|z) 以及 p(z)，但是 p(x) 也就是我们的似然函数，也就是这个积分很难计算。

所以我们无法直接优化它（似然），不过我们会看到一个解决办法，一个可以让我们训练该模型的办法，那就是：如果在使用神经网络解码器来定义一个对 p(x|z) 建模神经网络的同时，我们现在额外定义一个编码器 q(z|x)，我们会把这成为编码器，因为我们打算将输入 x 编码为 z，从而得到似然 p(z|x)。也就是说，我们定义该网络来估计出 p(z|x)。没错，这个后验密度分布项仍然是难解的。如果我们用该附加网络来估计该后验分布，我们将会看到这事实上将使得我们得到一个数据似然的下界，而该下界是易解的，也是能优化的。



#### Details

![](https://i.loli.net/2018/09/10/5b95bd16d701a.png)

那么对于我指出的这些编码器和解码器说得再具体一点就是：在变分自编码器中，我们想要得到一个生成数据的概率模型。在讲自编码器的时候我们已经讲过这一概念，就是说，将输入 x 送入编码器得到一些特征 z，然后通过解码器网络再把 z 映射回到图像 x。所以这里我们还是有一个编码器网络和一个解码器网络，但是我们要将一切**随机化**。那么现在我们的参数是 $\phi$，解码器网络 q(z|x)，将会从这里输出一个均值和一个对角协方差矩阵。这些将会由编码器网络直接输出，同时对于解码器网络也一样，只不过它是从 z 开始，将会输出均值和关于 x 的对角协方差矩阵。给定 z 下，这里的 x 的维度和输入一样。该解码器网络由不同的编码器网络的参数 $\theta$ 决定。

现在为了真正得到 z，准确地讲是给定 x 下的 z 和给定 z 下的 x，我们将会从这些分布（p 和 q）中采样。那么现在我们的编码器和解码器网络，所给出的分别是 z 和 x 的（条件概率）分布，并会从这些分布中采样从而获得值。现在你应该已经了解采样和生成新数据的整个流程了。

还有一点要注意的是，这些编码器和解码器网络还有其他的叫法。编码器网络也是一种识别或者推断网络（recognition or inference network），因为我们是在给定 x 的条件下形成对隐式表征 z 的推断的，而对于解码器网络，我们将用来执行生成过程，所以你也会听到有人称它生成网络（generation network）。

---

![](https://i.loli.net/2018/09/10/5b95bfe4832c7.png)

既然已经配备编码器和解码器网络，下面我们再来求解下数据似然。这里我们会使用对数似然。

那么我们将会看到，如果我们想获得 log(p(x))，我们可以把它写成 p(x)，但要关于 z 取期望。所以 z 是采样自分布 q(z|x)，也就是我们目前为止通过编码器网络定义的分布。我们之所以能这么做，是因为 p(x) 并不依赖 z，z 不是它的一部分。现在关于 z 取期望的作用之后就能显现出来了（第一行）。

根据贝叶斯共识，从这一原始表达式开始（第二行），我们可以将其展开成 p(x|z) 乘以 p(z) 再除以 p(z|x) 的对数形式。下面为了求解它我们可以再乘一个常数，也就是乘以 q(z|x) 除以 q(z|x)，事实上只是乘了常数1（第三行）。这样一来，我们要做的就是把它写成三项之和的形式，这里的关键在于使用对数法则（第四行）。当我们仔细观察这三项，会发现第一项是 log(p(x|z)) 关于 z 取期望，接下来我们还会有两个 KL 项，实际上是 KL 散度项，它们是用来描述这两个分布有多么相似，也就是分布 q(z|x) 和分布 p(z) 有多相似，这事实上就是上面的（第二个）期望项，是对分布函数距离的度量。

---

![](https://i.loli.net/2018/09/10/5b95c345d6379.png)

接下来我们将会看到我们之前见过这些是能够写出的性质很好的 KL 项。现在如果我们再仔细观察这三项，第一项是由 p(x|z) 它由解码器提供，同时我们能够通过采样计算并估计出这些项的值，而且我们还会看到我们能够通过一种叫做重参数化（re-parametrization）的技巧来进行一次可微分的采样。如果你对重参数化感兴趣可以参考那篇论文。现在只要知道我们能够计算就行了，然后这些 KL 项里面，第二个 KL 项是两个高斯分布之间的 KL 散度，也就是我们的 q(z|x)，还记得是我们的编码器生成了一个均值和一个协方差么？它们构成了一个性质很好的高斯分布。同样，接下来我们的先验假设 p(z) 也是一个高斯分布。那么这样你有一个关于两个高斯分布的 KL 散度时，就等于你获得了一个很好的闭式解（closed form solution）。下面这第三个 KL 项是一个关于 q(z|x) 和 q(z|x) 的 KL 散度。但是我们知道 p(z|x) 是一个难解的后验概率，我们之前看到过，我们不想直接计算它，这也是为什么我们用 q 来估计它。那么这一项仍然是一个问题，那么这一项仍然是一个问题。

---

![](https://i.loli.net/2018/09/10/5b95c628722e1.png)

但是关于这第三项，我们目前所了解的是 KL 散度是对两个分布之间距离的度量，从定义上看它总是大于或等于零。因此我们能对它做的是，在前面我们有两项很好的解决，这两项合起来就是一个搞的定的下界，我们就可以对其取梯度并进行优化。p(x|z) 是可微分的，而这一 KL 项（也就是这个闭式解）也是可微分的，同时这是一个下界，因为我们知道右边的 KL 项，也就是难解的那一个是大于等于零的，于是我们就有了一个下界。

---

![](https://i.loli.net/2018/09/10/5b95ca36e09fe.png)

那么为了训练一个变分自编码器，接下来我们要做的是转而优化并最大化这一下界。因此我们是在优化数据似然的下界。这就意味着我们的数据总是有一个至少和这个我们要最大化的下界一样大的似然。这样一来，我们想要找到参数 $\theta$，通过估计参数 $\theta$ 和 $\phi$ 我们才可以最大化这一似然。

最后一个对于这一下界的直观解释是，其中第一项对所有采样的 z 取期望，z 是 x 经过编码器网络采样得到的，对 z 采样然后在所有的 z 值取 p(x|z) 的期望，这就是重构（reconstruction）。这实际上就是在说，如果我想让它变大，也就是让 p(x|z) 变大，这样一来就有点像是在最大限度地重构数据，所以和之前的自编码器一样。但这第二项是要让 KL 散度变小，让我们的近似后验分布和先验分布逐渐变得相似。这就意味着我们想让隐变量 z 遵循我们期望它遵循的分布类型和形状。

- Q：为什么将先验假设也就是隐变量分布设定为高斯分布？
  - 原因在于我们是在定义某种生成过程，该过程首先要对 z 采样然后对 x 采样。把它假设为高斯分布是因为这是一种合理的先验模型。对于隐变量的属性来说，分布成某种高斯分布是讲得通的，而且这么做可以让我们接下来能够优化模型

---

![](https://i.loli.net/2018/09/10/5b95cb6b60acd.png)

我们刚才讲的是我们如何得出该下界。现在我们把这些东西整理到一起，然后再把训练 AE（自动编码器）的流程过一遍。上图左上的公式就是我们要优化以及最大化的下界。现在对于前向传播来说，我们要按下面的流程处理。我有输入数据 x，我们会有小批量的输入数据。然后我们把它传递经过编码器网络，我们会得到 q(z|x)。我们会通过 q(z|x) 来计算 KL 项。然后我们会根据给定的 x 的 z 分布对 z 进行采样，由此一来，我们就获得了隐变量的样本，这些样本可以根据 x 推断获得。之后，我们继续把 z 传给第二个解码器网络。通过这个解码器网络，我们会获得 x 在给定 z 的条件下的分布的两个参数：均值和协方差。然后最终我们就可以在给定 z 的条件下从这个分布中采样获得 x，这里就会产生一些样本输出。我们在训练的时候，我们就是要获得该分布，而我们的损失项将会是给定 z 的条件下对训练像素值取对数。那么我们的损失函数要做的是就是最大化被重构的原始输入数据的似然。

现在，对于每个小批量输入，我们都要计算这一前向传播过程，取得所有我们所需的项。它们都是可微分的，所以我们接下来把它们全部反向传播回去并获得梯度。我们利用梯度不断更新我们的参数，包括生成器以及解码器，网络参数 $\theta$ 和 $\phi$ 从而最大化训练数据的似然。

---

![](https://i.loli.net/2018/09/10/5b95cdd16f44e.png)

那么一旦我们训练好 VAE。要想生成数据，我们只需要用解码器网络就可以了。现在我们在训练阶段就可以开始对 z 采样，而不用从后验分布中采样。在生成阶段，我们会从真实的生成过程中采样。因此，我们从设定好的先验分布中采样，然后接下来我们就要从这里对数据 x 采样。

右图就是在 MNIST 数据集上训练的 VAE。我们可以生成这些手写数字样本。我们之前说过，用 z 表示隐变量，这样一来，由于我们是从先验分布的不同部分采样的，所以我们可以通过改变 z 来获得不同的可解释的意义。关于二维 z 的数据流形，如果我们有一个二维的 z 然后我们让在某个区间内变化，比如该分布的百分比区间。接下来我们让 z1，z2 逐渐变化，那么从图上你就可以看到各种不同的 z1 和 z2 的组合所生成的图像（光滑地过渡变化）。

---

![](https://i.loli.net/2018/09/10/5b95cfa757ba1.png)

我们对 z 的先验假设是对角的，这样做是为了促使它成为独立的隐变量，这样一来它才能编码，具有可解释性的变量。因此，我们就有了 z 的不同维度。它们编码了不同的具有可解释性的变量（看人脸图）。

还有一点需要指出的是，这么做的好处就是这些 z 同时也是很好的特征表征。因为他们编码了这些不同的可解释的语义信息的多少。那么这样一来，我们就可以利用 q(z|x)，也就是我们训练好的编码器，我们给它一个输入图像 x，我们可以将之映射到 z，并把 z 用作下游任务的特征，比如监督学习，就像分类任务或者其他任务。

---

#### Pros vs Cons

![](https://i.loli.net/2018/09/10/5b95d1757fb4a.png)







### Generative Adversarial Networks (GAN)













---

[返回到上一页](./index.html) | [返回到顶部](./cs231n_12.html)

---
<br>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
<br>

<script type="application/json" class="js-hypothesis-config">
  {
    "openSidebar": false,
    "showHighlights": true,
    "theme": classic,
    "enableExperimentalNewNoteButton": true
  }
</script>
<script async src="https://hypothes.is/embed.js"></script>


