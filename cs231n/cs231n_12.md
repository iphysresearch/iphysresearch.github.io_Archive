---
title: CS231n Lecture.12
date: 2018-08-31
---

[返回到上一页](./index.html)

---

[TOC]

> CS231n 课程的官方地址：http://cs231n.stanford.edu/index.html
>
> 该笔记根据的视频课程版本是 [Spring 2017](https://www.bilibili.com/video/av17204303/?p=29)(BiliBili)，PPt 资源版本是 [Spring 2018](http://cs231n.stanford.edu/syllabus.html).
>


# Lecture 12. Generative Models

## Supervised vs Unsupervised Learning

![](https://i.loli.net/2018/08/31/5b892f9693267.png)

## Generative Models

生成式模型是无监督学习范畴下的一类模型。在给定训练数据的情况下，我们任务的目标是从相同的数据分布中生成新的样本。那么我们有一些训练数据是由某种分布 $p_{\text{data}}(x)$ 中生成的，然后我们想从中习得一个模型 $p_{\text{model}}(x)$ 来以相同的分布生成样本。也就是说，我们想**要 $p_{\text{model}}$ 能学得和 $p_{\text{data}}$ 尽可能地相似**。

![](https://i.loli.net/2018/08/31/5b89329910a71.png)

生成式模型可以解决密度估计问题，也就是我们之前看到的**估计训练数据的潜在分布**的任务。这也是无监督学习的 核心问题。同时，我们将会看到该问题的一些特点：

- 我们可以用生成式模型来做显式的密度估计。在这种情况下我们会显式地定义并求解出目标模型 $p_{\text{model}}$ 。
- 我们也可以进行隐式的密度估计。这种情况下我们会习得一个能够从 $p_{\text{model}}$ 中生成样本的模型而不需要显式地定义它。



- Why Generative Models?
  1. 我们能够从数据分布中创造出我们想要的真实样本。
  2. 我们还可以用时间序列数据的生成式模型来进行仿真和规划，这样一来就能在强化学习应用中派上用场。
  3. 隐式表征的推断成为可能。学习隐式特征对于下游任务（在这里可以作为一般特征）来说是非常有用的。



![](https://i.loli.net/2018/08/31/5b8934dfb07d6.png)





### PixelRNN and PixelCNN

[van der Oord et al. 2016]

PixelRNN 和 PixelCNN 都属于全可见信念网络（fully visible belief networks），它们要做的就是对一个密度分布显式建模。那么在这种情况下，我们有图像数据 $x$，同时我们想要对该图像的概率分布或者似然 $p(x)$ 建模。对于这几种模型，我们使用链式法则将这一似然分解为一维分布的乘积。那么这里我们有每个像素 $x_i$ 的条件概率，其条件是给定所有下标小于 i 的像素 $(x_1,\dots,x_{i-1})$ 。这时图像中所有像素的概率或者联合概率就是所有这些像素点——所有这些似然的乘积。

![](https://i.loli.net/2018/08/31/5b89385d9b707.png)

一旦我们定义好这一似然，为了训练这一模型我们只要在该定义下最大化我们的训练数据的似然。

那么如果我们观察下右边的像素值概率分布，也就是给定所有在 $x_i$ 之前的像素值条件下的条件概率 $p(x_i)$ ，那么我们该如何建模呢？

我们之前已经了解到如果想要进行一些复杂的变换，我们可以利用神经网络实现这一切。神经网络是一种表达复杂变换的很好的方法。所以我们家下来会做的就是我们会只用一个神经网络来表达这一关于概率分布的复杂函数。

不过在这里你会遇到的一个问题是：即使我们打算用神经网络解决问题，我们也必须考虑如何对这些像素排序。我们曾说过在这一任务中我们有一个给定所有之前的像素，关于 $x_i$ 的分布 $p$ ，但是究竟什么是所有之前的像素呢？

- PixelRNN

  ![](https://i.loli.net/2018/08/31/5b893a00af09a.png)

- PixelCNN

  ![](https://i.loli.net/2018/08/31/5b893a7845dbf.png)



- Summary for PixelRNN and PixelCNN

  ![](https://i.loli.net/2018/08/31/5b893bc7d9993.png)


### Variational Autoencoders (VAE)

对于 VAEs（变分自编码器），我们将会定义一个不易处理的密度函数，我们要通过附加的隐变量 z 对其（密度函数）建模。我们的数据的似然 $p(x)$ 现在是下面等式右边的积分形式，也就是对所有可能的 z 值取期望：
$$
p_\theta(x) = \int p_\theta(z)p_\theta(x|z) dz
$$
这是我们就看到问题了。我们不能直接优化它，所以我们只能转而找出一个似然函数的下界，然后再对该下界进行优化。

接下来，先回顾下什么是自动编码器（Autoencoders）。



#### Autoencoders

- Encoder

  ![](https://i.loli.net/2018/08/31/5b893f5e82340.png)

- Decoder

  ![](https://i.loli.net/2018/08/31/5b8940b55d49a.png)





### Generative Adversarial Networks (GAN)













---

[返回到上一页](./index.html) | [返回到顶部](./cs231n_12.html)

---
<br>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
<br>

<script type="application/json" class="js-hypothesis-config">
  {
    "openSidebar": false,
    "showHighlights": true,
    "theme": classic,
    "enableExperimentalNewNoteButton": true
  }
</script>
<script async src="https://hypothes.is/embed.js"></script>


