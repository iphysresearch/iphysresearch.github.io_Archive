<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>CS231n Lecture.10</title><style type='text/css'>html {overflow-x: initial !important;}:root { --bg-color: #ffffff; --text-color: #333333; --select-text-bg-color: #B5D6FC; --select-text-font-color: auto; --monospace: "Lucida Console",Consolas,"Courier",monospace; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
body { margin: 0px; padding: 0px; height: auto; bottom: 0px; top: 0px; left: 0px; right: 0px; font-size: 1rem; line-height: 1.42857143; overflow-x: hidden; background-image: inherit; background-size: inherit; background-attachment: inherit; background-origin: inherit; background-clip: inherit; background-color: inherit; background-position: inherit inherit; background-repeat: inherit inherit; }
iframe { margin: auto; }
a.url { word-break: break-all; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; word-wrap: break-word; position: relative; white-space: normal; padding-bottom: 70px; overflow-x: visible; }
.first-line-indent #write div, .first-line-indent #write li, .first-line-indent #write p { text-indent: 2em; }
.first-line-indent #write div :not(p):not(div), .first-line-indent #write div.md-htmlblock-container, .first-line-indent #write p *, .first-line-indent pre { text-indent: 0px; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
@media screen and (max-width: 500px) { 
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  .CodeMirror-sizer { margin-left: 0px !important; }
  .CodeMirror-gutters { display: none !important; }
}
#write > blockquote:first-child, #write > div:first-child, #write > figure:first-child, #write > ol:first-child, #write > p:first-child, #write > pre:first-child, #write > ul:first-child { margin-top: 30px; }
#write li > figure:first-child { margin-top: -20px; }
#write ol, #write ul { position: relative; }
img { max-width: 100%; vertical-align: middle; }
button, input, select, textarea { color: inherit; font-family: inherit; font-size: inherit; font-style: inherit; font-variant-caps: inherit; font-weight: inherit; font-stretch: inherit; line-height: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p { position: relative; }
h1, h2, h3, h4, h5, h6 { break-after: avoid-page; break-inside: avoid; orphans: 2; }
p { orphans: 4; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
.md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p { margin-top: 1rem; margin-bottom: 1rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.701961); color: rgb(85, 85, 85); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; cursor: pointer; }
sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
figure { overflow-x: auto; margin: 1.2em 0px; max-width: calc(100% + 16px); padding: 0px; }
figure > table { margin: 0px !important; }
tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 80px; }
.CodeMirror-gutters { border-right-width: 0px; background-color: inherit; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
#write pre { white-space: pre-wrap; }
#write.fences-no-line-wrapping pre { white-space: pre; }
#write pre.ty-contain-cm { white-space: normal; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background-image: inherit; background-size: inherit; background-attachment: inherit; background-origin: inherit; background-clip: inherit; background-color: inherit; position: relative !important; background-position: inherit inherit; background-repeat: inherit inherit; }
.md-diagram-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
#write .md-fences.mock-cm { white-space: pre-wrap; }
.md-fences.md-fences-with-lineno { padding-left: 0px; }
#write.fences-no-line-wrapping .md-fences.mock-cm { white-space: pre; overflow-x: auto; }
.md-fences.mock-cm.md-fences-with-lineno { padding-left: 8px; }
.CodeMirror-line, twitterwidget { break-inside: avoid; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; direction: ltr; background-position: 0px 0px; background-repeat: initial initial; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child, li > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; }
#write .footnote-line { white-space: pre-wrap; }
@media print { 
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid-page; break-before: avoid-page; }
  #write { margin-top: 0px; border-color: transparent !important; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  html.blink-to-pdf { font-size: 13px; }
  .typora-export #write { padding-left: 1cm; padding-right: 1cm; padding-bottom: 0px; break-after: avoid-page; }
  .typora-export #write::after { height: 0px; }
  @page { margin: 20mm 0px; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background-color: rgb(204, 204, 204); display: block; overflow-x: hidden; background-position: initial initial; background-repeat: initial initial; }
p > img:only-child { display: block; margin: auto; }
p > .md-image:only-child { display: inline-block; width: 100%; text-align: center; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.md-math-block { width: 100%; }
.md-math-block:not(:empty)::after { display: none; }
[contenteditable="true"]:active, [contenteditable="true"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-top-left-radius: 10px; border-top-right-radius: 10px; border-bottom-right-radius: 10px; border-bottom-left-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-content::after, .md-toc::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) { 
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, samp, tt { font-family: var(--monospace); }
kbd { margin: 0px 0.1em; padding: 0.1em 0.6em; font-size: 0.8em; color: rgb(36, 39, 41); background-color: rgb(255, 255, 255); border: 1px solid rgb(173, 179, 185); border-top-left-radius: 3px; border-top-right-radius: 3px; border-bottom-right-radius: 3px; border-bottom-left-radius: 3px; box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset; white-space: nowrap; vertical-align: middle; background-position: initial initial; background-repeat: initial initial; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.8; font-family: var(--monospace); }
code { text-align: left; }
a.md-print-anchor { white-space: pre !important; border: none !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; text-shadow: initial !important; background-position: 0px 0px !important; background-repeat: initial initial !important; }
.md-inline-math .MathJax_SVG .noError { display: none !important; }
.md-math-block .MathJax_SVG_Display { text-align: center; margin: 0px; position: relative; text-indent: 0px; max-width: none; max-height: none; min-height: 0px; min-width: 100%; width: auto; overflow-y: hidden; display: block !important; }
.MathJax_SVG_Display, .md-inline-math .MathJax_SVG_Display { width: auto; margin: inherit; display: inline-block !important; }
.MathJax_SVG .MJX-monospace { font-family: var(--monospace); }
.MathJax_SVG .MJX-sans-serif { font-family: sans-serif; }
.MathJax_SVG { display: inline; font-style: normal; font-weight: 400; line-height: normal; zoom: 90%; text-indent: 0px; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px; }
.MathJax_SVG * { transition: none; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="mermaid"] svg, [lang="flow"] svg { max-width: 100%; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom-width: 0px; }
video { max-width: 100%; display: block; margin: 0px auto; }
iframe { max-width: 100%; width: 100%; border: none; }
.highlight td, .highlight tr { border: 0px; }


:root {
    --side-bar-bg-color: #fff;
    --control-text-color: #777;
}

/* cyrillic-ext */
@font-face {
    font-family: 'Roboto Mono';
    font-style: normal;
    font-weight: 400;
    src: local('Roboto Mono'), local('RobotoMono-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/L0x5DF4xlVMF-BfR8bXMIjhGq3-cXbKDO1w.woff2') format('woff2');
    unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}

/* cyrillic */
@font-face {
    font-family: 'Roboto Mono';
    font-style: normal;
    font-weight: 400;
    src: local('Roboto Mono'), local('RobotoMono-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/L0x5DF4xlVMF-BfR8bXMIjhPq3-cXbKDO1w.woff2') format('woff2');
    unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}

/* greek-ext */
@font-face {
    font-family: 'Roboto Mono';
    font-style: normal;
    font-weight: 400;
    src: local('Roboto Mono'), local('RobotoMono-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/L0x5DF4xlVMF-BfR8bXMIjhHq3-cXbKDO1w.woff2') format('woff2');
    unicode-range: U+1F00-1FFF;
}

/* greek */
@font-face {
    font-family: 'Roboto Mono';
    font-style: normal;
    font-weight: 400;
    src: local('Roboto Mono'), local('RobotoMono-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/L0x5DF4xlVMF-BfR8bXMIjhIq3-cXbKDO1w.woff2') format('woff2');
    unicode-range: U+0370-03FF;
}

/* vietnamese */
@font-face {
    font-family: 'Roboto Mono';
    font-style: normal;
    font-weight: 400;
    src: local('Roboto Mono'), local('RobotoMono-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/L0x5DF4xlVMF-BfR8bXMIjhEq3-cXbKDO1w.woff2') format('woff2');
    unicode-range: U+0102-0103, U+0110-0111, U+1EA0-1EF9, U+20AB;
}

/* latin-ext */
@font-face {
    font-family: 'Roboto Mono';
    font-style: normal;
    font-weight: 400;
    src: local('Roboto Mono'), local('RobotoMono-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/L0x5DF4xlVMF-BfR8bXMIjhFq3-cXbKDO1w.woff2') format('woff2');
    unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}

/* latin */
@font-face {
    font-family: 'Roboto Mono';
    font-style: normal;
    font-weight: 400;
    src: local('Roboto Mono'), local('RobotoMono-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/L0x5DF4xlVMF-BfR8bXMIjhLq3-cXbKD.woff2') format('woff2');
    unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}

/* cyrillic-ext */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 300;
    src: local('Source Sans Pro Light'), local('SourceSansPro-Light'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwmhduz8A.woff2') format('woff2');
    unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}

/* cyrillic */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 300;
    src: local('Source Sans Pro Light'), local('SourceSansPro-Light'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwkxduz8A.woff2') format('woff2');
    unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}

/* greek-ext */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 300;
    src: local('Source Sans Pro Light'), local('SourceSansPro-Light'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwmxduz8A.woff2') format('woff2');
    unicode-range: U+1F00-1FFF;
}

/* greek */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 300;
    src: local('Source Sans Pro Light'), local('SourceSansPro-Light'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwlBduz8A.woff2') format('woff2');
    unicode-range: U+0370-03FF;
}

/* vietnamese */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 300;
    src: local('Source Sans Pro Light'), local('SourceSansPro-Light'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwmBduz8A.woff2') format('woff2');
    unicode-range: U+0102-0103, U+0110-0111, U+1EA0-1EF9, U+20AB;
}

/* latin-ext */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 300;
    src: local('Source Sans Pro Light'), local('SourceSansPro-Light'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwmRduz8A.woff2') format('woff2');
    unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}

/* latin */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 300;
    src: local('Source Sans Pro Light'), local('SourceSansPro-Light'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwlxdu.woff2') format('woff2');
    unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}

/* cyrillic-ext */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 400;
    src: local('Source Sans Pro Regular'), local('SourceSansPro-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNa7lqDY.woff2') format('woff2');
    unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}

/* cyrillic */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 400;
    src: local('Source Sans Pro Regular'), local('SourceSansPro-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qPK7lqDY.woff2') format('woff2');
    unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}

/* greek-ext */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 400;
    src: local('Source Sans Pro Regular'), local('SourceSansPro-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNK7lqDY.woff2') format('woff2');
    unicode-range: U+1F00-1FFF;
}

/* greek */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 400;
    src: local('Source Sans Pro Regular'), local('SourceSansPro-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qO67lqDY.woff2') format('woff2');
    unicode-range: U+0370-03FF;
}

/* vietnamese */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 400;
    src: local('Source Sans Pro Regular'), local('SourceSansPro-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qN67lqDY.woff2') format('woff2');
    unicode-range: U+0102-0103, U+0110-0111, U+1EA0-1EF9, U+20AB;
}

/* latin-ext */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 400;
    src: local('Source Sans Pro Regular'), local('SourceSansPro-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNq7lqDY.woff2') format('woff2');
    unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}

/* latin */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 400;
    src: local('Source Sans Pro Regular'), local('SourceSansPro-Regular'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qOK7l.woff2') format('woff2');
    unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}

/* cyrillic-ext */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 600;
    src: local('Source Sans Pro SemiBold'), local('SourceSansPro-SemiBold'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmhduz8A.woff2') format('woff2');
    unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}

/* cyrillic */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 600;
    src: local('Source Sans Pro SemiBold'), local('SourceSansPro-SemiBold'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwkxduz8A.woff2') format('woff2');
    unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}

/* greek-ext */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 600;
    src: local('Source Sans Pro SemiBold'), local('SourceSansPro-SemiBold'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmxduz8A.woff2') format('woff2');
    unicode-range: U+1F00-1FFF;
}

/* greek */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 600;
    src: local('Source Sans Pro SemiBold'), local('SourceSansPro-SemiBold'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwlBduz8A.woff2') format('woff2');
    unicode-range: U+0370-03FF;
}

/* vietnamese */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 600;
    src: local('Source Sans Pro SemiBold'), local('SourceSansPro-SemiBold'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmBduz8A.woff2') format('woff2');
    unicode-range: U+0102-0103, U+0110-0111, U+1EA0-1EF9, U+20AB;
}

/* latin-ext */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 600;
    src: local('Source Sans Pro SemiBold'), local('SourceSansPro-SemiBold'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmRduz8A.woff2') format('woff2');
    unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}

/* latin */
@font-face {
    font-family: 'Source Sans Pro';
    font-style: normal;
    font-weight: 600;
    src: local('Source Sans Pro SemiBold'), local('SourceSansPro-SemiBold'), url('file:///Users/Herb/Library/Application%20Support/abnerworks.Typora/themes/vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwlxdu.woff2') format('woff2');
    unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}

html {
    font-size: 16px;
}

body {
    font-family: Source Sans Pro, Helvetica Neue, Arial, sans-serif !important;
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

#write {
    max-width: 860px;
    margin: 0 auto;
    padding: 20px 30px 40px 30px;
    padding-top: 20px;
    padding-bottom: 100px;
}

#write p {
    /* text-indent: 2rem; */
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write>ul:first-child,
#write>ol:first-child {
    margin-top: 30px;
}

body>*:first-child {
    margin-top: 0 !important;
}

body>*:last-child {
    margin-bottom: 0 !important;
}

a {
    color: #42b983;
    font-weight: 600;
    padding: 0px 2px;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 1rem;
    font-weight: bold;
    line-height: 1.4;
    cursor: text;
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit;
}

h2 tt,
h2 code {
    font-size: inherit;
}

h3 tt,
h3 code {
    font-size: inherit;
}

h4 tt,
h4 code {
    font-size: inherit;
}

h5 tt,
h5 code {
    font-size: inherit;
}

h6 tt,
h6 code {
    font-size: inherit;
}

h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}

h2 {
    font-size: 1.75rem;
    line-height: 1.225;
    margin: 35px 0px 15px 0px;
}

h3 {
    font-size: 1.4rem;
    line-height: 1.43;
    margin: 20px 0px 7px 0px;
}

h4 {
    font-size: 1.2rem;
}

h5 {
    font-size: 1rem;
}

h6 {
    font-size: 1rem;
    color: #777;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li>ol,
li>ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body>h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body>h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body>h1:first-child+h2 {
    margin-top: 0;
    padding-top: 0;
}

body>h3:first-child,
body>h4:first-child,
body>h5:first-child,
body>h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

blockquote {
    border-left: 4px solid #42b983;
    padding: 10px 0px 10px 15px;
    color: #777;
    background-color: rgba(66, 185, 131, .1);
}

table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

table tr:nth-child(2n),
thead {
    background-color: #fafafa;
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

#write strong {
    padding: 0px 1px 0 1px;
}

#write em {
    padding: 0px 5px 0 2px;
}

#write table thead th {
    background-color: #f2f2f2;
}

#write .CodeMirror-gutters {
    border-right: none;
}

#write .md-fences {
    border: 1px solid #F4F4F4;
    -webkit-font-smoothing: initial;
    margin: 0.8rem 0 !important;
    padding: 0.3rem 0rem !important;
    line-height: 1.43rem;
    background-color: #F8F8F8 !important;
    border-radius: 2px;
    font-family: Roboto Mono, Source Sans Pro, Monaco, courier, monospace !important;
    font-size: 0.85rem;
    word-wrap: normal;
}

#write .CodeMirror-wrap .CodeMirror-code pre {
    padding-left: 12px;
}

#write code, tt {
    margin: 0 2px;
    padding: 2px 4px;
    border-radius: 2px;
    font-family: Source Sans Pro, Roboto Mono, Monaco, courier, monospace !important;
    font-size: 0.92rem;
    color: #e96900;
    background-color: #f8f8f8;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: #e96900;
}

/* heighlight. */
#write mark {
    background-color:#EBFFEB;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
    color: #222;
    font-weight: 500;
}

#write del {
    padding: 1px 2px;
}

.cm-s-inner .cm-link,
.cm-s-inner.cm-link {
    color: #22a2c9;
}

.cm-s-inner .cm-string {
    color: #22a2c9;
}

.md-task-list-item>input {
    margin-left: -1.3em;
}

@media screen and (min-width: 914px) {
    /*body {
        width: 854px;
        margin: 0 auto;
    }*/
}

@media print {
    html {
        font-size: 13px;
    }
    table,
    pre {
        page-break-inside: avoid;
    }
    pre {
        word-wrap: break-word;
    }
}

.md-fences {
    background-color: #f8f8f8;
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block>.code-tooltip {
    bottom: .375rem;
}

#write>h3.md-focus:before {
    left: -1.5625rem;
    top: .375rem;
}

#write>h4.md-focus:before {
    left: -1.5625rem;
    top: .285714286rem;
}

#write>h5.md-focus:before {
    left: -1.5625rem;
    top: .285714286rem;
}

#write>h6.md-focus:before {
    left: -1.5625rem;
    top: .285714286rem;
}

.md-image>.md-meta {
    /*border: 1px solid #ddd;*/
    border-radius: 3px;
    font-family: Consolas, "Liberation Mono", Courier, monospace;
    padding: 2px 0px 0px 4px;
    font-size: 0.9em;
    color: inherit;
}

.md-tag {
    color: inherit;
}

.md-toc {
    margin-top: 20px;
    padding-bottom: 20px;
}

.sidebar-tabs {
    border-bottom: none;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

/** focus mode */

.on-focus-mode blockquote {
    border-left-color: rgba(85, 85, 85, 0.12);
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: "Segoe UI", "Arial", sans-serif;
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.mac-seamless-mode #typora-sidebar {
    background-color: #fafafa;
    background-color: var(--side-bar-bg-color);
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}


</style>
</head>
<body class='typora-export' >
<div  id='write'  class = 'is-mac'><p><a href='./index.html'>返回到上一页</a></p><hr /><div class='md-toc' mdtype='toc'><p class="md-toc-content"><span class="md-toc-item md-toc-h1" data-ref="n311"><a class="md-toc-inner" style="" href="#header-n311">Lecture 10. Recurrent Neural Networks</a></span><span class="md-toc-item md-toc-h2" data-ref="n325"><a class="md-toc-inner" style="" href="#header-n325">Recurrent Neural Networks: Process Sequences</a></span><span class="md-toc-item md-toc-h2" data-ref="n328"><a class="md-toc-inner" style="" href="#header-n328">Recurrent Neural Networks: Non-Sequence Data</a></span><span class="md-toc-item md-toc-h2" data-ref="n344"><a class="md-toc-inner" style="" href="#header-n344">Recurrent Neural Network</a></span><span class="md-toc-item md-toc-h3" data-ref="n347"><a class="md-toc-inner" style="" href="#header-n347">Vanilla RNN</a></span><span class="md-toc-item md-toc-h3" data-ref="n353"><a class="md-toc-inner" style="" href="#header-n353">Computational Graph</a></span><span class="md-toc-item md-toc-h3" data-ref="n370"><a class="md-toc-inner" style="" href="#header-n370">Example: Character-level Language Model</a></span><span class="md-toc-item md-toc-h2" data-ref="n419"><a class="md-toc-inner" style="" href="#header-n419">Image Captioning</a></span><span class="md-toc-item md-toc-h2" data-ref="n428"><a class="md-toc-inner" style="" href="#header-n428">Image Captioning with Attention</a></span><span class="md-toc-item md-toc-h2" data-ref="n434"><a class="md-toc-inner" style="" href="#header-n434">Visual Question Answering: RNNs with Attention</a></span><span class="md-toc-item md-toc-h3" data-ref="n442"><a class="md-toc-inner" style="" href="#header-n442">Multilayer RNNs</a></span><span class="md-toc-item md-toc-h3" data-ref="n445"><a class="md-toc-inner" style="" href="#header-n445">Vanilla RNN Gradient Flow</a></span><span class="md-toc-item md-toc-h2" data-ref="n490"><a class="md-toc-inner" style="" href="#header-n490">Other RNN Variants</a></span><span class="md-toc-item md-toc-h2" data-ref="n493"><a class="md-toc-inner" style="" href="#header-n493">Summary</a></span></p></div><blockquote><p>CS231n 课程的官方地址：<a href='http://cs231n.stanford.edu/index.html' target='_blank' class='url'>http://cs231n.stanford.edu/index.html</a></p><p>该笔记根据的视频课程版本是 <a href='https://www.bilibili.com/video/av17204303/?p=21'>Spring 2017</a>(BiliBili)，PPt 资源版本是 <a href='http://cs231n.stanford.edu/syllabus.html'>Spring 2018</a>.</p><p>另有该 Lecture 10. 扩展讲义资料：</p><ul><li><a href='http://www.deeplearningbook.org/contents/rnn.html'>DL book RNN chapter</a> (optional) </li><li><a href='https://gist.github.com/karpathy/d4dee566867f8291f086'>min-char-rnn</a>, <a href='https://github.com/karpathy/char-rnn'>char-rnn</a>, <a href='https://github.com/karpathy/neuraltalk2'>neuraltalk2</a></li><li><a href='./The%20Unreasonable%20Effectiveness%20of%20Recurrent%20Neural%20Networks%20.html'>The Unreasonable Effectiveness of Recurrent Neural Networks</a>（中译版）</li></ul></blockquote><p>&nbsp;</p><h1><a name='header-n311' class='md-header-anchor '></a>Lecture 10. Recurrent Neural Networks</h1><p>&nbsp;</p><ul><li>Recall：</li></ul><p>小哥回顾了上节课中的经典模型，谈到 2014年的时候，还没有批量归一化技术。所以当初的 VGG 用了一些技巧和手段才实现了最终训练的收敛，而 GoogLeNet 是有一些辅助分类器把它们添加到下层，额外的梯度直接注入到网络的下层。以后用了批量归一化后，就不再需要这些笨拙的技巧使得网络收敛了。</p><p>ResNet 是一种有趣的框架，实际上它有两个很好的属性。</p><p>一个是如果我们把残差块中所有的权值设为零，那么所有的残差块就是<strong>恒等的</strong>，所以在某种程度上，这个模型是相对容易去训练的，并不需要添加额外的层。另外，在神经网络中添加 L2 正则化的原因是，一旦你使用了 L2 正则化，网络中的权值将迫使所有的参数趋近于零。也许你的标准卷积架构正趋近于零也许这有些说不通，但是在残差网络中，如果所有的参数逐渐趋向于0，那就是促使模型不再使用它不需要的层，因为它只是驱使残差块趋向同一性（identity），也就不需要进行分类。</p><p>另一个非常有用的属性是残差网络与反向路径中的<strong>梯度流</strong>有关。如果你还记得在反向传播中加法门的工作原理，当上游梯度通过一个加法门时，他将沿着两个不同的路径。所有，当上游梯度到来时，它将通过这些卷积块。但它也会通过这些残差连接直接连接到梯度。所以你可以看到当这些残差块堆叠在一起时，我们的网络最终会有几百个或上千个层，然后这些残差连接提供给梯度一个超级“高速公路”使梯度在整个网络中进行反向传播，这使网络可以更容易且更快地训练。实际上，即使模型有几百层的深度也能很好的收敛。在机器学习领域中，管理模型的梯度流是非常重要的，在递归网络中也是很普遍的。所以，我们还会再讨论到“梯度流”这个概念。</p><p>最近看到一些更为新奇的 CNN 构架，包括 DenseNet 和 FractalNet。一旦你用梯度流来思考这些构架，它们就更有意义了。像 DenseNet 和 FractalNet 这类模型中都加入了一些额外的快捷或恒等连接。如果你考虑到模型在反向传播中发生了什么，这些额外的有趣的拓扑结构可以为梯度从网络末端损失层更容易地流向整个网络中的不同层，提供一个直接的路径。所以我认为在 CNN 构架中，合理地管理梯度流使我们在过去几年里看到的最多的东西。随着越来越多的新奇构架被发明出来，我们将会看到更多的进步。</p><p><img src='assets/image-20180902152912957.png' alt='image-20180902152912957' referrerPolicy='no-referrer' /></p><p>&nbsp;</p><p>&nbsp;</p><h2><a name='header-n325' class='md-header-anchor '></a>Recurrent Neural Networks: Process Sequences</h2><p><img src='assets/image-20180902153947626.png' alt='image-20180902153947626' referrerPolicy='no-referrer' /></p><p>&nbsp;</p><h2><a name='header-n328' class='md-header-anchor '></a>Recurrent Neural Networks: Non-Sequence Data</h2><ul><li><p>Classify images by taking a series of “glimpses”</p><p><img src='assets/LimitedJointLarva-max-1mb.gif' alt='LimitedJointLarva-max-1mb' referrerPolicy='no-referrer' /></p><blockquote><p>Ba, Mnih, and Kavukcuoglu, “Multiple Object Recognition with Visual Attention”, ICLR 2015. </p><p>Gregor et al, “DRAW: A Recurrent Neural Network For Image Generation”, ICML 2015 </p></blockquote></li><li><p>Generate images one piece at a time!</p><p><img src='https://kevinzakka.github.io/assets/rnn/draw2.gif' alt='“DRAW: A Recurrent Neural Network For Image Generation gif”的图片搜索结果' referrerPolicy='no-referrer' /></p><p><img src='http://karpathy.github.io/assets/rnn/house_generate.gif' alt='&quot;DRAW: A Recurrent Neural Network For Image Generation gif&quot;的图片搜索结果' referrerPolicy='no-referrer' /></p><blockquote><p>Gregor et al, “DRAW: A Recurrent Neural Network For Image Generation”, ICML 2015 </p></blockquote></li></ul><p>&nbsp;</p><p>&nbsp;</p><h2><a name='header-n344' class='md-header-anchor '></a>Recurrent Neural Network</h2><p>每个 RNN 网络都有这样一个小小的循环核心单元（绿色块），它把 x 作为输入，将其传入 RNN。RNN 有一个<strong>内部隐藏态（internal hidden state）</strong>，这一隐藏态会在 RNN 每次读取新的输入时更新，然后这一内部隐藏态会将结果反馈至模型，当模型下一次读取输入时。通常来说，我们想让 RNN 在每一步都能给出输出，因此就有了这样的模式：它读取输入，更新隐藏态，并且生成输出。</p><p><img src='assets/image-20180902162134714.png' alt='image-20180902162134714' referrerPolicy='no-referrer' /></p><h3><a name='header-n347' class='md-header-anchor '></a>Vanilla RNN</h3><p>读取前一个隐藏态和当下的输入值 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-88-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.154ex" height="1.68ex" viewBox="0 -499.9 927.3 723.1" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E89-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E89-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E89-MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E89-MJMATHI-74" x="808" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-88">x_t</script>，生成下一个隐藏态。然后和你想象得一样简单，我们再用权重矩阵 W x h 将其与输入 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-88-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.154ex" height="1.68ex" viewBox="0 -499.9 927.3 723.1" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E89-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E89-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E89-MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E89-MJMATHI-74" x="808" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-88">x_t</script> 相乘，另一个权重矩阵 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-65-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.317ex" height="2.322ex" viewBox="0 -776.4 1858.6 999.7" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E66-MJMATHI-57" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path><path stroke-width="0" id="E66-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E66-MJMATHI-57" x="0" y="0"></use><g transform="translate(944,-150)"><use transform="scale(0.707)" xlink:href="#E66-MJMATHI-68" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E66-MJMATHI-68" x="576" y="0"></use></g></g></svg></span><script type="math/tex" id="MathJax-Element-65">W_{hh}</script> 与前一个隐藏态 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-87-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.262ex" height="2.322ex" viewBox="0 -776.4 1834.9 999.7" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E88-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path stroke-width="0" id="E88-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path stroke-width="0" id="E88-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="0" id="E88-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E88-MJMATHI-68" x="0" y="0"></use><g transform="translate(576,-150)"><use transform="scale(0.707)" xlink:href="#E88-MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E88-MJMAIN-2212" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="#E88-MJMAIN-31" x="1139" y="0"></use></g></g></svg></span><script type="math/tex" id="MathJax-Element-87">h_{t-1}</script> 相乘。我们将这两部分分别做乘法再相加，然后用 tanh 函数将结果缩放至 -1 至 1 之间，这样系统中就引入了一些非线性元素。</p><p><img src='assets/image-20180902163033254.png' alt='image-20180902163033254' referrerPolicy='no-referrer' /></p><p>为啥这里用 tanh 呢，而不是用其他非线性函数呢？回答：急什么？且听下文。。。。</p><p>在此架构中，如果我们想在每一步时都生成 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-91-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.963ex" height="1.936ex" viewBox="0 -555.2 845.3 833.8" role="img" focusable="false" style="vertical-align: -0.647ex;"><defs><path stroke-width="0" id="E92-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E92-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E92-MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E92-MJMATHI-74" x="692" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-91">y_t</script>，可能需要另外一个权重矩阵 W 来接受这一隐藏态，然后将其转换为某个 y，每一步都生成，例如分类评分的预测。</p><p>&nbsp;</p><h3><a name='header-n353' class='md-header-anchor '></a>Computational Graph</h3><p>值得注意的是：相同的 W。。。。</p><ul><li><p>Many to Many</p><p><img src='assets/image-20180902164653643.png' alt='image-20180902164653643' referrerPolicy='no-referrer' /></p></li><li><p>Many to One</p><p><img src='assets/image-20180902164716764.png' alt='image-20180902164716764' referrerPolicy='no-referrer' /></p></li><li><p>One to Many</p><p><img src='assets/image-20180902164741489.png' alt='image-20180902164741489' referrerPolicy='no-referrer' /></p></li><li><p>Sequence to Sequence: Many-to-one + one-to-many</p><p><img src='assets/image-20180902165002311.png' alt='image-20180902165002311' referrerPolicy='no-referrer' /></p><p>[Sutskever et al, “Sequence to Sequence Learning with Neural Networks”, NIPS 2014]</p></li></ul><p>&nbsp;</p><h3><a name='header-n370' class='md-header-anchor '></a>Example: Character-level Language Model</h3><p>Vocabulary: [h, e, l, o]; </p><p>Example training sequence: &quot;<strong>hello</strong>&quot;</p><ul><li>Training:</li></ul><p><img src='https://i.loli.net/2018/09/02/5b8bed5a9fd4b.png' alt='' referrerPolicy='no-referrer' /></p><ul><li><p>Testing</p><ul><li>At test-time sample characters one at a time, feed back to model</li></ul><p><img src='https://i.loli.net/2018/09/02/5b8bedb845b6d.png' alt='' referrerPolicy='no-referrer' /></p><ul><li><p>Q：为什么我们不是输出一个得分最高的字母？</p><ul><li>因为我们基于的是字母的概率分布图，所有我们不可能得到正确的字母，因此我们通过采样来解决这个问题。但是在实际中，你有时两者都会看到。所以你会选取概率最大的字母，而这种方法有时会更稳定一些，但是一般来说，softmax 方法的一个优势在于它可以让你的模型输出结果多样化，比如你的模型可能有相同的输入（相同的前缀），或者在图像标注时使用相同的图像，但是如果你使用概率分布而不是选择得分最大的，那么你会发现这些训练模型实际上可以产生多组不同类型的合理的输出序列，这取决于他们在第一个时间步中的样本。这实际上是一个好处，因为我们的输出结果更加多样化了。</li></ul></li><li><p>Q：在测试阶段，我们是否可以输入整个 softmax 向量，而不是一个 one-hot 向量？</p><ul><li>这存在两个问题。第一个问题是这与训练阶段所使用的数据不同。一般来说，如果你让训练好后的模型在测试阶段去做一些与训练阶段不同的任务，那么模型会产生一些偏差，它通常会输出一些无用的信息，你也会为此感到沮丧。另一个问题是在实际操作中，我们的词库可能非常大，而在我们刚刚讲的简单实例中词库里只有四个元素（字母），所以这个问题的规模不大，但是如果你想一次输出若干个单词，那么你的词库就是英语中所有的单词，而这可能会有数以万计的元素。所以在实际中，书里 one-hot 向量的首选通常使用稀疏向量，而不是用密集向量。如果你想加载 10,000 个元素的 softmax 向量，在计算时间上可能会比较长。所以这就是为什么我们通常使用 one-hot 向量，甚至在测试阶段。</li></ul></li></ul></li></ul><p>&nbsp;</p><ul><li><p>沿时间的截断反向传播方法（truncated backpropagation through time） </p><ul><li><strong>Problem</strong>: Forward through entire sequence to compute loss, then backward through entire sequence to compute gradient.</li><li><strong>Solution</strong>: Run forward and backward through <u>chunks</u> of the sequence instead of whole sequence</li></ul><p>即使我们输入的序列很长很长，甚至趋近于无限，我们采用的方法是，在训练模型时前向计算若干步，比如大概100这样的数目，也就是说我们可能会前向计算100步子序列的损失值，然后沿着这个子序列反向传播误差，并计算梯度更新参数。现在当我们重复上述过程，仍然会得到网络中的一些隐藏状态，那么我们从第一批数据中计算得到的。现在当我们计算下一批数据时，我们使用这些隐藏状态，所以前向计算过程是相同的，但是现在当我们基于下一批数据计算梯度时，我们只能根据第二批数据反向传播误差。现在我们基于沿时间的截断反向传播法计算一次梯度。这个过程会持续到我们使用下一批数据的时候，我们会复制这些隐藏层的状态值，但是前向计算和反向传播都只是持续一定数量的时间步。<img src='https://i.loli.net/2018/09/02/5b8bf3ae9de5e.png' alt='' referrerPolicy='no-referrer' /></p><ul><li><p>Q：这种方法是在做 Mark Hobb 假设么？</p><ul><li>不是的。因为我们在沿着时间使用这些隐藏层的状态值，这是在做 Marcovian 假设，从某种意义上来说，这是对隐藏状态的假设，但是这个隐藏状态是我们用来预测序列的未来值。但是这个假设从一开始是基于递归神经网络的计算公式，沿时间反向传播并不特殊。沿时间截断反向传播算法只是一种近似估计梯度的方法，这种方法不用反向传播遍历本来非常长的序列。</li></ul></li></ul></li></ul><p>&nbsp;</p><p>听上去很复杂是么？其实代码很简洁：(112行) <a href='https://gist.github.com/karpathy/d4dee566867f8291f086' target='_blank' class='url'>https://gist.github.com/karpathy/d4dee566867f8291f086</a></p><p>还有个有趣的例子是学一本代数拓扑的数学书，来自：<a href='https://stacks.math.columbia.edu' target='_blank' class='url'>https://stacks.math.columbia.edu</a></p><p>接下来的有趣例子和 paper 都在阐释这样一个事实：</p><blockquote><p>尽管我们在试着训练预测下一个字符的模型，但它最终会学到很多其他关于输入数据的结构的东西。</p><p>Karpathy, Johnson, and Fei-Fei: Visualizing and Understanding Recurrent Networks, ICLR Workshop 2016</p></blockquote><p>&nbsp;</p><h2><a name='header-n419' class='md-header-anchor '></a>Image Captioning</h2><p>此处可引用一批 papers：</p><blockquote><p>Explain Images with Multimodal Recurrent Neural Networks, Mao et al. </p><p>Deep Visual-Semantic Alignments for Generating Image Descriptions, Karpathy and Fei-Fei </p><p>Show and Tell: A Neural Image Caption Generator, Vinyals et al. </p><p>Long-term Recurrent Convolutional Networks for Visual Recognition and Description, Donahue et al. </p><p>Learning a Recurrent Visual Representation for Image Caption Generation, Chen and Zitnick</p></blockquote><p><img src='https://i.loli.net/2018/09/02/5b8bfb450e34c.png' alt='' referrerPolicy='no-referrer' /></p><h2><a name='header-n428' class='md-header-anchor '></a>Image Captioning with Attention</h2><p>此处的 paper：</p><blockquote><p>Xu et al, “Show, Attend, and Tell: Neural Image Caption Generation with Visual Attention”, ICML 2015 </p></blockquote><p><img src='https://i.loli.net/2018/09/02/5b8bfcb2cce67.png' alt='' referrerPolicy='no-referrer' /></p><p>&nbsp;</p><h2><a name='header-n434' class='md-header-anchor '></a>Visual Question Answering: RNNs with Attention</h2><p>此处的 papers：</p><blockquote><p>Agrawal et al, “VQA: Visual Question Answering”, ICCV 2015 </p><p>Zhu et al, “Visual 7W: Grounded Question Answering in Images”, CVPR 2016 </p></blockquote><p><img src='https://i.loli.net/2018/09/02/5b8bfd6578706.png' alt='' referrerPolicy='no-referrer' /></p><p>&nbsp;</p><p>&nbsp;</p><h3><a name='header-n442' class='md-header-anchor '></a>Multilayer RNNs</h3><p><img src='https://i.loli.net/2018/09/02/5b8bfe5d1c2e4.png' alt='' referrerPolicy='no-referrer' /></p><p>&nbsp;</p><h3><a name='header-n445' class='md-header-anchor '></a>Vanilla RNN Gradient Flow</h3><p>此处有两篇 papers：</p><blockquote><p>Bengio et al, “Learning long-term dependencies with gradient descent is difficult”, IEEE Transactions on Neural Networks, 1994 </p><p>Pascanu et al, “On the difficulty of training recurrent neural networks”, ICML 2013</p></blockquote><p>接下来要说清楚的是：在我们训练它们的时候，这些模型会发生什么？</p><p>这里我们将 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-88-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.154ex" height="1.68ex" viewBox="0 -499.9 927.3 723.1" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E89-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E89-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E89-MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E89-MJMATHI-74" x="808" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-88">x_t</script> 作为当前时间步的输入，并且输入前一个隐藏状态 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-87-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.262ex" height="2.322ex" viewBox="0 -776.4 1834.9 999.7" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E88-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path stroke-width="0" id="E88-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path stroke-width="0" id="E88-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="0" id="E88-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E88-MJMATHI-68" x="0" y="0"></use><g transform="translate(576,-150)"><use transform="scale(0.707)" xlink:href="#E88-MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E88-MJMAIN-2212" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="#E88-MJMAIN-31" x="1139" y="0"></use></g></g></svg></span><script type="math/tex" id="MathJax-Element-87">h_{t-1}</script>，然后将这两个向量堆叠起来，我们可以只把他们堆在一起，之后将它与权重矩阵做矩阵乘法来得到一个输出，再将输出送入 tanh 激活函数，这就得到下一个隐藏状态，这就是 Vanilla 递归神经网络的基本函数形式。</p><p><img src='assets/image-20180903133910877.png' alt='image-20180903133910877' referrerPolicy='no-referrer' /></p><p>现在我们需要考虑的是当我们尝试计算梯度时，反向传播在这个结构中如何进行。所以在反向传播过程中，我们会得到 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-90-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.163ex" height="2.322ex" viewBox="0 -776.4 931.3 999.7" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E91-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path stroke-width="0" id="E91-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E91-MJMATHI-68" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E91-MJMATHI-74" x="814" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-90">h_t</script> 的导数，以及关于 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-90-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.163ex" height="2.322ex" viewBox="0 -776.4 931.3 999.7" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E91-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path stroke-width="0" id="E91-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E91-MJMATHI-68" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E91-MJMATHI-74" x="814" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-90">h_t</script> 的损失函数的导数，在反向传播通过这个单元时，我们需要计算关于 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-87-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.262ex" height="2.322ex" viewBox="0 -776.4 1834.9 999.7" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E88-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path stroke-width="0" id="E88-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path stroke-width="0" id="E88-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="0" id="E88-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E88-MJMATHI-68" x="0" y="0"></use><g transform="translate(576,-150)"><use transform="scale(0.707)" xlink:href="#E88-MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E88-MJMAIN-2212" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="#E88-MJMAIN-31" x="1139" y="0"></use></g></g></svg></span><script type="math/tex" id="MathJax-Element-87">h_{t-1}</script> 的损失函数的导数。当我们计算反向传播时，我们可以看到梯度沿着这条红色的路线方向流动。因此，梯度会反向流过 tanh 门，然后会反向流过矩阵乘法门。 在作业中我们会看到在实现这些矩阵乘法的层时，当反向传播流过这个矩阵乘法门时，最后实际使用权重矩阵的转置来做矩阵乘法。这意味着每次反向传播经过其中一个 Vanilla 地推神经网络单元时，实际是和部分权重矩阵相乘。</p><p>现在你可以设想我们把许多递归神经网络单元连接成一个序列，因为这是一个递归神经网络，我们想要的是一个模型序列，你可以设想梯度流穿过一系列这样的层时会发生什么。之后会有一些不对劲的事情发生，因为当我们计算关于 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-75-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.391ex" height="2.322ex" viewBox="0 -776.4 1029.6 999.7" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E76-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path stroke-width="0" id="E76-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E76-MJMATHI-68" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E76-MJMAIN-30" x="814" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-75">h_0</script> 的损失函数的梯度时，反向传播需要经过递归神经网络中的每一个单元。每次反向传播经过一个单元时，都要使用其中某一个 W 的转置。这意味着最终的表达式对 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-75-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.391ex" height="2.322ex" viewBox="0 -776.4 1029.6 999.7" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E76-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path stroke-width="0" id="E76-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E76-MJMATHI-68" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E76-MJMAIN-30" x="814" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-75">h_0</script> 的梯度的表达式，将会包含很多很多权重矩阵因子，这将会很糟糕。或许你可以不考虑矩阵权重，但假如我们考虑标量，如果我们有一些标量我们不断地将同一个数值做乘法不断相乘，可能对四个时间步没问题，但对于有一百或几百个时间步的情况，这样不断对同一个值做乘法是非常糟糕的。在标量的情形中，它要么在这个值大于1时，发生（梯度）爆炸，要么当这个值绝对值小于1时（梯度）逐渐消失减小到零。唯一能够让这不发生的情况是当这个值恰好为1时，但这在实际中很少见。</p><p><img src='assets/image-20180903150157372.png' alt='image-20180903150157372' referrerPolicy='no-referrer' /></p><p>这让我们可以同样延伸到矩阵的情况，但现在不再是标量的绝对值，你需要关注权重矩阵的最大的奇异值。如果最大奇异值大于1，那么在反向传播时，当我们用权重矩阵一个一个相乘时，<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-75-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.391ex" height="2.322ex" viewBox="0 -776.4 1029.6 999.7" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E76-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path stroke-width="0" id="E76-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E76-MJMATHI-68" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E76-MJMAIN-30" x="814" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-75">h_0</script> 的梯度将会非常非常大（如果这个矩阵非常大），这就是我们称之为<strong>梯度爆炸（Exploding gradients）</strong>的问题。随着时间步数目的增加，梯度将会随着反向传播流向的深度增加而产生指数级爆炸。如果最大奇异值小于1，情况则相反，这是梯度会指数级的不断缩小，但我们反向传播不断乘上越来越多权重矩阵因子，这成为<strong>梯度消失（Vanishing gradients）</strong>问题。</p><p>有一个小技巧是大家经常用来解决梯度爆炸问题的方法，成为<strong>梯度截断（Gradient clipping）</strong>，也是一种启发式算法。在我们计算梯度之后，如果梯度的 L2 范式大于某个阈值，就将它剪断并做除法。就是这样把它剪短，这样的梯度就有最大阈值。这是比较粗暴的方法，但在实际中使用较多，在训练循环神经网络时，这是一种相对有用的方法来防止发生梯度爆炸问题。而对梯度消失的问题，常见的做法是换一个更加复杂的 RNN 结构。这就是<strong>使用 LSTM （Long Short Term Memory），即长短期记忆网络，的原因</strong>，是递归神经网络的一种更高级的递归结构。LSTM 被设计用来缓解梯度消失和梯度爆炸问题。我们不是直接在输出上想办法，而是设计一些更好的结构来获取更好的梯度流动，可以类比一下我们之前课程见到过的那些高级的 CNN 结构。</p><p>此处一篇 paper：</p><blockquote><p>Hochreiter and Schmidhuber, “Long Short Term Memory”, Neural Computation 1997</p></blockquote><p>另一点是 LSTM cell 这个想法起源于 1997 年。所以 LSTM 这个想法已经非常久远了，人们差不多是在上世纪九十年代就着手研究如何实现这些非常超前的想法。直到 20 年后的今天，这些模型才开始变得流行起来。</p><p><img src='assets/image-20180903150415732.png' alt='image-20180903150415732' referrerPolicy='no-referrer' /></p><p>这些 LSTM 的函数形式很有趣。我们之前讲过 vanilla 递归神经网络，它具备隐藏状态，在每个时间步中利用递归关系来更新隐藏状态。现在考虑 LSTM，我们在每个时间步中都维持两个隐藏状态，一个是 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-90-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.163ex" height="2.322ex" viewBox="0 -776.4 931.3 999.7" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E91-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path stroke-width="0" id="E91-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E91-MJMATHI-68" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E91-MJMATHI-74" x="814" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-90">h_t</script>，就简单叫做隐藏状态，可以类比 vanilla 递归神经网络中对应的隐藏状态。但是 LSTM 还有第二个向量 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-89-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.831ex" height="1.68ex" viewBox="0 -499.9 788.3 723.1" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E90-MJMATHI-63" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path><path stroke-width="0" id="E90-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E90-MJMATHI-63" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E90-MJMATHI-74" x="612" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-89">c_t</script>，这个叫做单元状态的向量相当于保留在 LSTM 内部的隐藏状态，并且不会完全暴露到外部去。我们可以看到通过这个更新公式，也就是说，首先我们可以使用两个输入来计算四个门，即 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-82-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.418ex" height="2.45ex" viewBox="0 -776.4 3194 1055" role="img" focusable="false" style="vertical-align: -0.647ex;"><defs><path stroke-width="0" id="E83-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E83-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path stroke-width="0" id="E83-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path><path stroke-width="0" id="E83-MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path stroke-width="0" id="E83-MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E83-MJMATHI-69" x="0" y="0"></use><use xlink:href="#E83-MJMAIN-2C" x="345" y="0"></use><use xlink:href="#E83-MJMATHI-66" x="789" y="0"></use><use xlink:href="#E83-MJMAIN-2C" x="1339" y="0"></use><use xlink:href="#E83-MJMATHI-6F" x="1784" y="0"></use><use xlink:href="#E83-MJMAIN-2C" x="2269" y="0"></use><use xlink:href="#E83-MJMATHI-67" x="2713" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-82">i,f,o,g</script>。我们使用这些门来更新单元状态 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-89-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.831ex" height="1.68ex" viewBox="0 -499.9 788.3 723.1" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E90-MJMATHI-63" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path><path stroke-width="0" id="E90-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E90-MJMATHI-63" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E90-MJMATHI-74" x="612" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-89">c_t</script>，然后我们将这些单元状态（作为参数）来计算下一个时间步中的隐藏状态。</p><p>在 LSTM 中第一件事情要做的就是：给定前一时刻的隐藏状态 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-90-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.163ex" height="2.322ex" viewBox="0 -776.4 931.3 999.7" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E91-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path stroke-width="0" id="E91-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E91-MJMATHI-68" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E91-MJMATHI-74" x="814" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-90">h_t</script> 和当前时刻的输入向量 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-88-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.154ex" height="1.68ex" viewBox="0 -499.9 927.3 723.1" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E89-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E89-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E89-MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E89-MJMATHI-74" x="808" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-88">x_t</script>，就像 vanilla 神经网络一样。在 vanilla 神经网络中，拿着两个输入向量拼接到一起，然后进行矩阵相乘，由此计算得到了 RNN 中下一个时刻的隐藏状态。现在 LSTM 的做法有点不同。我们仍然拿上一时间步的隐藏状态和当前的输入堆叠在一起，然后乘上一个非常大的权重矩阵 W，计算得到四个不同的门向量，每个门向量的大小和隐状态都一样。有时候你可能会见到不同的写法，有时候作者们会为每个门都用一个相应的权重矩阵，有时候作者们又会把这些矩阵结合成一个大的权重矩阵，其实本质都是一样的，都是通过隐藏状态和当前输入来计算四个门。</p><p>这四个门通常写作 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-82-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.418ex" height="2.45ex" viewBox="0 -776.4 3194 1055" role="img" focusable="false" style="vertical-align: -0.647ex;"><defs><path stroke-width="0" id="E83-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E83-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path stroke-width="0" id="E83-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path><path stroke-width="0" id="E83-MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path stroke-width="0" id="E83-MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E83-MJMATHI-69" x="0" y="0"></use><use xlink:href="#E83-MJMAIN-2C" x="345" y="0"></use><use xlink:href="#E83-MJMATHI-66" x="789" y="0"></use><use xlink:href="#E83-MJMAIN-2C" x="1339" y="0"></use><use xlink:href="#E83-MJMATHI-6F" x="1784" y="0"></use><use xlink:href="#E83-MJMAIN-2C" x="2269" y="0"></use><use xlink:href="#E83-MJMATHI-67" x="2713" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-82">i,f,o,g</script>，简称 <strong>ifog</strong>。要记住这四个门的名字也很容易：i 代表输入门（input gate），表示 LSTM 要接受多少新的输入信息；f 是遗忘门（forget gate），表示要遗忘多少之前的单元记忆，就是上一时间步的记忆信息；o 是输出门（output gate），表示我们要展现多少信息给外部；G 没有一个好名字，一般叫门之门（gate gate），表示我们有多少信息要写入到输入单元中。可以注意到这四个门都用了不同的非线性函数，<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-83-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.271ex" height="2.45ex" viewBox="0 -776.4 2269.3 1055" role="img" focusable="false" style="vertical-align: -0.647ex;"><defs><path stroke-width="0" id="E84-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E84-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path stroke-width="0" id="E84-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path><path stroke-width="0" id="E84-MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E84-MJMATHI-69" x="0" y="0"></use><use xlink:href="#E84-MJMAIN-2C" x="345" y="0"></use><use xlink:href="#E84-MJMATHI-66" x="789" y="0"></use><use xlink:href="#E84-MJMAIN-2C" x="1339" y="0"></use><use xlink:href="#E84-MJMATHI-6F" x="1784" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-83">i,f,o</script> 都用了 sigmoid，这意味着输出值都在 0 和 1 之间，但是门之门用了 tanh 函数，这意味着输出都在 -1 和 1 之间。这有点怪怪的，但是其实是说得通的，如果你想象这些都是二元的值，想象取到这两个极端的值是什么情景。如果你看看我们算的这些门，如果你看第二条公式，可以看到是上一时间步的单元状态经过了遗忘门的逐元素乘操作。这个遗忘门的话，可以看做都是 0 和 1 的向量，这些值告诉我们对于单元状态中的每个元素，如果遗忘门中的值是零，说明我们想要忘记这个单元状态中的元素值；如果遗忘门中的值是 1，说明我们想要记住单元状态中的值。一旦我们使用了遗忘门来断开部分单元状态的值，那么我们就需要输入门，即 i 和 g 做逐元素乘法。i 是由 0 和 1 构成的向量，因为 i 是经过了一个 sigmoid 函数得到的，输入门告诉我们，对于单元状态的每个元素值，如果 i 的值是 1，说明我们想要保留单元状态的那个元素，或者如果 i 的那个位置是 0 的话，说明我们不想保留单元状态对应的那个元素。现在考虑门之门，因为这个是 tanh 函数处理后的结果，所以值都在 -1 和 1 之间。这些值是当前时间步中我们可能会写入到单元状态中去的候选值。如果你看看单元状态的公式，可以看到每个时间步中，单元状态都有这些不同的独立的标量值，在每个时间步中可以被加一或者减去一，就是说，在单元状态的内部，我们可以保留或者遗忘之前的状态，在每个时间步中我们可以给单元状态的每个元素加上或者减去最多是 1 的值，所以你可以把单元状态的每个元素看作是小的标量计数器，每个时间步中只能自增或者自减。在计算了单元状态 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-89-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.831ex" height="1.68ex" viewBox="0 -499.9 788.3 723.1" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E90-MJMATHI-63" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path><path stroke-width="0" id="E90-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E90-MJMATHI-63" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E90-MJMATHI-74" x="612" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-89">c_t</script> 之后，我们将通过更新过的单元状态来计算隐状态 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-90-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.163ex" height="2.322ex" viewBox="0 -776.4 931.3 999.7" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E91-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path stroke-width="0" id="E91-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E91-MJMATHI-68" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E91-MJMATHI-74" x="814" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-90">h_t</script>，这个向量是要暴露到外部的。因为前面把单元状态解释成计数器，而且每个时间步都是加一或者减一，我们想要把这个计数用 tanh 压缩到 0 和 1 之间，现在用这个输出门逐元素乘上单元状态。因为这个输出门是经过 sigmoid 函数后的结果，所以它的组成元素大部分是 0 和 1，输出门告诉我们对于单元状态中的每个元素，我们在每个时刻计算外部的隐状态时，到底想不想暴露那个单元状态的元素。</p><p><img src='assets/image-20180903163327088.png' alt='image-20180903163327088' referrerPolicy='no-referrer' /></p><p>对于上图左边所示的上一时间步中的单元状态 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-87-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.262ex" height="2.322ex" viewBox="0 -776.4 1834.9 999.7" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E88-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path stroke-width="0" id="E88-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path stroke-width="0" id="E88-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="0" id="E88-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E88-MJMATHI-68" x="0" y="0"></use><g transform="translate(576,-150)"><use transform="scale(0.707)" xlink:href="#E88-MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E88-MJMAIN-2212" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="#E88-MJMAIN-31" x="1139" y="0"></use></g></g></svg></span><script type="math/tex" id="MathJax-Element-87">h_{t-1}</script> 和隐藏状态 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-87-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.262ex" height="2.322ex" viewBox="0 -776.4 1834.9 999.7" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E88-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path stroke-width="0" id="E88-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path stroke-width="0" id="E88-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="0" id="E88-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E88-MJMATHI-68" x="0" y="0"></use><g transform="translate(576,-150)"><use transform="scale(0.707)" xlink:href="#E88-MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E88-MJMAIN-2212" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="#E88-MJMAIN-31" x="1139" y="0"></use></g></g></svg></span><script type="math/tex" id="MathJax-Element-87">h_{t-1}</script> 以及当前时间步中的输入 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-88-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.154ex" height="1.68ex" viewBox="0 -499.9 927.3 723.1" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E89-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E89-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E89-MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E89-MJMATHI-74" x="808" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-88">x_t</script>。我们要把上一时间步的隐藏状态和当前时间步的输入堆积在一起，然后乘上权重矩阵 W，来得到四个门。这里我省略了非线性函数，因为之前的讲义提到过。遗忘门是和上一时间步的单元状态做逐元素乘法，输入门和门之门也是做逐元素乘法，然后加在一起，就得到了下一时间步的单元状态 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-89-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.831ex" height="1.68ex" viewBox="0 -499.9 788.3 723.1" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E90-MJMATHI-63" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path><path stroke-width="0" id="E90-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E90-MJMATHI-63" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E90-MJMATHI-74" x="612" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-89">c_t</script>，下一时间步的单元经过一个 tanh 函数的压缩，又经过输出门的逐元素乘法，得到了下一时间步的隐藏状态 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-90-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.163ex" height="2.322ex" viewBox="0 -776.4 931.3 999.7" role="img" focusable="false" style="vertical-align: -0.519ex;"><defs><path stroke-width="0" id="E91-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path stroke-width="0" id="E91-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E91-MJMATHI-68" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E91-MJMATHI-74" x="814" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-90">h_t</script>。</p><p>若在反向传播路径中，计算了单元状态的梯度，结果是很漂亮的。我们通过传输进来的单元获得了上游梯度，然后我们通过加法运算，记住这个加法匀速三仅仅是将上游的梯度复制在两个分支里，这样上游的梯度直接被复制并且通过元素相乘的方式直接贯穿了反向传播过程，然后上游的梯度最终通过遗忘门得到相乘后的元素。当我们通过这个单元状态向后反向传播时，对于上游的单元状态梯度，唯一会发生的事情就是它最终会通过遗忘门得到相乘后的元素。这确实比原始循环神经网络好很多，原因有两个：</p><ol start='' ><li>第一个原因是这里的遗忘门是矩阵元素相乘，而不是矩阵相乘。而矩阵元素相乘会比矩阵相乘好一点；</li><li>第二个原因是矩阵元素相乘可能会在不同的时间点乘以一个不同的遗忘门。因此要记住，在 vanilla 循环神经网络中，我们会不断地乘以相同的权重矩阵一遍又一遍，显而易见地这会导致梯度爆炸或者梯度消失。但是在这个 LSTM 例子中，遗忘门在每一个时间点会发生变化，因此对于这个模型来说避免出现梯度爆炸或者梯度消失问题。最后，因为遗忘门是一个 sigmoid 函数，所以矩阵元素相乘的结果会保证在 0 和 1 之间，这也会使数值性质更好。如果你想象一下这些矩阵元素一遍又一遍地相乘就会明白。</li></ol><p>另一个要注意的是在原始循环神经网络环境中，我们看到在反向传播过程中，在每一个梯度传播的时间步长中都会经过一个 tanh 激活函数。但是现在在一个 LSTM 中，使用隐藏状态来计算输出 <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-91-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.963ex" height="1.936ex" viewBox="0 -555.2 845.3 833.8" role="img" focusable="false" style="vertical-align: -0.647ex;"><defs><path stroke-width="0" id="E92-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E92-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E92-MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E92-MJMATHI-74" x="692" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-91">y_t</script>，因此从最后的隐藏状态单元反向传播到第一个单元状态，在反向传播的路径上，我们只通过一个单一的非线性 tanh 向后传播，而不是在每一个时间步长中单独设置 tanh 函数。</p><p><img src='assets/image-20180903170343489.png' alt='image-20180903170343489' referrerPolicy='no-referrer' /></p><p>梯度高速公路！梯度相对畅通无阻地</p><ul><li><p>Q：关于 W 的梯度咋整呢？</p><ul><li>W 的梯度其传播方式是：在每一个时间步长中获得当前的单元状态以及当前的隐藏状态，这会给我们在这个时间点的 W 的局部梯度。所以由于我们的单元状态（这里仅指在 vanilla 循环神经网络例子中），我们会将这些第一个时间不长 W 的梯度相加，从而计算出 W 的最终梯度。但是现在有一个很长的序列，我们仅仅得到序列末尾的梯度，然后进行反向传播，我们会得到每一个时间步长 W 的局部梯度，而这个 W 上的局部梯度将会经过 c 和 h 的梯度。由于在 LSTM 的例子中，我们很好地保存了 c 的梯度，所以在每一个时间步长的 W 的局部梯度，也会随着时间的推移更加平稳地向前和向后传播。</li></ul></li><li><p>Q：由于也是非线性的，这是否也会影响梯度消失的问题？</p><ul><li>确实是这样。事实上，你们可能会想这些遗忘门也许总是小于 0，或者总是小于1，当持续的让梯度通过这些遗忘门的时候，也许会出现梯度消失现象。人们在训练中使用的一种方法是他们有时候会初始化遗忘门的偏置参数，使其成为达到某种程度的正数，以便在训练开始的时候，这些遗忘门总是非常接近于1，至少在训练开始的时候，我们并没有这样，由于梯度都被初始化为接近于1，所以经过这些遗忘门的梯度相对简洁。在整个训练的过程中，这个模型会学习这些偏置参数，还会稍微学习一下在哪个地方它需要忘记。在这里，确实仍然存在出现梯度消失的可能性，但是相比于 vanilla 循环神经网络，这个可能性要小得多。 这都是因为函数 f 在每个时间步长中都会变化，并且我们进行的是矩阵元素相乘，而不是矩阵相乘。</li></ul></li></ul><p>&nbsp;</p><p>&nbsp;</p><h2><a name='header-n490' class='md-header-anchor '></a>Other RNN Variants</h2><p><img src='assets/image-20180903172307359.png' alt='image-20180903172307359' referrerPolicy='no-referrer' /></p><p>&nbsp;</p><h2><a name='header-n493' class='md-header-anchor '></a>Summary</h2><ul><li><p>RNNs allow a lot of flexibility in architecture design</p></li><li><p>Vanilla RNNs are simple but don&#39;t work very well</p></li><li><p>Common to use LSRM or GRU: their additive interactives impove pradient flow</p></li><li><p>Backward flow of gradients in RNN can explode or vanish</p><p>Exploding is controlled with gradient clipping. </p><p>Vanishing is controlled with additive interactions (LSTM)</p></li><li><p>Better/simpler architectures are a hot topic of current research</p></li><li><p>Better understanding (both theoretical and empirical) is needed.</p></li></ul><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><hr /><p><a href='./index.html'>返回到上一页</a> | <a href='./cs231n_10.html'>返回到顶部</a></p><hr /><p><br>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
<br></p><script type="application/json" class="js-hypothesis-config">
  {
    "openSidebar": false,
    "showHighlights": true,
    "theme": classic,
    "enableExperimentalNewNoteButton": true
  }
</script>
<script async="" src="https://hypothes.is/embed.js"></script><p>&nbsp;</p></div>
</body>
</html>