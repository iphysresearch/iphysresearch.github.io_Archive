<!DOCTYPE html>
<html>
  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  <meta name="description" content="Machine Learning, Deep Learning, Physics">
  <meta name="keyword" content="hexo-theme, vuejs">
  
    <link rel="shortcut icon" href="/css/images/logo.png">
  
  <title>
    
      《机器学习》(周志华)——要点笔记2 | Teaching is Learning
    
  </title>
  <link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.css" rel="stylesheet">
  <link href="//cdn.bootcss.com/highlight.js/9.12.0/styles/tomorrow.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/style.css">
<link rel="stylesheet" href="/css/plugins/gitment.css">
  <script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
  <script src="//cdn.bootcss.com/geopattern/1.2.3/js/geopattern.min.js"></script>
  <script src="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.js"></script>
  <script src="/js/qrious.js"></script>
<script src="/js/gitment.js"></script>
  
  
    <!-- MathJax support START -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- MathJax support END -->
  


  <script src="https://hypothes.is/embed.js" async></script>
</head>
<div class="wechat-share">
  <img src="/css/images/logo.png" />
</div>

  <body>
    <header class="header fixed-header">
  <div class="header-container">
    <a class="home-link" href="/">
      <div class="logo"></div>
      <span>Teaching is Learning</span>
    </a>
    <ul class="right-list">
      
        <li class="list-item">
          
            <a href="/" class="item-link">Home</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/tags/" class="item-link">Tags</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/archives/" class="item-link">Archives</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/project/" class="item-link">Projects</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/about/" class="item-link">About</a>
          
        </li>
      
    </ul>
    <div class="menu">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </div>
    <div class="menu-mask">
      <ul class="menu-list">
        
          <li class="menu-item">
            
              <a href="/" class="menu-link">Home</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/tags/" class="menu-link">Tags</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/archives/" class="menu-link">Archives</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/project/" class="menu-link">Projects</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/about/" class="menu-link">About</a>
            
          </li>
        
      </ul>
    </div>
  </div>
</header>

    <div id="article-banner">
  <h2>《机器学习》(周志华)——要点笔记2</h2>
  <p class="post-date">2018-03-06</p>
  <div class="arrow-down">
    <a href="javascript:;"></a>
  </div>
</div>
<main class="app-body flex-box">
  <!-- Article START -->
  <article class="post-article">
    <section class="markdown-content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><ul>
<li>西瓜书中的第4~10章<ul>
<li>决策树</li>
<li>神经网络</li>
<li>支持向量机</li>
<li>贝叶斯分类器</li>
<li>集成学习</li>
<li>聚类</li>
<li>降维与度量学习</li>
</ul>
</li>
</ul>
<a id="more"></a>
<blockquote>
<p>内含自己的学习历程和从其他信息渠道获取的归纳与总结，并不会细致的罗列所有内容，仅摘取对个人有一定价值的信息，以备不时之需。</p>
</blockquote>
<p><br></p>
<h1 id="第4章-决策树"><a href="#第4章-决策树" class="headerlink" title="第4章 决策树"></a>第4章 决策树</h1><h2 id="4-1-基本流程"><a href="#4-1-基本流程" class="headerlink" title="4.1 基本流程"></a>4.1 基本流程</h2><blockquote>
<p>一颗决策树 = 一个根节点 + 若干个内部结点 + 若干个叶结点</p>
</blockquote>
<p>决策树是一个递归过程，说白了，就是不断循环操作，指导满足条件终止。</p>
<ol>
<li>当前结点包含的样本全部属于同一类别；</li>
<li>当前属性集合是空的，或者，所有样本在所有属性上的取值相同；</li>
<li>当前结点包含的样本集合为空。</li>
</ol>
<p><br></p>
<h2 id="4-2-划分选择"><a href="#4-2-划分选择" class="headerlink" title="4.2 划分选择"></a>4.2 划分选择</h2><blockquote>
<p>究竟如何选择最优划分属性？</p>
<p><br></p>
<p>说白了，就是一种基于训练样本集信息的聚类行为。</p>
</blockquote>
<p><br></p>
<h3 id="4-2-1-信息增益"><a href="#4-2-1-信息增益" class="headerlink" title="4.2.1 信息增益"></a>4.2.1 信息增益</h3><p>两个很重要的概念：</p>
<ul>
<li><p>“信息熵”（information entropy）：</p>
<p>（若有个样本集合叫 D，里面有 k 个类别，每个类里所占的比例是 $p_k$）<br>$$<br>\text{Ent}(D)=-\sum^{|\mathcal{Y}|}_{k=1}p_k\log_2p_k<br>$$</p>
<ul>
<li>$\text{Ent}(D)$ 越小越好，所谓 D 的”纯度“（purity） 越高。可以想象”纯度“很糟糕的情况就是样本的分类类别很多，每类所占比例还特别小，接近于0，那么 -log 完了以后就会得到特别大的数，信息熵肯定小不了。</li>
</ul>
</li>
<li><p>“信息增益”（information gain）：</p>
<p>（ D 中有某属性 a，这个属性 a 中有 v 个取值，$D^v$ 是相应取值内的样本集合）<br>$$<br>\text{Gain}(D,a)=\text{Ent}(D)-\sum^{V}_{v=1}\frac{|D^v|}{|D|}\text{Ent}(D^v)<br>$$</p>
<ul>
<li>可以对 D 中每一个属性 a 算一次$\text{Gain}(D,a)$，谁的信息增益更大，就说明使用哪个属性作为划分依据未来的”纯度“越高。当然说白了，这句话可以直接从上面的公式中看出</li>
<li>信息增益准则对<strong>可取值数目较多的属性</strong>有所偏好</li>
</ul>
</li>
</ul>
<p><br></p>
<h3 id="4-2-2-增益率"><a href="#4-2-2-增益率" class="headerlink" title="4.2.2 增益率"></a>4.2.2 增益率</h3><ul>
<li>增益率准则对可取值数目较少的属性有所偏好</li>
</ul>
<p>增益率的定义：<br>$$<br>\text{Gain_ratio}(D,a)=\frac{\text{Gain}(D,a)}{\text{IV(a)}}<br>$$<br>其中，IV(a) 成为属性 a 的”固有值”（intrinsic value）。</p>
<p><br></p>
<h3 id="4-2-3-基尼指数"><a href="#4-2-3-基尼指数" class="headerlink" title="4.2.3 基尼指数"></a>4.2.3 基尼指数</h3><p>（暂略）</p>
<p><br></p>
<h2 id="4-3-剪枝处理"><a href="#4-3-剪枝处理" class="headerlink" title="4.3 剪枝处理"></a>4.3 剪枝处理</h2><blockquote>
<p>剪枝（pruning） 是决策树学习算法对付“过拟合”的主要手段。可通过主动去掉一些分支来降低过拟合的风险（此法的精神很类似于 dropout）。</p>
</blockquote>
<p><br></p>
<h3 id="4-3-1-预剪枝"><a href="#4-3-1-预剪枝" class="headerlink" title="4.3.1 预剪枝"></a>4.3.1 预剪枝</h3><blockquote>
<p>预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点。</p>
</blockquote>
<p>不仅降低过拟合的风险，还显著减少了决策树的训练时间开销和测试时间开销。不过。。。。。</p>
<p><br></p>
<h3 id="4-3-2-后剪枝"><a href="#4-3-2-后剪枝" class="headerlink" title="4.3.2 后剪枝"></a>4.3.2 后剪枝</h3><blockquote>
<p>后剪枝是先从训练集生成一课完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点。</p>
</blockquote>
<p>后剪枝决策树的欠拟合风险很小，泛化性能优于预剪枝决策树，但后剪枝过程的训练时间开销比未剪枝决策树和预剪枝决策树都要大得多。</p>
<p><br></p>
<h2 id="4-4-连续与缺失值"><a href="#4-4-连续与缺失值" class="headerlink" title="4.4 连续与缺失值"></a>4.4 连续与缺失值</h2><p>接下来讨论两类需要额外处理的数据类型特征。</p>
<p><br></p>
<h3 id="4-4-1-连续值处理"><a href="#4-4-1-连续值处理" class="headerlink" title="4.4.1 连续值处理"></a>4.4.1 连续值处理</h3><p>连续值怎么搞呢？说白了就是连续值离散化呗~~</p>
<p><br></p>
<h3 id="4-4-2-缺失值处理"><a href="#4-4-2-缺失值处理" class="headerlink" title="4.4.2 缺失值处理"></a>4.4.2 缺失值处理</h3><p>缺失值的处理，说白了，就是填充呗！怎么填充呢？只要是”合理“的，怎么填充就行！</p>
<p><br></p>
<h2 id="4-5-多变量决策树"><a href="#4-5-多变量决策树" class="headerlink" title="4.5 多变量决策树"></a>4.5 多变量决策树</h2><blockquote>
<p>决策树所形成的分类边界有一个明显的特点：轴平行（axis-parallel）</p>
</blockquote>
<p>这也容易理解，毕竟”离散分类”地做决策嘛。</p>
<p>多变量决策树并不是为每个非叶结点寻找一个最优划分属性，而是试图建立一个合适的线性分类器，实现“斜划分”。</p>
<h1 id="第5章-神经网络"><a href="#第5章-神经网络" class="headerlink" title="第5章 神经网络"></a>第5章 神经网络</h1><h2 id="5-1-神经元模型"><a href="#5-1-神经元模型" class="headerlink" title="5.1 神经元模型"></a>5.1 神经元模型</h2><p>定义比较新颖：神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界所作出的交互反应。</p>
<p><br></p>
<p>一张图说明一切：</p>
<p><img src="https://i.loli.net/2018/03/09/5aa2965e15e72.png" alt=""></p>
<p><br></p>
<h2 id="5-2-感知机与多层网络"><a href="#5-2-感知机与多层网络" class="headerlink" title="5.2 感知机与多层网络"></a>5.2 感知机与多层网络</h2><p>有一点不解，改日再好好看。</p>
<p><br></p>
<h2 id="5-3-误差逆传播算法"><a href="#5-3-误差逆传播算法" class="headerlink" title="5.3 误差逆传播算法"></a>5.3 误差逆传播算法</h2><blockquote>
<p>可以证明，只需一个包含足够多神经元的隐层，多层前馈网络就能以任意精度逼近任意复杂度的连续函数。</p>
</blockquote>
<p>然而，如何设置隐层神经元的个数仍是个未解决的问题。</p>
<p><br></p>
<h2 id="5-4-全局最小与局部最小"><a href="#5-4-全局最小与局部最小" class="headerlink" title="5.4 全局最小与局部最小"></a>5.4 全局最小与局部最小</h2><p>“跳出”局部最小是有一定的策略的：</p>
<ul>
<li>从不同的初始点开始搜索，增大更接近全局最小的概率</li>
<li>”模拟退火“，即一定概率的接受”次优解“。</li>
<li>用随机梯度下降。因为即使陷入局部极小点，其梯度仍可能不为0.</li>
</ul>
<p><br></p>
<h2 id="5-5-其他常见神经网络"><a href="#5-5-其他常见神经网络" class="headerlink" title="5.5 其他常见神经网络"></a>5.5 其他常见神经网络</h2><h3 id="5-5-1-RBF-网络"><a href="#5-5-1-RBF-网络" class="headerlink" title="5.5.1 RBF 网络"></a>5.5.1 RBF 网络</h3><ul>
<li>RBF（Radial Basis Function，径向基函数）网络是一种单隐层前馈神经网络。</li>
<li>已证明：具有足够多隐层神经元的 RBF 网络能以任意精度逼近任意连续函数。</li>
</ul>
<p><br></p>
<h3 id="5-5-2-ART-网络"><a href="#5-5-2-ART-网络" class="headerlink" title="5.5.2 ART 网络"></a>5.5.2 ART 网络</h3><ul>
<li>ART（Adaptive Resonance Theory，自适应谐振理论）网络是竞争型学习的重要代表。</li>
<li>ART 比较好地缓解了竞争型学习中的”可塑性-稳定性窘境“（stability-plasticity dilemma），可塑性是指神经网络要有学习新知识的能力，而稳定性是指神经网络在学习新知识时要保持对旧知识的记忆。</li>
<li>优点：可进行增量学习（incremental learning） 或在线学习（online Learning）。</li>
</ul>
<p><br></p>
<h3 id="5-5-3-SOM网络"><a href="#5-5-3-SOM网络" class="headerlink" title="5.5.3 SOM网络"></a>5.5.3 SOM网络</h3><ul>
<li>SOM（Self-Organizing Map，自组织映射）网络是一种竞争学习型的无监督神经网络。</li>
<li>将高位输入数据映射到低维空间，同时保持输入数据在高维空间的拓扑结构。</li>
</ul>
<p><br></p>
<h3 id="5-5-4-级联相关网络"><a href="#5-5-4-级联相关网络" class="headerlink" title="5.5.4 级联相关网络"></a>5.5.4 级联相关网络</h3><ul>
<li>级联相关（Cascade-Correlation） 网络是结构自适应网路的重要代表。</li>
<li>与一般的前馈神经网络相比，级联相关网络无需设置网络层数、隐层神经元数目，且训练速度较快，但其在数据较小时易陷入过拟合。</li>
</ul>
<p><br></p>
<h3 id="5-5-5-Elman-网络"><a href="#5-5-5-Elman-网络" class="headerlink" title="5.5.5 Elman 网络"></a>5.5.5 Elman 网络</h3><ul>
<li>Elman 网络是最常用的递归神经网络之一。</li>
</ul>
<p><br></p>
<h3 id="5-5-6-Boltzmann-机"><a href="#5-5-6-Boltzmann-机" class="headerlink" title="5.5.6 Boltzmann 机"></a>5.5.6 Boltzmann 机</h3><ul>
<li>Boltzmann 机是一种”基于能量的模型“（energy-based model）</li>
<li>标准的 Boltzmann 机是一个全连接图，难以用于解决现实任务。现实中常采用受限 Boltzmann 机（Restricted Boltzmann Machine，RBM）。</li>
</ul>
<p><br></p>
<h2 id="5-6-深度学习"><a href="#5-6-深度学习" class="headerlink" title="5.6 深度学习"></a>5.6 深度学习</h2><blockquote>
<p>对输入信号进行逐层加工，从而把初始的、与输出目标之间联系不太密切的输入表示，转化为与输出目标联系更密切的表示，使得原来仅基于最后一层输出映射难以完成的任务成为可能。</p>
<p><br></p>
<p>通过多层处理，逐渐将初始的”低层“特征表示转化为”高层“特征表示后，用”简单模型“即可完成复杂的分类学习任务。</p>
</blockquote>
<p><br></p>
<h1 id="第6章-支持向量机"><a href="#第6章-支持向量机" class="headerlink" title="第6章 支持向量机"></a>第6章 支持向量机</h1><h2 id="6-1-间隔与支持向量"><a href="#6-1-间隔与支持向量" class="headerlink" title="6.1 间隔与支持向量"></a>6.1 间隔与支持向量</h2><p>这里探讨了支持向量机（Support Vector Machine，SVM）的基本型。</p>
<p><img src="https://i.loli.net/2018/03/11/5aa4ebe7dbe96.png" alt=""></p>
<p>说白了呢，很像是寻找某微分流形中的一个最佳的嵌入子流形（超曲面），当然配的是欧式的平面度规。</p>
<p><br></p>
<h2 id="6-2-对偶问题"><a href="#6-2-对偶问题" class="headerlink" title="6.2 对偶问题"></a>6.2 对偶问题</h2><p>当具体求解模型参数时，发现这是一个凸二次规划（convex quadratic programming）问题。</p>
<p><br></p>
<p>我们可以用拉格朗日乘子法转换为其“对偶问题”（dual problem）。</p>
<p><br></p>
<p>此处应该较为平缓的引入关于“拉格朗日乘子法”的介绍。</p>
<p><br></p>
<h2 id="6-3-核函数"><a href="#6-3-核函数" class="headerlink" title="6.3 核函数"></a>6.3 核函数</h2><blockquote>
<p>入股原始空间是有限维的，即属性数有限，那么一定存在一个高维特征空间使样本可分。</p>
<p>模型的最优解可通过训练样本的核函数（kernel function） 展开，即所谓“支持向量展式”（support vector expansion）。</p>
</blockquote>
<p>于是乎，核函数的选择就成了关键之一：</p>
<p><img src="https://i.loli.net/2018/03/11/5aa4eea0b23b4.png" alt=""></p>
<p><br></p>
<h2 id="6-4-软间隔与正则化"><a href="#6-4-软间隔与正则化" class="headerlink" title="6.4 软间隔与正则化"></a>6.4 软间隔与正则化</h2><p>如何缓解线性可分的结果不是由于过拟合造成的呢？</p>
<ul>
<li>“软间隔”<ul>
<li>允许一些不满足约束的样本</li>
</ul>
</li>
</ul>
<p><br></p>
<h2 id="6-5-支持向量回归"><a href="#6-5-支持向量回归" class="headerlink" title="6.5 支持向量回归"></a>6.5 支持向量回归</h2><p>现在开始考虑回归问题。即所谓支持向量回归（Support Vector Regression，SVR）</p>
<ul>
<li>间隔带</li>
</ul>
<p><br></p>
<h2 id="6-6-核方法"><a href="#6-6-核方法" class="headerlink" title="6.6 核方法"></a>6.6 核方法</h2><p>核函数的线性组合就满足了？</p>
<p><br></p>
<p>我们可以“核化”！实现非线性扩展！</p>
</section>
    <!-- Tags START -->
    
      <div class="tags">
        <span>Tags:</span>
        
  <a href="/tags#怒啃西瓜书" >
    <span class="tag-code">怒啃西瓜书</span>
  </a>

      </div>
    
    <!-- Tags END -->
    <!-- NAV START -->
    
  <div class="nav-container">
    <!-- reverse left and right to put prev and next in a more logic postition -->
    
      <a class="nav-left" href="/2018/03/ML_ZHOU1/">
        <span class="nav-arrow">← </span>
        
          《机器学习》(周志华)——要点笔记1
        
      </a>
    
    
  </div>

    <!-- NAV END -->
    <!-- 打赏 START -->
    
      <div class="money-like">
        <div class="reward-btn">
          赏
          <span class="money-code">
            <span class="alipay-code">
              <div class="code-image"></div>
              <b>使用支付宝打赏</b>
            </span>
            <span class="wechat-code">
              <div class="code-image"></div>
              <b>使用微信打赏</b>
            </span>
          </span>
        </div>
        <p class="notice">若你觉得我的文章对你有帮助，欢迎点击上方按钮对我打赏</p>
      </div>
    
    <!-- 打赏 END -->
    <!-- 二维码 START -->
    
      <div class="qrcode">
        <canvas id="share-qrcode"></canvas>
        <p class="notice">扫描二维码，分享此文章</p>
      </div>
    
    <!-- 二维码 END -->
    
      <!-- Gitment START -->
      <div id="comments"></div>
      <!-- Gitment END -->
    
  </article>
  <!-- Article END -->
  <!-- Catalog START -->
  
    <aside class="catalog-container">
  <div class="toc-main">
    <strong class="toc-title">Catalog</strong>
    
      <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#第4章-决策树"><span class="toc-nav-text">第4章 决策树</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#4-1-基本流程"><span class="toc-nav-text">4.1 基本流程</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#4-2-划分选择"><span class="toc-nav-text">4.2 划分选择</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#4-2-1-信息增益"><span class="toc-nav-text">4.2.1 信息增益</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#4-2-2-增益率"><span class="toc-nav-text">4.2.2 增益率</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#4-2-3-基尼指数"><span class="toc-nav-text">4.2.3 基尼指数</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#4-3-剪枝处理"><span class="toc-nav-text">4.3 剪枝处理</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#4-3-1-预剪枝"><span class="toc-nav-text">4.3.1 预剪枝</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#4-3-2-后剪枝"><span class="toc-nav-text">4.3.2 后剪枝</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#4-4-连续与缺失值"><span class="toc-nav-text">4.4 连续与缺失值</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#4-4-1-连续值处理"><span class="toc-nav-text">4.4.1 连续值处理</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#4-4-2-缺失值处理"><span class="toc-nav-text">4.4.2 缺失值处理</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#4-5-多变量决策树"><span class="toc-nav-text">4.5 多变量决策树</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#第5章-神经网络"><span class="toc-nav-text">第5章 神经网络</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#5-1-神经元模型"><span class="toc-nav-text">5.1 神经元模型</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#5-2-感知机与多层网络"><span class="toc-nav-text">5.2 感知机与多层网络</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#5-3-误差逆传播算法"><span class="toc-nav-text">5.3 误差逆传播算法</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#5-4-全局最小与局部最小"><span class="toc-nav-text">5.4 全局最小与局部最小</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#5-5-其他常见神经网络"><span class="toc-nav-text">5.5 其他常见神经网络</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#5-5-1-RBF-网络"><span class="toc-nav-text">5.5.1 RBF 网络</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#5-5-2-ART-网络"><span class="toc-nav-text">5.5.2 ART 网络</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#5-5-3-SOM网络"><span class="toc-nav-text">5.5.3 SOM网络</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#5-5-4-级联相关网络"><span class="toc-nav-text">5.5.4 级联相关网络</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#5-5-5-Elman-网络"><span class="toc-nav-text">5.5.5 Elman 网络</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#5-5-6-Boltzmann-机"><span class="toc-nav-text">5.5.6 Boltzmann 机</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#5-6-深度学习"><span class="toc-nav-text">5.6 深度学习</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#第6章-支持向量机"><span class="toc-nav-text">第6章 支持向量机</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#6-1-间隔与支持向量"><span class="toc-nav-text">6.1 间隔与支持向量</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#6-2-对偶问题"><span class="toc-nav-text">6.2 对偶问题</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#6-3-核函数"><span class="toc-nav-text">6.3 核函数</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#6-4-软间隔与正则化"><span class="toc-nav-text">6.4 软间隔与正则化</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#6-5-支持向量回归"><span class="toc-nav-text">6.5 支持向量回归</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#6-6-核方法"><span class="toc-nav-text">6.6 核方法</span></a></li></ol></li></ol>
    
  </div>
</aside>
  
  <!-- Catalog END -->
</main>

<script>
  (function () {
    var url = 'http://iphysresearch.github.io/2018/03/ML_ZHOU2/';
    var banner = 'https://i.loli.net/2018/03/02/5a993e559d4d1.jpg'
    if (banner !== '' && banner !== 'undefined' && banner !== 'null') {
      $('#article-banner').css({
        'background-image': 'url(' + banner + ')'
      })
    } else {
      $('#article-banner').geopattern(url)
    }
    $('.header').removeClass('fixed-header')

     // error image
    $(".markdown-content img").on('error', function() {
      $(this).attr('src', 'http://file.muyutech.com/error-img.png')
      $(this).css({
        'cursor': 'default'
      })
    })

    // zoom image
    $(".markdown-content img").on('click', function() {
      var src = $(this).attr('src')
      if (src !== 'http://file.muyutech.com/error-img.png') {
        var imageW = $(this).width()
        var imageH = $(this).height()
        
        var zoom = ($(window).width() * 0.95 / imageW).toFixed(2)
        zoom = zoom < 1 ? 1 : zoom
        zoom = zoom > 2 ? 2 : zoom
        var transY = (($(window).height() - imageH) / 2).toFixed(2)

        $('body').append('<div class="image-view-wrap"><div class="image-view-inner"><img src="'+ src +'" /></div></div>')
        $('.image-view-wrap').addClass('wrap-active')
        $('.image-view-wrap img').css({
          'width': `${imageW}`,
          'transform': `translate3d(0, ${transY}px, 0) scale3d(${zoom}, ${zoom}, 1)`
        })
        $('html').css('overflow', 'hidden')

        $('.image-view-wrap').on('click', function() {
          $(this).remove()
          $('html').attr('style', '')
        })
      }
    })

    // qrcode
    var qr = new QRious({
      element: document.getElementById('share-qrcode'),
      value: document.location.href
    });

    // gitment
    var gitmentConfig = "iphysresearch";
    if (gitmentConfig !== 'undefined') {
      var gitment = new Gitment({
        id: "《机器学习》(周志华)——要点笔记2",
        owner: "iphysresearch",
        repo: "iphysresearch.github.io",
        oauth: {
          client_id: "6b978dc207dc30e58ec8",
          client_secret: "2bc56895d0221e8c27ab87b072f8f18523231e22"
        },
        theme: {
          render(state, instance) {
            const container = document.createElement('div')
            container.lang = "en-US"
            container.className = 'gitment-container gitment-root-container'
            container.appendChild(instance.renderHeader(state, instance))
            container.appendChild(instance.renderEditor(state, instance))
            container.appendChild(instance.renderComments(state, instance))
            container.appendChild(instance.renderFooter(state, instance))
            return container;
          }
        }
      })
      gitment.render(document.getElementById('comments'))
    }
  })();
</script>

    <div class="scroll-top">
  <span class="arrow-icon"></span>
</div>
    <footer class="app-footer">
  <p class="copyright">
    &copy; 2018 | Proudly powered by <a href="https://hexo.io" target="_blank">Hexo</a>
    <br>
    Theme by <a href="https://github.com/yanm1ng">yanm1ng</a>
  </p>
</footer>

<script>
  function async(u, c) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }
</script>
<script>
  async("//cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
    FastClick.attach(document.body);
  })
</script>

<script>
  var hasLine = 'true';
  async("//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js", function(){
    $('figure pre').each(function(i, block) {
      var figure = $(this).parents('figure');
      if (hasLine === 'false') {
        figure.find('.gutter').hide();
      }
      var lang = figure.attr('class').split(' ')[1] || 'code';
      var codeHtml = $(this).html();
      var codeTag = document.createElement('code');
      codeTag.className = lang;
      codeTag.innerHTML = codeHtml;
      $(this).attr('class', '').empty().html(codeTag);
      figure.attr('data-lang', lang.toUpperCase());
      hljs.highlightBlock(block);
    });
  })
</script>
<!-- Baidu Tongji -->

<script src="/js/script.js"></script>
  </body>
</html>