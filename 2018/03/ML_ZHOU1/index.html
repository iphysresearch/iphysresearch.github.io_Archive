<!DOCTYPE html>
<html>
  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  <meta name="description" content="Machine Learning, Deep Learning, Physics">
  <meta name="keyword" content="hexo-theme, vuejs">
  
    <link rel="shortcut icon" href="/css/images/logo.png">
  
  <title>
    
      《机器学习》(周志华)——要点笔记1 | Teaching is Learning
    
  </title>
  <link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.css" rel="stylesheet">
  <link href="//cdn.bootcss.com/highlight.js/9.12.0/styles/tomorrow.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/style.css">
<link rel="stylesheet" href="/css/plugins/gitment.css">
  <script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
  <script src="//cdn.bootcss.com/geopattern/1.2.3/js/geopattern.min.js"></script>
  <script src="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.js"></script>
  <script src="/js/qrious.js"></script>
<script src="/js/gitment.js"></script>
  
  
    <!-- MathJax support START -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- MathJax support END -->
  


  <script src="https://hypothes.is/embed.js" async></script>
</head>
<div class="wechat-share">
  <img src="/css/images/logo.png" />
</div>

  <body>
    <header class="header fixed-header">
  <div class="header-container">
    <a class="home-link" href="/">
      <div class="logo"></div>
      <span>Teaching is Learning</span>
    </a>
    <ul class="right-list">
      
        <li class="list-item">
          
            <a href="/" class="item-link">Home</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/tags/" class="item-link">Tags</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/archives/" class="item-link">Archives</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/project/" class="item-link">Projects</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/about/" class="item-link">About</a>
          
        </li>
      
    </ul>
    <div class="menu">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </div>
    <div class="menu-mask">
      <ul class="menu-list">
        
          <li class="menu-item">
            
              <a href="/" class="menu-link">Home</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/tags/" class="menu-link">Tags</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/archives/" class="menu-link">Archives</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/project/" class="menu-link">Projects</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/about/" class="menu-link">About</a>
            
          </li>
        
      </ul>
    </div>
  </div>
</header>

    <div id="article-banner">
  <h2>《机器学习》(周志华)——要点笔记1</h2>
  <p class="post-date">2018-03-04</p>
  <div class="arrow-down">
    <a href="javascript:;"></a>
  </div>
</div>
<main class="app-body flex-box">
  <!-- Article START -->
  <article class="post-article">
    <section class="markdown-content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><ul>
<li>西瓜书中的第1~3章<ul>
<li>绪论</li>
<li>模型评估与选择</li>
<li>线性模型</li>
</ul>
</li>
</ul>
<a id="more"></a>
<blockquote>
<p>内含自己的学习历程和从其他信息渠道获取的归纳与总结，并不会细致的罗列所有内容，仅摘取对个人有一定价值的信息，以备不时之需。</p>
</blockquote>
<p><br></p>
<h1 id="第1章-绪论"><a href="#第1章-绪论" class="headerlink" title="第1章 绪论"></a>第1章 绪论</h1><p>刚开始的引言部分，看似虽短，但就已经道出了“机器学习”与通常的程式化编程的本质区别：</p>
<blockquote>
<p>通过对<strong>经验</strong>的利用，对新情况做出有效的<strong>决策</strong>（预判）。</p>
</blockquote>
<p>不过，经常被引用的是另一个<a href="https://zh.wikipedia.org/wiki/机器学习" target="_blank" rel="noopener">英文定义</a>：</p>
<blockquote>
<p>A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.</p>
</blockquote>
<p>注：用“模型(model)”泛指从数据中学得的结果。（如神经网络中的模型参数和权重等）</p>
<p><br></p>
<p>周老师在“基本术语”中给出了相当丰富，甚至细致过分的术语定义和解释，并配有英文释义。让我自己眼前一亮的术语定义有：“属性空间（attribute space）或”“样本空间”（sample space）、“真相”或“真实”（ground-truth）、要区别“示例”（instance）或“样本”（sample） 与“样例”（example）等等。</p>
<p><br></p>
<p>可以说，“泛化”（generalization）能力是机器学习的最重要目标之一。</p>
<blockquote>
<p>通常假设样本空间中全体样本服从一个未知”分布”（distribution）$\mathcal{D}$，我们获得的每个样本都是独立地从这个分布上采样获得的，即“<strong>独立同分布</strong>”（independent and identically distributed，简称 i.i.d）。</p>
</blockquote>
<p>统计机器学习算法都是基于了样本<strong>独立同分布</strong>的假设。说白了，就是获取每个样本的随机变量的时候，假设每个样本的随机变量之间都是独立不相关的，而且关于各个样本的随机变量的分布是相同的。举个例子：环境条件保持不变的情况下，一系列的抛硬币的正反面结果（作为随机变量）是独立同分布的；再比如，若预测天津市西青区的房屋价格，我们就不能拿北京某个小区的房子放到这个模型中去预测，这样做会导致误差很大。</p>
<p><br></p>
<p>接下来谈到的两个概念是非常有趣的：“<strong>假设空间</strong>”（hypothesis space） 和“<strong>版本空间</strong>”（version space），源于概念学习技术。说到底，假设空间就是穷尽样本空间所有可能性，是样本空间中所有”开子集”的集合（包括$\varnothing$）。那么显然，训练集中所有独立假设构成的集合肯定是假设空间的子集，机器学习充当了搜索或匹配（fit）的过程，寻找数据样例要求的”标记“（label） 下的”最具概括意义“的最小假设集合。那么这个最小假设集合可能不是唯一的，这就有了版本空间的概念。</p>
<p><img src="https://i.loli.net/2018/03/03/5a9a505cc9337.png" alt=""></p>
<blockquote>
<p>GB 是最大泛化正假设边界（maximally General positive hypothesis Boundary）；SB 是最大精确正假设边界（maximally Specific positive hypothesis Boundary）。 所有绿色方块就是所有绿色样本的版本空间了。</p>
</blockquote>
<p>再用习题1.1作为例子，有如下两个样例：</p>
<p><br></p>
<table>
<thead>
<tr>
<th>编号</th>
<th>色泽</th>
<th>根蒂</th>
<th>敲声</th>
<th>好瓜？</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>青绿</td>
<td>蜷缩</td>
<td>浊响</td>
<td>是</td>
</tr>
<tr>
<td>4</td>
<td>乌黑</td>
<td>稍卷</td>
<td>沉闷</td>
<td>否</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>找编号1的版本空间，就是找出包含编号1这个假设的所有其他更具概括意义的假设，同时还不能包含作为负样本的编号4的假设。所以就有：</p>
<p><img src="https://i.loli.net/2018/03/03/5a9a5c46cfbee.png" alt=""></p>
<p>上图中，不能进一步的向下将 <code>色泽=*,根蒂=*,敲声=*</code> 作为编号1的版本空间，是因为 <code>色泽=*,根蒂=*,敲声=*</code> 会包含了编号4的负样本。编号4的版本空间以此类推。</p>
<p><br></p>
<p>“归纳偏好”（inductive bias）是一个很有趣的提法：</p>
<blockquote>
<p>任何一个有效的机器学习算法必有其归纳偏好。</p>
</blockquote>
<p>在物理学等基础学科中，“奥卡姆剃刀”（Occam’s razor） 无疑是默认的追求事物运行机制背后本质的基本原则。但是在机器学习算法中，将这个原则单纯的去类比到算法和决策选择上并不合适。造成这个现象的原因，在我的理解下，我想很可能是在机器学习领域中，我们还没有达到或触及更本质、更一般、更深层的规律机制吧。</p>
<p><br></p>
<p>最后，“没有免费的午餐”定理（No Free Lunch Theorem，NFL）给出了令人惊异的结论，告诉了我们，不存在普遍意义下绝对好用的算法。要因地制宜，随机应变。 至于证明嘛，日后补上吧。。。。</p>
<p><br></p>
<p>至于习题作业嘛，再日后补上吧。。。。</p>
<p><br></p>
<h1 id="第2章-模型评估与选择"><a href="#第2章-模型评估与选择" class="headerlink" title="第2章 模型评估与选择"></a>第2章 模型评估与选择</h1><h2 id="2-1-经验误差与过拟合"><a href="#2-1-经验误差与过拟合" class="headerlink" title="2.1 经验误差与过拟合"></a>2.1 经验误差与过拟合</h2><p>我们希望算法模型能够从训练样本中尽可能学出适合于<strong>所有潜在样本的“普遍规律”</strong>，但是很担心它把<strong>训练样本自身的一些特点</strong>当做了所有潜在样本都会具有的一般性质，从而泛化能力下降，导致“<strong>过拟合</strong>”。</p>
<blockquote>
<p>书中的小标注很有启发性：</p>
<p><br></p>
<p>“算法的学习能力是由学习算法和数据内涵共同决定的。”</p>
<p><br></p>
<p>可见除了算法本身外，数据的”质量”也是至关重要的因素。</p>
</blockquote>
<p>过拟合是机器学习面临的关键障碍，没有哪个学习算法可以逃避这个现实，是无法彻底避免的，只能“缓解”，所以每个算法都有应对过拟合的措施。</p>
<p><br></p>
<p>综上，现在面对着两个问题：</p>
<ol>
<li>我们无法直接获得泛化误差（木有也无法用包罗万象的完整数据用来训练）;</li>
<li>训练误差的参考价值极其有限。</li>
</ol>
<p>那么，</p>
<ul>
<li>问：我们该如何进行模型评估与选择呢？</li>
<li>答：利用测试集（testing set）。</li>
</ul>
<p><br></p>
<h2 id="2-2-评估方法"><a href="#2-2-评估方法" class="headerlink" title="2.2 评估方法"></a>2.2 评估方法</h2><ul>
<li>要求：<ul>
<li>测试集上的“测试误差”作为泛化误差的近似。</li>
</ul>
</li>
<li>假设：<ul>
<li>测试样本是从样本真实分布中独立同分布采样而得；</li>
<li>测试集是尽可能与训练集互斥的。</li>
</ul>
</li>
</ul>
<p>对于一个样例数据集 $D = \{(\boldsymbol{x}_1,y_1),(\boldsymbol{x}_2,y_2),\dots,(\boldsymbol{x}_m,y_m\}$，如何划分训练集和测试集呢？</p>
<p><br></p>
<h3 id="2-2-1-留出法"><a href="#2-2-1-留出法" class="headerlink" title="2.2.1 留出法"></a>2.2.1 留出法</h3><blockquote>
<p>有放回的随机划分！——留出法（hold-out）</p>
</blockquote>
<p>说白了，就是每次闭着眼睛切一小块用来测试，评估完再放回去，再切一小块用来测试，如此反复。</p>
<ul>
<li>注意：<ul>
<li>训练/测试集的划分要尽可能保持数据分布的一致性！从而避免引入额外的偏差，如采样中保留类别比例。</li>
<li>要采用若干次随机划分、重复进行试验评估后取平均值作为结果。</li>
<li>经验上，通常将2/3~4/5的样本用于训练，其他用于测试。测试集至少应含30个样例。</li>
</ul>
</li>
</ul>
<p><br></p>
<h3 id="2-2-2-交叉验证法"><a href="#2-2-2-交叉验证法" class="headerlink" title="2.2.2 交叉验证法"></a>2.2.2 交叉验证法</h3><blockquote>
<p>定格的依次划分！——交叉验证（cross validation）</p>
</blockquote>
<p>说白了，就是用尺子打好格子，定下来每一小块，逐个用来测试，如此反复。</p>
<ul>
<li>注意：<ul>
<li>每一小块尽可能保持数据分布的一致性（分层采样）。</li>
<li>通常随机使用不同的划分重复 p 次，每次 k 折交叉验证，$p\times k$ 个结果取均值。</li>
<li>留一法（Leave-One-Out, LOO）：虽然评估结果被认为比较准确，但计算开销大，也未必总比其他评估方法准确（根据 NFL 定理）。</li>
</ul>
</li>
</ul>
<p><br></p>
<h3 id="2-2-3-自助法"><a href="#2-2-3-自助法" class="headerlink" title="2.2.3 自助法"></a>2.2.3 自助法</h3><blockquote>
<p>留出法+留一法！——自助法（bootstrapping）</p>
</blockquote>
<p>说白了，每次闭着眼睛挑一个出来，复制一下再放回去，直到挑出来的数目和原集合总是一致后开始训练，用原集合中从来没挑出来过的用来测试。</p>
<ul>
<li>注意：<ul>
<li>约有36.8%的样本作为测试样本。</li>
<li>适用于数据集较小、难以有效划分训练/测试集时。</li>
<li>因会改变原集合的分布，存在估计偏差。</li>
<li>多次生成不同的训练集可以用于集成学习。</li>
</ul>
</li>
</ul>
<p><br></p>
<h3 id="2-2-4-调参与最终模型"><a href="#2-2-4-调参与最终模型" class="headerlink" title="2.2.4 调参与最终模型"></a>2.2.4 调参与最终模型</h3><p>算法参数的调节对最终模型性能有关键性的影响。</p>
<p>在实际应用中，利用数据集中的一部分数据来训练，剩余一部分作为“验证集”（validation set）。当定下来学习算法和参数配置后，在完整数据集上用定下来的算法再训练一次，作为最终的算法模型，这样是即参考了全部数据集的信息，也兼顾了我们可以接受和达到的泛化能力。</p>
<p><br></p>
<h2 id="2-3-性能度量"><a href="#2-3-性能度量" class="headerlink" title="2.3 性能度量"></a>2.3 性能度量</h2><p>说了半天评估的方法和手段，那究竟该如何量化呢？用什么标准来比较和评估当前算法和参数配置好不好呢？</p>
<blockquote>
<p>衡量模型泛化能力的评价标准 —— 性能度量（performance measure）</p>
</blockquote>
<p>模型的好坏，不仅取决于算法和数据，还决定于任务需求，进而存在性能度量的选择问题。</p>
<ul>
<li><p>回归任务</p>
<ul>
<li>常用性能度量：“均方误差”（mean squared error）</li>
</ul>
<p>$$<br>E(f;D)=\frac{1}{m}\sum^m_{i=1}(f(\boldsymbol{x}_i)-y_i)^2<br>$$</p>
<ul>
<li>一般的，对于数据分布$\mathcal{D}$和概率密度函数$p(\cdot)$，MSE：</li>
</ul>
<p>$$<br>E(f;\mathcal{D})=\int_{\boldsymbol{x}\sim\mathcal{D}}(f(\boldsymbol{x})-y)^2p(\boldsymbol{x})d\boldsymbol{x}<br>$$</p>
</li>
<li><p>分类任务</p>
</li>
</ul>
<p><br></p>
<h3 id="2-3-1-错误率与精度"><a href="#2-3-1-错误率与精度" class="headerlink" title="2.3.1 错误率与精度"></a>2.3.1 错误率与精度</h3><blockquote>
<p>着眼于分类错误和分类正确分别占样本数的比例，也适用于多分类任务。</p>
</blockquote>
<p>$$<br>\begin{align}<br>\text{错误率：}E(f;D)&amp;=\frac{1}{m}\sum^m_{i=1}\mathbb{I}(f(\boldsymbol{x}_i)\neq y_i)\\<br>\text{精度：}\text{acc}(f;D)&amp;=\frac{1}{m}\sum^m_{i=1}\mathbb{I}(f(\boldsymbol{x}_i) = y_i)=1-E(f;D)<br>\end{align}<br>$$</p>
<p>一般的，对于数据分布$\mathcal{D}$和概率密度函数$p(\cdot)$：<br>$$<br>\begin{align}<br>\text{错误率：}E(f;\mathcal{D})&amp;=\int_{\boldsymbol{x}\sim\mathcal{D}}\mathbb{I}(f(\boldsymbol{x})\neq y)p(\boldsymbol{x})d\boldsymbol{x}\\<br>\text{精度：}\text{acc}(f;D)&amp;=\int_{\boldsymbol{x}\sim\mathcal{D}}\mathbb{I}(f(\boldsymbol{x})= y)p(\boldsymbol{x})d\boldsymbol{x}=1-E(f;D)<br>\end{align}<br>$$<br><br></p>
<h3 id="2-3-2-查准率、查全率与-F1"><a href="#2-3-2-查准率、查全率与-F1" class="headerlink" title="2.3.2 查准率、查全率与 F1"></a>2.3.2 查准率、查全率与 F1</h3><ul>
<li>二分类问题中，可以对错误率和精度进一步细化评估指标。</li>
<li>混淆矩阵（confusion matrix）：</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">真实情况</th>
<th style="text-align:center">预测结果</th>
<th style="text-align:center">预测结果</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">正例</td>
<td style="text-align:center">反例</td>
</tr>
<tr>
<td style="text-align:center">正例</td>
<td style="text-align:center">TP（真正例）</td>
<td style="text-align:center">FN（假反例）</td>
</tr>
<tr>
<td style="text-align:center">反例</td>
<td style="text-align:center">FP（假正例）</td>
<td style="text-align:center">TN（真反例）</td>
</tr>
</tbody>
</table>
<p>查准率 P （precision）与查全率 R 分别定义为：<br>$$<br>P= \frac{TP}{TP+FP}\\<br>R= \frac{TP}{TP+FN}<br>$$<br>用哪个指标来衡量，就看你的归纳偏好是怎样的了，如果看重预测结果中，“预测出来的某类别中有多少是判断正确的”，那就是查准率；如果看重真实情况中，“真实的某类别中有多少是判断正确的”，那就是查全率。</p>
<p><br></p>
<p>除了一些简单任务，查准率与查全率是一堆矛盾指标。查准率可以认为是”宁缺毋滥”，适合对准确率要求高的应用，例如商品推荐，网页检索等。查全率可以认为是”宁错杀一百，不放过1个”，适合类似于检查走私、逃犯信息等。</p>
<ul>
<li><p>P-R 曲线</p>
<p><img src="https://i.loli.net/2018/03/04/5a9b8fe1ef85d.png" alt=""></p>
<p>此处的坑就多啦~ (<a href="https://www.zhihu.com/question/50326563" target="_blank" rel="noopener">REF</a>)</p>
<ul>
<li>首先，这个图究竟是如何画出来的呢？书中说的排序很不清楚。对于一些算法(如逻辑回归)输出的样本预测并不是0或1这样直截了当，而是一对连续的”概率”值，可以衡量样本”最可能”是正例的程度。所以据此对预测后的样本进行排序。</li>
<li>假如一共有 m 个预测后的样本经过了排序，先将排第一最可能是正例的样本取作“正例”（废话！人家本来就是正例），然后取其他 m-1 个预测后的样例为“反例”，于是根据样本预测前的真实标签可以计算得出此时的 P 和 R；再取排名第一和第二的预测后样本为“正例”，其他的 m-2个样例都假装是“反例”，同理再算得出当前的 P 和 R；以此类推，可以算出 m 对 P 和 R，然后绘出 P-R 曲线图。</li>
<li>这样绘图的本质是，<strong>穷尽了该算法预测分类结果的所有阈值可能</strong>（毕竟还用0.5概率作为阈值还是太一厢情愿了），<strong>然后分别与所有样本真实分类标签作对比，即可将不同算法的分类表现区别出来</strong>（此时就仅剩下不同“算法模型”这一个变量了，所谓”待定系数法”嘛）。</li>
<li>周老师的这个图误导性很强，要知道：P=1 时不见得 R=0，P=0 时也不见得 R=1。比方说有<strong>排序后的样本</strong>的真实类别：(1，1，0，1，0，0)，那么当仅第一个样本看作是类别1的话，P-R 上的点对应为（1/(1+0)，1/(1+2)）；如果全部样本看作是类别0的话，P-R 上的点对应为（3/(3+3)，3/(3+0)）；由此可见一斑。事实上，如果算法预测完美，P-R 上对应（1，1）点的可能性也有。</li>
<li>如何从 P-R 图上比较模型算法呢？<ul>
<li>能包住其他算法模型的，性能更优</li>
<li>曲线下面积更大者，性能更优（但不太容易估算）</li>
<li>平衡点（Break-Even Point，BEP） 更大者，性能更优</li>
</ul>
</li>
<li>最后给一个比较真实的 P-R 曲线图。</li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2018/03/04/5a9b9bf218356.png" alt=""></p>
<p>上述是平衡 P 和 R 时的评判方式，更常用的是 F1 度量，可以根据对 P 和 R 不同的重视程度来评估算法。</p>
<ul>
<li><p>F1 度量（对 P 和 R 的加权调和平均）<br>$$<br>\frac{1}{F_\beta} = \frac{1}{1+\beta^2}\cdot\left(\frac{1}{P}+\frac{\beta^2}{R}\right)<br>$$</p>
<ul>
<li>其中，$0&lt;\beta<1$ 时查准率="" p="" 有更大影响；$\beta="">1$ 时查全率 R 有更大影响。</1$></li>
<li>$\beta=1$ 时，是对 P 和 R 的调和平均：</li>
</ul>
</li>
</ul>
<p>$$<br>\frac{1}{F_1} = \frac{1}{2}\cdot\left(\frac{1}{P}+\frac{1}{R}\right)<br>$$</p>
<ul>
<li>对于多个二分类混淆矩阵或者多个数据集上估计算法的“全局”性能，只需要对 P 和 R 做平均即可，也可以对混淆矩阵的四个元素分别平均后得到综合性能。</li>
</ul>
<h3 id="2-3-3-ROC-与-AUC"><a href="#2-3-3-ROC-与-AUC" class="headerlink" title="2.3.3 ROC 与 AUC"></a>2.3.3 ROC 与 AUC</h3><blockquote>
<p>ROC 全称是“受试者工作特征”（Receiver Operating Characteristic）曲线。体现了不同算法在不同任务下“<strong>期望泛化性能</strong>”的好坏。</p>
</blockquote>
<p>ROC 曲线与画 P-R 曲线的方法完全一样，唯一的区别排序计算的坐标轴改为了“真正例率”（True Postitve Rate，TPR） 和“假正例率”（False Positive Rate，FPR）：</p>
<p><br></p>
<table>
<thead>
<tr>
<th style="text-align:center">真实情况</th>
<th style="text-align:center">预测结果</th>
<th style="text-align:center">预测结果</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">正例</td>
<td style="text-align:center">反例</td>
</tr>
<tr>
<td style="text-align:center">正例</td>
<td style="text-align:center">TP（真正例）</td>
<td style="text-align:center">FN（假反例）</td>
</tr>
<tr>
<td style="text-align:center">反例</td>
<td style="text-align:center">FP（假正例）</td>
<td style="text-align:center">TN（真反例）</td>
</tr>
</tbody>
</table>
<p>$$<br>TPR = \frac{TP}{TP+FN}\\<br>FPR = \frac{FP}{TN+FP}<br>$$</p>
<p><img src="https://i.loli.net/2018/03/04/5a9ba86734f89.png" alt=""></p>
<ul>
<li>同 P-R 曲线的分析一样，要先搞清楚极端情况：<ul>
<li>最完美的模型算法是存在某种阈值（ROC 曲线上某点）经过（0，1）这一点（FN=0，FP=0），也就是 ROC 图像的左上角。</li>
<li>ROC 曲线是一定经过（0，0）和（1，1）两点的，分别对应了排序后的样本全部取预测值为反例（TP=0，FP=0）和正例（FN=0，TN=0）。</li>
<li>对角线对应的是TPR=FPR，其代表的是一个“随机乱猜”的算法模型。算法预测正反例的概率各占1/2，那么经过所谓的样本排序后，其上的真实标签是均匀规律交替出现的（如（1，0，1，0，1…）），所以算得的所有混淆矩阵里 TP/FN 和 FP/TN 的比例总是相同的。</li>
</ul>
</li>
<li>ROC 曲线上判断算法模型的好坏：<ul>
<li>能包住其他算法模型的，性能更优</li>
<li>曲线下面积（AUC）更大者，性能更优</li>
</ul>
</li>
</ul>
<p><br></p>
<h3 id="2-3-4-代价敏感错误率与代价曲线（略）"><a href="#2-3-4-代价敏感错误率与代价曲线（略）" class="headerlink" title="2.3.4 代价敏感错误率与代价曲线（略）"></a>2.3.4 代价敏感错误率与代价曲线（略）</h3><blockquote>
<p>开始考虑非均等代价，并可以适用于多分类任务。</p>
</blockquote>
<p><br></p>
<h2 id="2-4-比较检验（略）"><a href="#2-4-比较检验（略）" class="headerlink" title="2.4 比较检验（略）"></a>2.4 比较检验（略）</h2><p><br></p>
<h2 id="2-5-偏差与方差"><a href="#2-5-偏差与方差" class="headerlink" title="2.5 偏差与方差"></a>2.5 偏差与方差</h2><blockquote>
<p>泛化误差 = 偏差 + 方差 + 噪声</p>
</blockquote>
<p>其中，噪声造成了 true label 和 observed label 之间的区别，表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，也就是说“天公不作美，再努力也有力不从心的时候”。</p>
<ul>
<li>REF：<ul>
<li><a href="http://blog.csdn.net/simple_the_best/article/details/71167786" target="_blank" rel="noopener">理解机器学习中的偏差与方差</a></li>
<li><a href="https://towardsdatascience.com/mse-and-bias-variance-decomposition-77449dd2ff55" target="_blank" rel="noopener">MSE and Bias-Variance decomposition</a></li>
</ul>
</li>
</ul>
<p><br></p>
<h1 id="第3章-线性模型"><a href="#第3章-线性模型" class="headerlink" title="第3章 线性模型"></a>第3章 线性模型</h1></section>
    <!-- Tags START -->
    
      <div class="tags">
        <span>Tags:</span>
        
  <a href="/tags#怒啃西瓜书" >
    <span class="tag-code">怒啃西瓜书</span>
  </a>

      </div>
    
    <!-- Tags END -->
    <!-- NAV START -->
    
  <div class="nav-container">
    <!-- reverse left and right to put prev and next in a more logic postition -->
    
      <a class="nav-left" href="/2018/03/NG_DeepLearning2/">
        <span class="nav-arrow">← </span>
        
          品读 A. Ng 的 DeepLearning.ai 之“改善深层神经网络”
        
      </a>
    
    
  </div>

    <!-- NAV END -->
    <!-- 打赏 START -->
    
      <div class="money-like">
        <div class="reward-btn">
          赏
          <span class="money-code">
            <span class="alipay-code">
              <div class="code-image"></div>
              <b>使用支付宝打赏</b>
            </span>
            <span class="wechat-code">
              <div class="code-image"></div>
              <b>使用微信打赏</b>
            </span>
          </span>
        </div>
        <p class="notice">若你觉得我的文章对你有帮助，欢迎点击上方按钮对我打赏</p>
      </div>
    
    <!-- 打赏 END -->
    <!-- 二维码 START -->
    
      <div class="qrcode">
        <canvas id="share-qrcode"></canvas>
        <p class="notice">扫描二维码，分享此文章</p>
      </div>
    
    <!-- 二维码 END -->
    
      <!-- Gitment START -->
      <div id="comments"></div>
      <!-- Gitment END -->
    
  </article>
  <!-- Article END -->
  <!-- Catalog START -->
  
    <aside class="catalog-container">
  <div class="toc-main">
    <strong class="toc-title">Catalog</strong>
    
      <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#第1章-绪论"><span class="toc-nav-text">第1章 绪论</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#第2章-模型评估与选择"><span class="toc-nav-text">第2章 模型评估与选择</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-1-经验误差与过拟合"><span class="toc-nav-text">2.1 经验误差与过拟合</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-2-评估方法"><span class="toc-nav-text">2.2 评估方法</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#2-2-1-留出法"><span class="toc-nav-text">2.2.1 留出法</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#2-2-2-交叉验证法"><span class="toc-nav-text">2.2.2 交叉验证法</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#2-2-3-自助法"><span class="toc-nav-text">2.2.3 自助法</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#2-2-4-调参与最终模型"><span class="toc-nav-text">2.2.4 调参与最终模型</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-3-性能度量"><span class="toc-nav-text">2.3 性能度量</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#2-3-1-错误率与精度"><span class="toc-nav-text">2.3.1 错误率与精度</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#2-3-2-查准率、查全率与-F1"><span class="toc-nav-text">2.3.2 查准率、查全率与 F1</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#2-3-3-ROC-与-AUC"><span class="toc-nav-text">2.3.3 ROC 与 AUC</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#2-3-4-代价敏感错误率与代价曲线（略）"><span class="toc-nav-text">2.3.4 代价敏感错误率与代价曲线（略）</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-4-比较检验（略）"><span class="toc-nav-text">2.4 比较检验（略）</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-5-偏差与方差"><span class="toc-nav-text">2.5 偏差与方差</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#第3章-线性模型"><span class="toc-nav-text">第3章 线性模型</span></a></li></ol>
    
  </div>
</aside>
  
  <!-- Catalog END -->
</main>

<script>
  (function () {
    var url = 'http://iphysresearch.github.io/2018/03/ML_ZHOU1/';
    var banner = 'https://i.loli.net/2018/03/02/5a993e559d4d1.jpg'
    if (banner !== '' && banner !== 'undefined' && banner !== 'null') {
      $('#article-banner').css({
        'background-image': 'url(' + banner + ')'
      })
    } else {
      $('#article-banner').geopattern(url)
    }
    $('.header').removeClass('fixed-header')

     // error image
    $(".markdown-content img").on('error', function() {
      $(this).attr('src', 'http://file.muyutech.com/error-img.png')
      $(this).css({
        'cursor': 'default'
      })
    })

    // zoom image
    $(".markdown-content img").on('click', function() {
      var src = $(this).attr('src')
      if (src !== 'http://file.muyutech.com/error-img.png') {
        var imageW = $(this).width()
        var imageH = $(this).height()
        
        var zoom = ($(window).width() * 0.95 / imageW).toFixed(2)
        zoom = zoom < 1 ? 1 : zoom
        zoom = zoom > 2 ? 2 : zoom
        var transY = (($(window).height() - imageH) / 2).toFixed(2)

        $('body').append('<div class="image-view-wrap"><div class="image-view-inner"><img src="'+ src +'" /></div></div>')
        $('.image-view-wrap').addClass('wrap-active')
        $('.image-view-wrap img').css({
          'width': `${imageW}`,
          'transform': `translate3d(0, ${transY}px, 0) scale3d(${zoom}, ${zoom}, 1)`
        })
        $('html').css('overflow', 'hidden')

        $('.image-view-wrap').on('click', function() {
          $(this).remove()
          $('html').attr('style', '')
        })
      }
    })

    // qrcode
    var qr = new QRious({
      element: document.getElementById('share-qrcode'),
      value: document.location.href
    });

    // gitment
    var gitmentConfig = "iphysresearch";
    if (gitmentConfig !== 'undefined') {
      var gitment = new Gitment({
        id: "《机器学习》(周志华)——要点笔记1",
        owner: "iphysresearch",
        repo: "iphysresearch.github.io",
        oauth: {
          client_id: "6b978dc207dc30e58ec8",
          client_secret: "2bc56895d0221e8c27ab87b072f8f18523231e22"
        },
        theme: {
          render(state, instance) {
            const container = document.createElement('div')
            container.lang = "en-US"
            container.className = 'gitment-container gitment-root-container'
            container.appendChild(instance.renderHeader(state, instance))
            container.appendChild(instance.renderEditor(state, instance))
            container.appendChild(instance.renderComments(state, instance))
            container.appendChild(instance.renderFooter(state, instance))
            return container;
          }
        }
      })
      gitment.render(document.getElementById('comments'))
    }
  })();
</script>

    <div class="scroll-top">
  <span class="arrow-icon"></span>
</div>
    <footer class="app-footer">
  <p class="copyright">
    &copy; 2018 | Proudly powered by <a href="https://hexo.io" target="_blank">Hexo</a>
    <br>
    Theme by <a href="https://github.com/yanm1ng">yanm1ng</a>
  </p>
</footer>

<script>
  function async(u, c) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }
</script>
<script>
  async("//cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
    FastClick.attach(document.body);
  })
</script>

<script>
  var hasLine = 'true';
  async("//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js", function(){
    $('figure pre').each(function(i, block) {
      var figure = $(this).parents('figure');
      if (hasLine === 'false') {
        figure.find('.gutter').hide();
      }
      var lang = figure.attr('class').split(' ')[1] || 'code';
      var codeHtml = $(this).html();
      var codeTag = document.createElement('code');
      codeTag.className = lang;
      codeTag.innerHTML = codeHtml;
      $(this).attr('class', '').empty().html(codeTag);
      figure.attr('data-lang', lang.toUpperCase());
      hljs.highlightBlock(block);
    });
  })
</script>
<!-- Baidu Tongji -->

<script src="/js/script.js"></script>
  </body>
</html>