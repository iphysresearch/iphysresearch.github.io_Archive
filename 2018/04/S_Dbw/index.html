<!DOCTYPE html>
<html>
  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  <meta name="description" content="Machine Learning, Deep Learning, Physics">
  <meta name="keyword" content="hexo-theme, vuejs">
  
    <link rel="shortcut icon" href="/css/images/logo.png">
  
  <title>
    
      S_Dbw 聚类评估指标（代码全解析） | Teaching is Learning
    
  </title>
  <link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.css" rel="stylesheet">
  <link href="//cdn.bootcss.com/highlight.js/9.12.0/styles/tomorrow.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/style.css">
<link rel="stylesheet" href="/css/plugins/gitment.css">
  <script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
  <script src="//cdn.bootcss.com/geopattern/1.2.3/js/geopattern.min.js"></script>
  <script src="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.js"></script>
  <script src="/js/qrious.js"></script>
<script src="/js/gitment.js"></script>
  
  
    <!-- MathJax support START -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- MathJax support END -->
  


  <script src="https://hypothes.is/embed.js" async></script>
</head>
<div class="wechat-share">
  <img src="/css/images/logo.png" />
</div>

  <body>
    <header class="header fixed-header">
  <div class="header-container">
    <a class="home-link" href="/">
      <div class="logo"></div>
      <span>Teaching is Learning</span>
    </a>
    <ul class="right-list">
      
        <li class="list-item">
          
            <a href="/" class="item-link">Home</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/tags/" class="item-link">Tags</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/archives/" class="item-link">Archives</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/project/" class="item-link">Projects</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/about/" class="item-link">About</a>
          
        </li>
      
    </ul>
    <div class="menu">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </div>
    <div class="menu-mask">
      <ul class="menu-list">
        
          <li class="menu-item">
            
              <a href="/" class="menu-link">Home</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/tags/" class="menu-link">Tags</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/archives/" class="menu-link">Archives</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/project/" class="menu-link">Projects</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/about/" class="menu-link">About</a>
            
          </li>
        
      </ul>
    </div>
  </div>
</header>

    <div id="article-banner">
  <h2>S_Dbw 聚类评估指标（代码全解析）</h2>
  <p class="post-date">2018-04-10</p>
  <div class="arrow-down">
    <a href="javascript:;"></a>
  </div>
</div>
<main class="app-body flex-box">
  <!-- Article START -->
  <article class="post-article">
      <section class="markdown-content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><blockquote>
<p><code>S_Dbw</code> 算法的原论文地址：<a href="https://pdfs.semanticscholar.org/dc44/df745fbf5794066557e52074d127b31248b2.pdf" target="_blank" rel="noopener">Clustering Validity Assessment: Finding the optimal partitioning of a data set</a></p>
<p>本文算法的 Rep 地址：<a href="https://github.com/iphysresearch/S_Dbw_validity_index" target="_blank" rel="noopener">https://github.com/iphysresearch/S_Dbw_validity_index</a></p>
</blockquote>
<p>此文的 motivation 来自于近期接的某无监督 k-means 聚类项目，并计划是用基于 K-means 算法的 <a href="https://github.com/nicodv/kmodes" target="_blank" rel="noopener"><code>k-prototypes</code></a> 聚类算法来打发了事。为了对聚类结果给出合理靠谱的评估评价，最终决定主要参考 <code>S_Dbw</code> 评估指标，并且打算写作此文，非原理性的解析 <code>S_Dbw</code>，原因有二：</p>
<a id="more"></a>
<ol>
<li>在2001年有一篇引用率挺高(300+)的 paper <sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="[      Clustering validity assessment: Finding the optimal partitioning of a data set](http://ieeexplore.ieee.org/abstract/document/989517/) （[下载地址](http://datamining.rutgers.edu/publication/internalmeasures.pdf)）
">[1]</span></a></sup>谈到说，<code>S_Dbw</code> 聚类评价指标对于各种噪声，不同密度的数据集等等干扰项来调参的鲁棒性最强，直接完爆其他所有评价指标~ </li>
<li><code>S_Dbw</code> 算法在 sciki-learn 中至今还没有被添加到 api 中 <sup id="fnref:2"><a href="#fn:2" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="[     Add more unsupervised clustering metrics #6654](https://github.com/scikit-learn/scikit-learn/issues/6654)
">[2]</span></a></sup>，相比， R 语言里却有现成且很好的 api 可以调用，如  <a href="https://rdrr.io/cran/clv/man/SD_SDbw.html" target="_blank" rel="noopener"><code>clv</code></a> 和 <a href="https://github.com/cran/NbClust" target="_blank" rel="noopener"><code>NbClust</code></a> <sup id="fnref:3"><a href="#fn:3" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="[NbClust: An R Package for Determining the Relevant Number of Clusters in a Data Set](https://www.jstatsoft.org/article/view/v061i06/v61i06.pdf)">[3]</span></a></sup>。关于 <code>S_Dbw</code> 算法现成的 Python 代码版本，在网络上也难以寻觅，唯一的参考是 fanfanda 的 <a href="https://github.com/fanfanda/S_Dbw" target="_blank" rel="noopener">版本</a>。不过，此代码应该是有问题的，它聚类中心的定义是有误的。</li>
</ol>
<p>综上，自己决定在 fanfanda 的代码基础上修正代码，并且贴出此代码算法的详细解析。</p>
<p><br></p>
<p>注：符号完全参考论文原文，且已尽可能的说明算法的内涵和代码实现原理，更详细信息请参阅原论文。</p>
<p><br></p>
<hr>
<p><br></p>
<pre><code class="python">import numpy as np
</code></pre>
<p>我们先给出数学上的预定义：</p>
<p><br></p>
<p>说 $D = \{\nu_i|i_1,\dots,c\}$ 是一个针对数据集 S 的划分，分成了 c 个类，其中的 $\nu_i$ 就是第 $i$ 类的中心。</p>
<p><br></p>
<p>下面定义类 <code>S_Dbw</code>，并且可以看到，算法的输入信息有三个方面：数据集+聚类结果+各聚类类别的”中心”</p>
<script src="https://gist.github.com/iphysresearch/ce548d477ca4e756b5d1f32fa8e29b87.js"></script>

<p>在上面的初始化中，我们定义了一个叫做 <code>stdev</code> 的变量，定义为每个类的平均标准方差：<br>$$<br>stdev = \frac{1}{c}\sqrt{\sum^c_{i=1}||\sigma(\nu_i)||}<br>$$<br>其中，符号 $||\cdot||$ 表示为 $||\mathbf{x}||=(\mathbf{x}^T\mathbf{x})^{1/2}$ （矢量的欧式距离，或者说白了，就是高维空间中坐标两点之间的欧氏距离）。</p>
<p><br></p>
<p>下面开始计算所谓的 Inter-cluster Density（ID），即要定义的 <code>Dens_bw</code> 函数。但在此之前，需要先行考量计算的是一个关于两个类之间的 density，定义如下：<br>$$<br>density(u)=\sum^{n_{ij}}_{l=1}f(x_l,u), \,\text{where } n_{ij}= \text{ number of tuples}<br>$$<br>其中，$x_l$ 是以 $u$ 为邻域内的样本个数，显然这个样本数目肯定不会超过两个类的合并，更不会超过整个数据量，也就是说满足：$x_l\in c_i\cup c_j \subseteq S$。所以说，上面的公式针对两个类别样本，只要给定一个邻域范围 $u$，就可以给出一个 scalar 来表征密度的含义。那么 $u$ 怎么定义？表征密度的 $f$ 函数又怎么定义呢？说来就来，立马给你定义！<br>$$<br>f(x,u) = \left\{\begin{matrix}<br> 0,&amp; \text{if } d(x,u)&gt;stdev\\<br> 1,&amp; \text{otherwise}<br>\end{matrix}\right.<br>$$<br>这是啥意思呢？</p>
<p><br></p>
<p>上面定义过的 <code>stdev</code> 相当于是给每个聚类类别定义了一个“单位圆“作为标准。$f$ 函数所做的事情就是数数啊，假如考虑的是某单类 $i$ 里的 $density(\nu_i)$，那就去数究竟有多少个样本可以落到该聚类类别中心点外 $\nu_i$ 的这个标准范围 <code>stdev</code> 内。如果说是像上面某两个类 $(i,j)$ 的 $density(u_{ij})$ 的情况话，也简单，把这两个类中的中心点当做新的中心，再看它附近”单位圆“里有多少个样本。</p>
<p><br></p>
<p>值得注意的是，我刚刚用了”圆“这个词，其实也就是暗示了每个样本的维度是 comparable 的。也就是说数据至少要做过标准化才行哦~ 最好也是正态化好的。</p>
<p><br></p>
<p>下面就是这个 <code>density(density_list=[])</code> 函数的定义了：</p>
<p>定义完 <code>density()</code> ，我们就终于可以给出 Inter-cluster Density（ID），即要定义的 <code>Dens_bw</code> 函数：<br>$$<br>\text{Dens_bw}(c) = \frac{1}{c\cdot(c-1)}\sum^c_{i=1}\left(\sum^c_{j=1,j\neq i} \frac{density(u_{ij})}{\max\{density(\nu_i),density(\nu_j)\}}\right)<br>$$<br>这个时候，上面的公式就好读多了。</p>
<p><br></p>
<p>大括号里有很多项是加起来的，每一项对应于在所有聚类类别中，两两匹配且有序不重复的去穷举（所谓“排列”规则，如6个里面取2个就有 $6^2$ 种取法）。其中分子是两个聚类类别合在一起的密度，再除以该两个聚类类别里密度相对最大的那个。可见，如果两个聚类中心分得很开，同时每个类还各自密度很高很紧凑，那么分子就越小（两个类中心的中点处密度甚至可能为0），分母就越大（显然每类越紧凑，密度越大嘛）。所以，由此可见一斑，这个评估指标是越小越好啊！</p>
<script src="https://gist.github.com/iphysresearch/ce548d477ca4e756b5d1f32fa8e29b87.js"></script>



<p><br></p>
<p>下面的代码对应的就是上面公式 <code>Dens_bw</code>：</p>
<script src="https://gist.github.com/iphysresearch/5caed5bdeda23668e1b098b924bd26e8.js"></script>

<p>我们把 <code>Dens_bw</code> 定义好后，任务只能说是刚过半。接下来要把另一半定义清楚，即_Intra-cluster variance_ ，所谓对 average scattering 的衡量，定义为 <code>Scat()</code> 函数：<br>$$<br>\text{Scat}(c) = \frac{1}{c}\sum^c_{i=1}\frac{||\sigma(\nu_i)||}{||\sigma(S)||}<br>$$<br>上式中，$||\sigma(S)||$ 表示的是整个样本数据 $S$ 的方差，那么 $||\sigma(\nu_i)||$ 表示的就是第 $i$ 类样本数据的方差。一个数列的方差我们很清楚，俺么话说一个二维数列的方差是什么鬼呢？原论文给出了详细的解释：不管是整个样本数据集 $S$ 还是其中的某一类样本数据集合 $\nu_i$。所谓方差，是对数据集合的每一列（每一个特征）求方差，得到一个维数为特征数目的向量 $\mathbf{x}$，然后就是如上法炮制去算该矢量的欧式距离 $||\mathbf{x}||$ 即可。</p>
<script src="https://gist.github.com/iphysresearch/dbd440a8ba7bb1595daedc6ebdb097d6.js"></script>

<p>从上面的公式也可以晓得，如果所有的聚类类目在高维特征空间上散布的很开（即 $||\sigma(S)||$ 挺大的），同时每个聚类类别各自在空间中散布的很紧凑（$||\sigma(\nu_i)||$都挺小），那不就说明聚类效果还不错，输出 <code>Scat()</code> 也就对应于一个较小的评估值。</p>
<p><br></p>
<p>综上呢，我们的 <code>S_Dbw</code> 聚类评估指标就是把 <code>Dens_bw()</code> 和 <code>Scat()</code> 的结果加起来，即可万事大吉：</p>
<script src="https://gist.github.com/iphysresearch/8f733071a4269ec2cb3dcf07c42b9ff6.js"></script>

<p>来个栗子，瞧一瞧！</p>
<p><br></p>
<p>固定住模拟数据的中心点，变化散布程度：</p>
<p><img src="https://i.loli.net/2018/04/10/5accba84c4288.png" alt=""></p>
<p>变化模拟数据的中心点，固定每类的散布程度：</p>
<p><img src="https://i.loli.net/2018/04/10/5accba9fb87b5.png" alt=""></p>
<p>上面两个图的代码如下：</p>
<pre><code class="python">import numpy as np
import S_Dbw as sdbw
from sklearn.cluster import KMeans
from sklearn.datasets.samples_generator import make_blobs
from sklearn.metrics.pairwise import pairwise_distances_argmin

np.random.seed(0)

S_Dbw_result = []
batch_size = 45
centers = [[1, 1], [-1, -1], [1, -1]]
cluster_std=[0.7,0.3,1.2]
n_clusters = len(centers)
X1, _ = make_blobs(n_samples=3000, centers=centers, cluster_std=cluster_std[0])
X2, _ = make_blobs(n_samples=3000, centers=centers, cluster_std=cluster_std[1])
X3, _ = make_blobs(n_samples=3000, centers=centers, cluster_std=cluster_std[2])

import matplotlib.pyplot as plt
fig = plt.figure(figsize=(9, 3))
fig.subplots_adjust(left=0.02, right=0.98, bottom=0.08, top=0.9)
colors = [&#39;#4EACC5&#39;, &#39;#FF9C34&#39;, &#39;#4E9A06&#39;]

for item, X in enumerate(list([X1, X2, X3])):
    k_means = KMeans(init=&#39;k-means++&#39;, n_clusters=3, n_init=10)
    k_means.fit(X)

    k_means_cluster_centers = k_means.cluster_centers_
    k_means_labels = pairwise_distances_argmin(X, k_means_cluster_centers)

    KS = sdbw.S_Dbw(X, k_means_labels, k_means_cluster_centers)
    S_Dbw_result.append(KS.S_Dbw_result())

    ax = fig.add_subplot(1,3,item+1)
    for k, col in zip(range(n_clusters), colors):
        my_members = k_means_labels == k
        cluster_center = k_means_cluster_centers[k]
        ax.plot(X[my_members, 0], X[my_members, 1], &#39;w&#39;,
                markerfacecolor=col, marker=&#39;.&#39;)
        ax.plot(cluster_center[0], cluster_center[1], &#39;o&#39;, markerfacecolor=col,
                markeredgecolor=&#39;k&#39;, markersize=6)
    ax.set_title(&#39;S_Dbw: %.3f&#39; %(S_Dbw_result[item]))
    ax.set_ylim((-4,4))
    ax.set_xlim((-4,4))
    plt.text(-3.5, 1.8, &#39;cluster_std: %f&#39; %(cluster_std[item]))
plt.savefig(&#39;./pic1.png&#39;, dpi=150)
</code></pre>
<pre><code class="python">np.random.seed(0)

S_Dbw_result = []
batch_size = 45
centers = [[[1, 1], [-1, -1], [1, -1]],
            [[0.8, 0.8], [-0.8, -0.8], [0.8, -0.8]],
            [[1.2, 1.2], [-1.2, -1.2], [1.2, -1.2]]]
n_clusters = len(centers)
X1, _ = make_blobs(n_samples=3000, centers=centers[0], cluster_std=0.7)
X2, _ = make_blobs(n_samples=3000, centers=centers[1], cluster_std=0.7)
X3, _ = make_blobs(n_samples=3000, centers=centers[2], cluster_std=0.7)

import matplotlib.pyplot as plt
fig = plt.figure(figsize=(8, 3))
fig.subplots_adjust(left=0.02, right=0.98, bottom=0.2, top=0.9)
colors = [&#39;#4EACC5&#39;, &#39;#FF9C34&#39;, &#39;#4E9A06&#39;]

for item, X in enumerate(list([X1, X2, X3])):
    k_means = KMeans(init=&#39;k-means++&#39;, n_clusters=3, n_init=10)
    k_means.fit(X)

    k_means_cluster_centers = k_means.cluster_centers_
    k_means_labels = pairwise_distances_argmin(X, k_means_cluster_centers)

    KS = sdbw.S_Dbw(X, k_means_labels, k_means_cluster_centers)
    S_Dbw_result.append(KS.S_Dbw_result())

    ax = fig.add_subplot(1,3,item+1)
    for k, col in zip(range(n_clusters), colors):
        my_members = k_means_labels == k
        cluster_center = k_means_cluster_centers[k]
        ax.plot(X[my_members, 0], X[my_members, 1], &#39;w&#39;,
                markerfacecolor=col, marker=&#39;.&#39;)
        ax.plot(cluster_center[0], cluster_center[1], &#39;o&#39;, markerfacecolor=col,
                markeredgecolor=&#39;k&#39;, markersize=6)
    ax.set_title(&#39;S_Dbw: %.3f &#39; %(S_Dbw_result[item]))
#     ax.set_xticks(())
#     ax.set_yticks(())
    ax.set_ylim((-4,4))
    ax.set_xlim((-4,4))
    ax.set_xlabel(&#39;centers: \n%s&#39; %(centers[item]))
plt.savefig(&#39;./pic2.png&#39;, dpi=150)
</code></pre>
<p><br></p>
<div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a href="http://ieeexplore.ieee.org/abstract/document/989517/" target="_blank" rel="noopener">      Clustering validity assessment: Finding the optimal partitioning of a data set</a> （<a href="http://datamining.rutgers.edu/publication/internalmeasures.pdf" target="_blank" rel="noopener">下载地址</a>）<a href="#fnref:1" rev="footnote"> ↩</a></span></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">2.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a href="https://github.com/scikit-learn/scikit-learn/issues/6654" target="_blank" rel="noopener">     Add more unsupervised clustering metrics #6654</a><a href="#fnref:2" rev="footnote"> ↩</a></span></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">3.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a href="https://www.jstatsoft.org/article/view/v061i06/v61i06.pdf" target="_blank" rel="noopener">NbClust: An R Package for Determining the Relevant Number of Clusters in a Data Set</a><a href="#fnref:3" rev="footnote"> ↩</a></span></li></ol></div></div></section>
      <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
    <!-- Tags START -->
    
      <div class="tags">
        <span>Tags:</span>
        
  <a href="/tags#Cluster" >
    <span class="tag-code">Cluster</span>
  </a>

      </div>
    
    <!-- Tags END -->
    <!-- NAV START -->
    
  <div class="nav-container">
    <!-- reverse left and right to put prev and next in a more logic postition -->
    
      <a class="nav-left" href="/2018/02/CS231n_MXNet8/">
        <span class="nav-arrow">← </span>
        
          CS231n 讲义笔记：卷积神经网络
        
      </a>
    
    
  </div>

    <!-- NAV END -->
    <!-- 打赏 START -->
    
      <div class="money-like">
        <div class="reward-btn">
          赏
          <span class="money-code">
            <span class="alipay-code">
              <div class="code-image"></div>
              <b>使用支付宝打赏</b>
            </span>
            <span class="wechat-code">
              <div class="code-image"></div>
              <b>使用微信打赏</b>
            </span>
          </span>
        </div>
        <p class="notice">若你觉得我的文章对你有帮助，欢迎点击上方按钮对我打赏</p>
      </div>
    
    <!-- 打赏 END -->
    <!-- 二维码 START -->
    
      <div class="qrcode">
        <canvas id="share-qrcode"></canvas>
        <p class="notice">扫描二维码，分享此文章</p>
      </div>
    
    <!-- 二维码 END -->
    
      <!-- Gitment START -->
      <div id="comments"></div>
      <!-- Gitment END -->
    
  </article>
  <!-- Article END -->
  <!-- Catalog START -->
  
    <aside class="catalog-container">
  <div class="toc-main">
    <strong class="toc-title">Catalog</strong>
    
      <ol class="nav">none</ol>
    
  </div>
</aside>
  
  <!-- Catalog END -->
</main>

<script>
  (function () {
    var url = 'http://iphysresearch.github.io/2018/04/S_Dbw/';
    var banner = 'https://i.loli.net/2018/04/10/5accbcb5b09fe.png'
    if (banner !== '' && banner !== 'undefined' && banner !== 'null') {
      $('#article-banner').css({
        'background-image': 'url(' + banner + ')'
      })
    } else {
      $('#article-banner').geopattern(url)
    }
    $('.header').removeClass('fixed-header')

     // error image
    $(".markdown-content img").on('error', function() {
      $(this).attr('src', 'http://file.muyutech.com/error-img.png')
      $(this).css({
        'cursor': 'default'
      })
    })

    // zoom image
    $(".markdown-content img").on('click', function() {
      var src = $(this).attr('src')
      if (src !== 'http://file.muyutech.com/error-img.png') {
        var imageW = $(this).width()
        var imageH = $(this).height()
        
        var zoom = ($(window).width() * 0.95 / imageW).toFixed(2)
        zoom = zoom < 1 ? 1 : zoom
        zoom = zoom > 2 ? 2 : zoom
        var transY = (($(window).height() - imageH) / 2).toFixed(2)

        $('body').append('<div class="image-view-wrap"><div class="image-view-inner"><img src="'+ src +'" /></div></div>')
        $('.image-view-wrap').addClass('wrap-active')
        $('.image-view-wrap img').css({
          'width': `${imageW}`,
          'transform': `translate3d(0, ${transY}px, 0) scale3d(${zoom}, ${zoom}, 1)`
        })
        $('html').css('overflow', 'hidden')

        $('.image-view-wrap').on('click', function() {
          $(this).remove()
          $('html').attr('style', '')
        })
      }
    })

    // qrcode
    var qr = new QRious({
      element: document.getElementById('share-qrcode'),
      value: document.location.href
    });

    // gitment
    var gitmentConfig = "iphysresearch";
    if (gitmentConfig !== 'undefined') {
      var gitment = new Gitment({
        id: "S_Dbw 聚类评估指标（代码全解析）",
        owner: "iphysresearch",
        repo: "iphysresearch.github.io",
        oauth: {
          client_id: "6b978dc207dc30e58ec8",
          client_secret: "2bc56895d0221e8c27ab87b072f8f18523231e22"
        },
        theme: {
          render(state, instance) {
            const container = document.createElement('div')
            container.lang = "en-US"
            container.className = 'gitment-container gitment-root-container'
            container.appendChild(instance.renderHeader(state, instance))
            container.appendChild(instance.renderEditor(state, instance))
            container.appendChild(instance.renderComments(state, instance))
            container.appendChild(instance.renderFooter(state, instance))
            return container;
          }
        }
      })
      gitment.render(document.getElementById('comments'))
    }
  })();
</script>

    <div class="scroll-top">
  <span class="arrow-icon"></span>
</div>
    <footer class="app-footer">
  <p class="copyright">
    &copy; 2018 | Proudly powered by <a href="https://hexo.io" target="_blank">Hexo</a>
    <br>
    Theme by <a href="https://github.com/yanm1ng">yanm1ng</a>
  </p>
</footer>

<script>
  function async(u, c) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }
</script>
<script>
  async("//cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
    FastClick.attach(document.body);
  })
</script>

<script>
  var hasLine = 'true';
  async("//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js", function(){
    $('figure pre').each(function(i, block) {
      var figure = $(this).parents('figure');
      if (hasLine === 'false') {
        figure.find('.gutter').hide();
      }
      var lang = figure.attr('class').split(' ')[1] || 'code';
      var codeHtml = $(this).html();
      var codeTag = document.createElement('code');
      codeTag.className = lang;
      codeTag.innerHTML = codeHtml;
      $(this).attr('class', '').empty().html(codeTag);
      figure.attr('data-lang', lang.toUpperCase());
      hljs.highlightBlock(block);
    });
  })
</script>
<!-- Baidu Tongji -->

<script src="/js/script.js"></script>
  </body>
</html>