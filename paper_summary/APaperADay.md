---
title: A Paper A Day
date: 2018-09-28
---

[返回到首页](../index.html) | [返回到 Paper Summary](./index.html)

---

![](https://i.loli.net/2018/09/28/5bad80bf9e4bf.png)

---



# :pencil2: A Paper A Day

> Felt like I wasn’t reading enough – and what I was reading wasn’t sinking in enough. I also wanted to keep track of my sources in a more controlled manner. As a part of adding everything to my JabRef (maybe…), I figured I would write up my comments on papers. 
>
> The goal is to read and comment once a day and this [post](./APaperADay.html) will be updated day by day according to the reading process.

[TOC]

## :repeat: Generative Models

**On Finding Local Nash Equilibria (and Only Local Nash Equilibria) in Zero-Sum Games**. E V. Mazumdar, M I. Jordan, S. S Sastry [UC Berkeley] (2019) [arXiv:1901.00838](https://arxiv.org/abs/1901.00838)

**Evaluating Generative Adversarial Networks on Explicitly Parameterized Distributions**. S O'Brien, M Groh, A Dubey [MIT] (2018) [arXiv:1812.10782](https://arxiv.org/abs/1812.10782) [Github](https://github.com/shayneobrien/explicit-gan-eval)

**InstaGAN: Instance-aware Image-to-Image Translation**. S Mo, M Cho, J Shin [Korea Advanced Institute of Science and Technology (KAIST) & Pohang University of Science and Technology (POSTECH)] (2018) [arXiv:1812.10889](https://arxiv.org/abs/1812.10889) [OpenReview.net](https://openreview.net/forum?id=ryxwJhC9YX) [Github](https://github.com/sangwoomo/instagan)  [机器之心](https://www.jiqizhixin.com/articles/2019-01-02-17)

**Improving Generalization and Stability of Generative Adversarial Networks**. H Thanh-Tung, T Tran, S Venkatesh [Deakin University] (ICLR 2018) [OpenReview.net](https://openreview.net/forum?id=ByxPYjC5KQ) [Github](https://github.com/LMescheder/GAN_stability)

**Finger-GAN: Generating Realistic Fingerprint Images Using Connectivity Imposed GAN**. S Minaee, A Abdolrashidi [New York University & University of California, Riverside] (2018) [arXiv:1812.10482](https://arxiv.org/abs/1812.10482) 

**Generative Models from the perspective of Continual Learning**. T Lesort, H Caselles-Dupré, M Garcia-Ortiz, A Stoian, D Filliat [Flowers Team (ENSTA ParisTech & INRIA)] (2018) [arXiv:1812.09111](https://arxiv.org/abs/1812.09111) [Github](https://github.com/TLESORT/Generative_Continual_Learning) [OpenReview.net](https://openreview.net/forum?id=S1eFtj0cKQ)

**A Probe into Understanding GAN and VAE models**. J Zhang, L Mi, M Shen [MIT] (2018) [arXiv:1812.05676](https://arxiv.org/abs/1812.05676)

**A Style-Based Generator Architecture for Generative Adversarial Networks**. T Karras, S Laine, T Aila [NVIDIA] (2018) [arXiv:1812.04948](https://arxiv.org/abs/1812.04948) [Code](https://docs.google.com/document/d/1SDbnM1nxLZNuwD8fQkIigUve_SlihgoCmvjN3e388Us/edit) [YouTube](https://www.youtube.com/watch?v=kSLJriaOumA) [机器之心](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650753854&idx=4&sn=683d862b174cb26c01c1e4d7541498d7)

**Intra-class Variation Isolation in Conditional GANs**. R T. Marriott, S Romdhani, L Chen [Ecole Centrale de Lyon & IDEMIA] (2018) [arXiv:1811.11296](https://arxiv.org/abs/1811.11296)

**Metropolis-Hastings Generative Adversarial Networks**. R Turner, J Hung, Y Saatci, J Yosinski [Uber AI Labs] (2018) [arXiv:1811.11357](https://arxiv.org/abs/1811.11357) [Github](https://github.com/uber-research/metropolis-hastings-gans) [Blog](https://eng.uber.com/mh-gan/)

**Label-Noise Robust Generative Adversarial Networks**. Takuhiro Kaneko, Yoshitaka Ushiku, Tatsuya Harada [The University of Tokyo & RIKEN] (2018) [arXiv:1811.11165](https://arxiv.org/abs/1811.11165)

**Do GAN Loss Functions Really Matter?**. Y Qin, N Mitra, P Wonka [KAUST & UCL] (2018) [arXiv:1811.09567](https://arxiv.org/abs/1811.09567) [Reddit](https://www.reddit.com/r/MachineLearning/comments/a0p9wg/r_do_gan_loss_functions_really_matter/)

**Copy the Old or Paint Anew? An Adversarial Framework for (non-) Parametric Image Stylization**. N Jetchev, U Bergmann, G Yildirim [Zalando Research] (2018) [arXiv:1811.09236](https://arxiv.org/abs/1811.09236) [GitHub](https://github.com/zalandoresearch/famos)

**Guiding the One-to-one Mapping in CycleGAN via Optimal Transport**. G Lu, Z Zhou, Y Song, K Ren, Y Yu [Shanghai Jiao Tong University] (2018) [arXiv:1811.06284](https://arxiv.org/abs/1811.06284)

**NEMGAN: Noise Engineered Mode-matching GAN**. D Mishra, P AP, A J, P Pandey, S Chaudhury [Indian Institute of Technology Delhi] (2018) [arXiv:1811.03692](https://arxiv.org/abs/1811.03692) [GitHub](https://github.com/NEMGAN/NEMGAN)

**Bias and Generalization in Deep Generative Models: An Empirical Study**. S Zhao, H Ren, A Yuan, J Song, N Goodman, S Ermon [Stanford University] ([ICML2018](https://sites.google.com/view/tadgm/home?authuser=0)) [arXiv:1811.03259](https://arxiv.org/abs/1811.03259) [GitHub](https://github.com/ermongroup/BiasAndGeneralization)

**Language GANs Falling Short**. Massimo Caccia, Lucas Caccia, William Fedus, Hugo Larochelle, Joelle Pineau, Laurent Charlin [MILA, Université de Montréal & MILA, McGill University & MILA, HEC Montréal & Google Brain & Facebook AI Research] (2018) [arXiv:1811.02549](https://arxiv.org/abs/1811.02549v3)

**CariGANs: Unpaired Photo-to-Caricature Translation**. K Cao, J Liao, L Yuan [Tsinghua University & Microsoft Research] (2018) [arXiv:1811.00222](https://arxiv.org/abs/1811.00222) [Blog](https://cari-gan.github.io) [App](https://ai.stanford.edu/~kaidicao/cari-gan/index.html) [YouTube](https://www.youtube.com/watch?v=V6G717ewUuw)

**Large Scale GAN Training for High Fidelity Natural Image Synthesis** | [OpenReview](https://openreview.net/forum?id=B1xsqj09Fm). (2018) 

**Generative adversarial networks and adversarial methods in biomedical image analysis**. J M. Wolterink, K Kamnitsas, C Ledig, I Išgum [University Medical Center Utrecht & Imperial College London & Imagen Technologies] (2018) [arXiv:1810.10352](https://arxiv.org/abs/1810.10352)

**Do Deep Generative Models Know What They Don't Know?**. E Nalisnick, A Matsukawa, Y W Teh, D Gorur, B Lakshminarayanan [DeepMind] (2018) [arXiv:1810.09136](https://arxiv.org/abs/1810.09136)

**Discriminator Rejection Sampling**. Samaneh Azadi, Catherine Olsson, Trevor Darrell, Ian Goodfellow, Augustus Odena   [UC Berkeley & Google Brain]. [arXiv:1810.06758](https://arxiv.org/abs/1810.06758)

**Refacing: reconstructing anonymized facial features using GANs**. D Abramian, A Eklund [Linkoping University] (2018) [arXiv:1810.06455](https://arxiv.org/abs/1810.06455)

**ClusterGAN : Latent Space Clustering in Generative Adversarial Networks**. S Mukherjee, H Asnani, E Lin, S Kannan [University of Washington] (2018) [arXiv:1809.03627](https://arxiv.org/abs/1809.03627)

**Whispered-to-voiced Alaryngeal Speech Conversion with Generative Adversarial Networks**. Santiago Pascual, Antonio Bonafonte, Joan Serrà, Jose A. Gonzalez [Universitat Polite`cnica de Catalunya & Telefo ́nica Research & Universidad de Ma ́laga, Spain] (2018) [arXiv:1808.10687](https://arxiv.org/abs/1808.10687)

**The relativistic discriminator: a key element missing from standard GAN**. Alexia Jolicoeur-Martineau [Lady Davis Institute Montreal, Canada] (2018) [arXiv:1807.00734](https://arxiv.org/abs/1807.00734)

**Do GANs learn the distribution? Some Theory and Empirics**. Sanjeev Arora, Andrej Risteski, Yi Zhang [Princeton University & MIT] (ICLR 2018) [OpenReview.net](https://openreview.net/forum?id=BJehNfW0-)

**Do GANs actually learn the distribution? An empirical study**. Sanjeev Arora, Yi Zhang [] (2017) [arXiv:1706.08224](https://arxiv.org/abs/1706.08224) [Reddit](https://www.reddit.com/r/MachineLearning/comments/6jxes2/r_170608224_do_gans_actually_learn_the/) [Blog](http://www.offconvex.org/2017/07/06/GANs3/)

**Generalization and Equilibrium in Generative Adversarial Nets (GANs)**. S Arora, R Ge, Y Liang, T Ma, Y Zhang [Princeton University & Duke University] (2017) [arXiv:1703.00573](https://arxiv.org/abs/1703.00573) [Blog](http://www.offconvex.org/2017/03/30/GANs2/) [Reddit](https://www.reddit.com/r/MachineLearning/comments/637u1l/r_generalization_and_equilibrium_in_generative/)

**Improved Techniques for Training GANs**. Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen [OpenAI] (2016) [arXiv:1606.03498](https://arxiv.org/abs/1606.03498) [Github](https://github.com/openai/improved-gan) [Reddit](https://www.reddit.com/r/MachineLearning/comments/4o0aj9/160603498_improved_techniques_for_training_gans/)



## :facepunch: Adversarial Examples/Attacks

**Multi-Label Adversarial Perturbations**. Q Song, H Jin, X Huang, X Hu [Texas A&M University] (2019) [arXiv:1901.00546](https://arxiv.org/abs/1901.00546)

**Adversarial Transfer Learning**. G Wilson, D J. Cook [Washington State University] (2018) [arXiv:1812.02849](https://arxiv.org/abs/1812.02849)

**Defensive Dropout for Hardening Deep Neural Networks under Adversarial Attacks**. S Wang, X Wang, P Zhao, W Wen, D Kaeli, P Chin, X Lin [Northeastern University & Boston university & Florida International University] (2018) [arXiv:1809.05165](https://arxiv.org/abs/1809.05165)

**Are adversarial examples inevitable?**. A Shafahi, W. R Huang, C Studer, S Feizi, T Goldstein (2018) [arXiv:1809.02104](https://arxiv.org/abs/1809.02104)

**Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples**. Anish Athalye, Nicholas Carlini, David Wagner [MIT & Berkeley] (2018) [arXiv:1802.00420](https://arxiv.org/abs/1802.00420) [Github](https://github.com/anishathalye/obfuscated-gradients)

**Generating Natural Adversarial Examples**. Z Zhao, D Dua, S Singh [University of California, Irvine] (2017) [arXiv:1710.11342](https://arxiv.org/abs/1710.11342) [Github](https://github.com/zhengliz/natural-adversary) [comment]





## :musical_note: Sound & Signal Processing

**Kymatio: Scattering Transforms in Python**. M Andreux, T Angles, G Exarchakis... [PSL Research University & Universite de Montreal & New York University] (2018) [arXiv:1812.11214](https://arxiv.org/abs/1812.11214) [Home](https://www.kymat.io)

**Deep Neural Networks for Automatic Classification of Anesthetic-Induced Unconsciousness**. Konstantinos Patlatzoglou, etc. [etc.] (2018) [PDF](./2018Patlatzoglou-DeepNeuralNetworks.pdf)

**Using Convolutional Neural Networks to Classify Audio Signal in Noisy Sound Scenes**. M.V. Gubin [South Ural State University] (2018 GloSIC) [PDF](https://ieeexplore.ieee.org/abstract/document/8570117) [Github](https://github.com/gubinmv/cnn_in_noisy_scenes)

**Interpretable Convolutional Filters with SincNet**. M Ravanelli, Y Bengio [Université de Montréal] (2018) [arXiv:1811.09725](https://arxiv.org/abs/1811.09725)  [GitHub](https://github.com/mravanelli/SincNet/)

**A Deep Neural Network for Unsupervised Anomaly Detection and Diagnosis in Multivariate Time Series Data**. C Zhang, D Song, Y Chen, X Feng, C Lumezanu, W Cheng, J Ni, B Zong, H Chen, N V. Chawla [University of Notre Dame & NEC Laboratories America & Columbia University] (2018) [arXiv:1811.08055](https://arxiv.org/abs/1811.08055)

**Stochastic Adaptive Neural Architecture Search for Keyword Spotting**. T Véniat, O Schwander, L Denoyer [Sorbonne Université & Facebook AI Research] (2018) [arXiv:1811.06753](https://arxiv.org/abs/1811.06753) [GitHub](https://github.com/TomVeniat/SANAS)

**Unifying Probabilistic Models for Time-Frequency Analysis**. W J. Wilkinson, M R Andersen, J D. Reiss, D Stowell, A Solin [Queen Mary University of London & Aalto University] (2018) [arXiv:1811.02489](https://arxiv.org/abs/1811.02489) [GitHub](https://github.com/wil-j-wil/unifying-prob-time-freq)

**WaveGlow: A Flow-based Generative Network for Speech Synthesis**. Ryan Prenger, Rafael Valle, Bryan Catanzaro [NVIDIA Corporation] (2018) [arXiv:1811.00002](https://arxiv.org/abs/1811.00002) [Github](https://github.com/NVIDIA/waveglow)

**Training neural audio classifiers with few data**. J Pons, J Serrà, X Serra [Telefonica Research & Universitat Pompeu Fabra] (2018) [arXiv:1810.10274](https://arxiv.org/abs/1810.10274) [Github](https://github.com/jordipons/neural-classifiers-with-few-audio/)

**End-to-end music source separation: is it possible in the waveform domain?**. F Lluís, J Pons, X Serra [Universitat Pompeu Fabra] (2018) [arXiv:1810.12187](https://arxiv.org/abs/1810.12187)

**Multilevel Wavelet Decomposition Network for Interpretable Time Series Analysis**. Jingyuan Wang, Ze Wang, Jianfeng Li, Junjie Wu.[Beihang University] (2018) [arXiv:1806.08946](https://arxiv.org/abs/1806.08946)

**Deep Convolutional Neural Networks On Multichannel Time Series For Human Activity Recognition**. Jian Bo Yang, Minh Nhut Nguyen, Phyo Phyo San, Xiao Li Li, Shonali Krishnaswamy (2015) [IJCAI2015](http://www.aaai.org/ocs/index.php/IJCAI/IJCAI15/paper/download/10710/11297)

**Towards a universal neural network encoder for time series**. J Serrà, S Pascual, A Karatzoglou [Telefonica Research & Universitat Politecnica de Catalunya] (2018)

**Sound Event Detection Using Spatial Features and Convolutional Recurrent Neural Network**. Sharath Adavanne, Pasi Pertilä, Tuomas Virtanen [Tampere University of Technology] (DCASE 2017) [arXiv:1706.02291](https://arxiv.org/abs/1706.02291) [Github](https://github.com/sharathadavanne/multichannel-sed-crnn)

**Time Series Classification Using Multi-Channels Deep Convolutional Neural Networks**. Yi Zheng, Qi Liu, Enhong Chen, Yong Ge, and J. Leon Zhao [USTC, et al.] (2014) [WAIM2014](http://staff.ustc.edu.cn/~cheneh/paper_pdf/2014/Yi-Zheng-WAIM2014.pdf)





## :chart_with_downwards_trend: Optimization & Generalization

**Elimination of All Bad Local Minima in Deep Learning**. K Kawaguchi, L P Kaelbling [MIT] (2019) [arXiv:1901.00279](https://arxiv.org/abs/1901.00279)

**Towards Understanding the Role of Over-Parametrization in Generalization of Neural Networks**. B Neyshabur, Z Li... [Princeton & Toyota Technological Institute at Chicago & Facebook AI Research] (2018) [arXiv:1805.12076](https://arxiv.org/abs/1805.12076) [Github](https://github.com/bneyshabur/over-parametrization) [Reddit](https://www.reddit.com/r/MLEVN/comments/92u58v/towards_understanding_the_role_of/)

**Visualizing the Loss Landscape of Neural Nets**. H Li, Z Xu, G Taylor, T Goldstein [University of Maryland & United States Naval Academy] (NIPS 2018) [arXiv:1712.09913](https://arxiv.org/abs/1712.09913) [Github](https://github.com/tomgoldstein/loss-landscape) [Reddit](https://www.reddit.com/r/MachineLearning/comments/7mr7j5/r_171209913_visualizing_the_loss_landscape_of/)

**Gradient Descent Happens in a Tiny Subspace**. G Gur-Ari, D A. Roberts, E Dyer [Institute for Advanced Study & Facebook AI Research & Johns Hopkins University] (2018) [arXiv:1812.04754](https://arxiv.org/abs/1812.04754)

**A Sufficient Condition for Convergences of Adam and RMSProp**. F Zou, L Shen, Z Jie, W Zhang, W Liu [Stony Brook University & Tencent AI Lab] (2018) [arXiv:1811.09358](https://arxiv.org/abs/1811.09358)

**Stochastic Gradient Descent Optimizes Over-parameterized Deep ReLU Networks**. D Zou, Y Cao, D Zhou, Q Gu [University of California, Los Angeles] (2018) [arXiv:1811.08888](https://arxiv.org/abs/1811.08888)

**Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers**. Z Allen-Zhu, Y Li, Y Liang [Microsoft Research AI & Stanford University & University of Wisconsin-Madison] (2018) [arXiv:1811.04918](https://arxiv.org/abs/1811.04918)

**A Convergence Theory for Deep Learning via Over-Parameterization**. Z Allen-Zhu, Y Li, Z Song [Microsoft Research AI & Stanford University & UT-Austin] (2018) [arXiv:1811.03962](https://arxiv.org/abs/1811.03962)

**Gradient Descent Finds Global Minima of Deep Neural Networks**. S S. Du, J D. Lee, H Li, L Wang, X Zhai [CMU & University of Southern California & Peking University & MIT] (2018) [arXiv:1811.03804](https://arxiv.org/abs/1811.03804)

**Identifying Generalization Properties in Neural Networks**. H Wang, N S Keskar, C Xiong, R Socher [Salesforce Research] (2018) [arXiv:1809.07402](https://arxiv.org/abs/1809.07402)

**Accelerating Natural Gradient with Higher-Order Invariance**. by Yang Song [Post](https://ermongroup.github.io/blog/geo/) [paper](http://proceedings.mlr.press/v80/song18a/song18a.pdf)



## :+1: Model Evaluation & Performance & Interpretion & Visualization

**Attribute-Aware Attention Model for Fine-grained Representation Learning**. K Han, J Guo, C Zhang, M Zhu [Peking University] (2019) [arXiv:1901.00392](https://arxiv.org/abs/1901.00392)

**Multi-class Classification without Multi-class Labels**. Y Hsu, Z Lv, J Schlosser, P Odom, Z Kira [Georgia Institute of Technology & Georgia Tech Research Institute] (ICLR 2019) [arXiv:1901.00544](https://arxiv.org/abs/1901.00544)

**Are All Training Examples Created Equal? An Empirical Study**. K Vodrahalli, K Li, J Malik [UC Berkeley] (2018) [arXiv:1811.12569](https://arxiv.org/abs/1811.12569) [知乎](https://zhuanlan.zhihu.com/p/52458512)

**Rethinking ImageNet Pre-training**. K He, R Girshick, P Dollár [Facebook AI Research (FAIR)] (2018) [arXiv:1811.08883](https://arxiv.org/abs/1811.08883)

**Efficient Identification of Approximate Best Configuration of Training in Large Datasets**. S Huang, C Wang, B Ding, S Chaudhuri [University of Illinois & Microsoft Research & Alibaba Group] (2018) [arXiv:1811.03250](https://arxiv.org/abs/1811.03250)

**Explaining Deep Learning Models - A Bayesian Non-parametric Approach**. W Guo, S Huang, Y Tao, X Xing, L Lin [The Pennsylvania State University & Netflix Inc & Columbia University] (2018) [arXiv:1811.03422](https://arxiv.org/abs/1811.03422)

**How deep is deep enough? - Optimizing deep neural network architecture**. A Schilling, J Rietsch, R Gerum, H Schulze, C Metzner, P Krauss [University Hospital Erlangen & Friedrich-Alexander University Erlangen-N¨urnberg (FAU)] (2018) [arXiv:1811.01753](https://arxiv.org/abs/1811.01753)

**Approximate Fisher Information Matrix to Characterise the Training of Deep Neural Networks**. Z Liao, T Drummond, I Reid, G Carneiro [University of Adelaide & Monash University] (2018) [arXiv:1810.06767](https://arxiv.org/abs/1810.06767)  [GitHub](https://github.com/zhibinliao89/fisher.info.mat.torch) 

**A Performance Evaluation of Convolutional Neural Networks for Face Anti Spoofing**. Chaitanya Nagpal, Shiv Ram Dubey (2018) [arXiv:1805.04176](https://arxiv.org/abs/1805.04176)

**An Information-Theoretic View for Deep Learning**. J Zhang, T Liu, D Tao [UBTECH Sydney AI Centre] (2018) [arXiv:1804.09060](https://arxiv.org/abs/1804.09060)

**Understanding Individual Neuron Importance Using Information Theory**. K Liu, R A Amjad, B C. Geiger [Technical University of Munich & Graz University of Technology] (2018) [arXiv:1804.06679](https://arxiv.org/abs/1804.06679)

**Understanding Convolutional Neural Network Training with Information Theory**. S Yu, R Jenssen, J C. Principe [University of Florida & University of Tromsø] (2018) [arXiv:1804.06537](https://arxiv.org/abs/1804.06537)

**A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay**. Leslie N. Smith. [arXiv:1803.09820](https://arxiv.org/abs/1803.09820)

**Focal Loss for Dense Object Detection**. Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, Piotr Dollár [Facebook AI Research] (2017) [arXiv:1708.02002](https://arxiv.org/abs/1708.02002) [Github](https://github.com/facebookresearch/Detectron)

- Samples & Datasets

  **Image Score: How to Select Useful Samples**. Simiao Zuo, Jialin Wu [University of Texas at Austin] (2018) [arXiv:1812.00334](https://arxiv.org/abs/1812.00334) [Reddit](https://www.reddit.com/r/MachineLearning/comments/a30cuw/181200334_image_score_how_to_select_useful_samples/)

  **Failing Loudly: An Empirical Study of Methods for Detecting Dataset Shift**. S Rabanser, S Günnemann, Z C. Lipton [CMU & Technical University of Munich] (2018) [arXiv:1810.11953](https://arxiv.org/abs/1810.11953)

  **How Many Samples are Needed to Learn a Convolutional Neural Network?**. S S. Du, Y Wang, X Zhai, S Balakrishnan, R Salakhutdinov, A Singh [CMU & University of Cambridge] (2018) [arXiv:1805.07883](https://arxiv.org/abs/1805.07883)

- Batch-size

  **An Empirical Model of Large-Batch Training**. Sam McCandlish, Jared Kaplan, Dario Amodei [OpenAI] (DECEMBER 14, 2018) [PDF](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/science-of-ai/An+Empirical+Model+of+Large-Batch+Training.pdf) [BLOG](https://blog.openai.com/science-of-ai/)

  **Don't Use Large Mini-Batches, Use Local SGD**. T Lin, S U. Stich, M Jaggi [EPFL] (2018) [arXiv:1808.07217](https://arxiv.org/abs/1808.07217)

  **Revisiting Small Batch Training for Deep Neural Networks**. Dominic Masters, Carlo Luschi. (2018) [arXiv:1804.07612](https://arxiv.org/abs/1804.07612)

- Saliency

  **Visualizing Deep Similarity Networks**. A Stylianou, R Souvenir, R Pless [George Washington University & Temple University] (2019) [arXiv:1901.00536](https://arxiv.org/abs/1901.00536) [Github](https://github.com/GWUvision/Similarity-Visualization)

  **Understanding Individual Decisions of CNNs via Contrastive Backpropagation**. J Gu, Y Yang, V Tresp [the University of Munich & Siemens AG] (2018) [arXiv:1812.02100](https://arxiv.org/abs/1812.02100)

  **Local Explanation Methods for Deep Neural Networks Lack Sensitivity to Parameter Values**. J Adebayo, J Gilmer, I Goodfellow, B Kim [Google Brain] (2018) [arXiv:1810.03307](https://arxiv.org/abs/1810.03307)  [OpenReview](https://openreview.net/forum?id=SJOYTK1vM)

  **Sanity Checks for Saliency Maps**. J Adebayo, J Gilmer, M Muelly, I Goodfellow, M Hardt, B Kim [Google Brain] (2018) [arXiv:1810.03292](https://arxiv.org/abs/1810.03292)

## :control_knobs: Model Configuration

**Flow Based Self-supervised Pixel Embedding for Image Segmentation**. B Ma, S Liu, Y Zhi, Q Song [CuraCloud] (2019) [arXiv:1901.00520](https://arxiv.org/abs/1901.00520)

**Bag of Tricks for Image Classification with Convolutional Neural Networks**. Tong He, Zhi Zhang, Hang Zhang, Zhongyue Zhang, Junyuan Xie, Mu Li [AWS] (2018) [arXiv:1812.01187](https://arxiv.org/abs/1812.01187) [Reddit](https://www.reddit.com/r/MachineLearning/comments/a4dxna/r_bag_of_tricks_for_image_classification_with/) [Slides[Reddit]](https://www.reddit.com/r/MachineLearning/comments/a5s8pv/r_a_bags_of_tricks_which_may_improve_deep/)

**Linear Backprop in non-linear networks**. Mehrdad Yazdani [University of California San Diego] (NIPS 2018) [OpenReview](https://openreview.net/forum?id=ByfPDyrYim) [机器之心](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650753228&idx=2&sn=fad16dfb7e96c4301ac3838f058ecaae)

**Seeing in the dark with recurrent convolutional neural networks**. T S. Hartmann [Harvard Medical School] (2018) [arXiv:1811.08537](https://arxiv.org/abs/1811.08537)

**Dataset Distillation**. T Wang, J Zhu, A Torralba, A A. Efros [Facebook AI Research & MIT & UC Berkeley] (2018) [arXiv:1811.10959](https://arxiv.org/abs/1811.10959)

**Retina U-Net: Embarrassingly Simple Exploitation of Segmentation Supervision for Medical Object Detection**. P F. Jaeger, S A. A. Kohl, S Bickelhaupt, F Isensee, T A Kuder, H Schlemmer, K H. Maier-Hein [German Cancer Research Center] (2018) [arXiv:1811.08661](https://arxiv.org/abs/1811.08661) [GitHub](https://github.com/pfjaeger/medicaldetectiontoolkit)

**Rethinking floating point for deep learning**. Jeff Johnson [Facebook AI Research] (2018) [arXiv:1811.01721](https://arxiv.org/abs/1811.01721) [Github](https://github.com/facebookresearch/deepfloat) [Blog](https://code.fb.com/ai-research/floating-point-math/)

**Quaternion Convolutional Neural Networks**. Xuanyu Zhu / Yi Xu / Hongteng Xu / Changjian Chen. [Shanghai Jiao Tong University & Duke University] (ECCV2018) ([pdf](http://openaccess.thecvf.com/content_ECCV_2018/html/Xuanyu_Zhu_Quaternion_Convolutional_Neural_ECCV_2018_paper.html))

**Why scatter plots suggest causality, and what we can do about it**. C T. Bergstrom, J D. West [University of Washington] (2018) [arXiv:1809.09328](https://arxiv.org/abs/1809.09328)

**Human activity recognition based on time series analysis using U-Net**. Y Zhang, Y Zhang, Z Zhang, J Bao, Y Song [Beijing University of Posts and Telecommunications & AIdong Super AI] (2018). [arXiv:1809.08113](https://arxiv.org/abs/1809.08113)

**Backprop Evolution**. M Alber, I Bello, B Zoph, P Kindermans, P Ramachandran, Q Le [TU Berlin & Google Brain] (2018) [arXiv:1808.01974](https://arxiv.org/abs/1808.01974)

**Learning Classifiers with Fenchel-Young Losses: Generalized Entropies, Margins, and Algorithms**. M Blondel, A F. T. Martins, V Niculae [NTT Communication Science Laboratories & Instituto de Telecomunicacoes] (2018) [arXiv:1805.09717](https://arxiv.org/abs/1805.09717) [Github](https://github.com/mblondel/fenchel-young-losses)

**Smooth Loss Functions for Deep Top-k Classification**. L Berrada, A Zisserman, M. P Kumar [University of Oxford] (2018) [arXiv:1802.07595](https://arxiv.org/abs/1802.07595) [Github](https://github.com/oval-group/smooth-topk)

**Learning Confidence for Out-of-Distribution Detection in Neural Networks**. T DeVries, G W. Taylor [University of Guelph & Vector Institute] (2018) [arXiv:1802.04865](https://arxiv.org/abs/1802.04865)

- Batch Normalization

  **Generalized Batch Normalization: Towards Accelerating Deep Neural Networks**. X Yuan, Z Feng, M Norton, X Li [University of Florida & Naval Postgraduate School] (2018) [arXiv:1812.03271](https://arxiv.org/abs/1812.03271)

  **How Does Batch Normalization Help Optimization? (No, It Is Not About Internal Covariate Shift)**. S Santurkar, D Tsipras, A Ilyas, A Madry [MIT] (2018) [arXiv:1805.11604](https://arxiv.org/abs/1805.11604) [YouTube](https://www.youtube.com/watch?v=ZOabsYbmBRM) [Reddit](https://www.reddit.com/r/MachineLearning/comments/8n4eot/r_how_does_batch_normalization_help_optimization/) [Notes from SALU](https://shaoanlu.wordpress.com/2018/07/12/notes-for-paper-how-does-batch-normalization-help-optimization-no-it-is-not-about-internal-covariate-shift/)





## 〽️ ODE & PDE

**Data Driven Governing Equations Approximation Using Deep Neural Networks**. T Qin, K Wu, D Xiu [The Ohio State University] (2018) [arXiv:1811.05537](https://arxiv.org/abs/1811.05537)

**Neural Ordinary Differential Equations**. Ricky T. Q. Chen, Yulia Rubanova, Jesse Bettencourt, David Duvenaud [University of Toronto, Canada] (NeurIPS 2018 | best paper) [arXiv:1806.07366](https://arxiv.org/abs/1806.07366) [Github](https://github.com/rtqichen/torchdiffeq) [Blog](https://rkevingibson.github.io/blog/neural-networks-as-ordinary-differential-equations/) [机器之心](https://mp.weixin.qq.com/s/ZEIsyV-0aTvYn6K8GyANPA)(【硬核NeruIPS 2018最佳论文，一个神经了的常微分方程】这是一篇神奇的论文，以前一层一层叠加的神经网络似乎突然变得连续了，反向传播也似乎不再需要一点一点往前传、一层一层更新参数了。 )

【《Neural Ordinary Differential Equations》论文解读】《Paper Summary: Neural Ordinary Differential Equations》by Branislav Holländer http://t.cn/EGPEh8y 

**Forward-Backward Stochastic Neural Networks: Deep Learning of High-dimensional Partial Differential Equations**. M Raissi [Brown University] (2018) [arXiv:1804.07010](https://arxiv.org/abs/1804.07010)





---



## :atom_symbol: Physics Related

**The Calabi-Yau Landscape: from Geometry, to Physics, to Machine-Learning**. Y He (2018) [arXiv:1812.02893](https://arxiv.org/abs/1812.02893)

**DeepSphere: Efficient spherical Convolutional Neural Network with HEALPix sampling for cosmological applications**. N Perraudin, M Defferrard, T Kacprzak, R Sgier [aSwiss Data Science Center (SDSC) & EPFL & ETH Zurich] (2018) [arXiv:1810.12186](https://arxiv.org/abs/1810.12186)

**Toward an AI Physicist for Unsupervised Learning**. T Wu, M Tegmark [MIT] (2018) [arXiv:1810.10525](https://arxiv.org/abs/1810.10525)

**Using Machine Learning to Predict the Evolution of Physics Research**. W Liu, S Saganowski, P Kazienko, S A Cheong [Nanyang Technological University & Wrocław University of Science and Technology] (2018) [arXiv:1810.12116](https://arxiv.org/abs/1810.12116)

**hep-th**. Y He, V Jejjala, B D. Nelson [University of London & Nankai University & Northeastern University] (2018) [arXiv:1807.00735](https://arxiv.org/abs/1807.00735) [comment]

**Physics-guided Neural Networks (PGNNs)**. Anuj Karpatne, William Watkins, Jordan Read, Vipin Kumar [University of Minnesota] (2017) [arXiv:1710.11431](https://arxiv.org/abs/1710.11431)



## :books: Review

**How Generative Adversarial Networks and Their Variants Work: An Overview**. Yongjun Hong, Uiwon Hwang, Jaeyoon Yoo, Sungroh Yoon [Seoul National University] (2017, 2018v9) [arXiv:1711.05914](https://arxiv.org/abs/1711.05914)

**A Survey on Multi-output Learning**. D Xu, Y Shi, I W. Tsang, Y Ong, C Gong, X Shen [ University of Technology Sydney & Nanyang Technological University] (2019) [arXiv:1901.00248](https://arxiv.org/abs/1901.00248)

**Analysis Methods in Neural Language Processing: A Survey**. Y Belinkov, J Glass [MIT] (2018) [arXiv:1812.08951](https://arxiv.org/abs/1812.08951) [Github](https://github.com/boknilev/nlp-analysis-methods) [Blog](https://boknilev.github.io/nlp-analysis-methods/)

**Neural Approaches to Conversational AI**. J Gao, M Galley, L Li [Microsoft Research & Google Brain] (2018) [arXiv:1809.08267](https://arxiv.org/abs/1809.08267)

**Recent Advances in Autoencoder-Based Representation Learning**. M Tschannen, O Bachem, M Lucic [ETH Zurich & Google AI] (2018) [arXiv:1812.05069](https://arxiv.org/abs/1812.05069)

**Learning From Positive and Unlabeled Data: A Survey**. J Bekker, J Davis [KU Leuven] (2018) [arXiv:1811.04820](https://arxiv.org/abs/1811.04820)

**Analyzing biological and artificial neural networks: challenges with opportunities for synergy?**. David G.T. Barrett, Ari S. Morcos, Jakob H. Macke [DeepMind; Technical University of Munich, Germany] (2018) [arXiv:1810.13373](https://arxiv.org/abs/1810.13373)

**Model Selection Techniques -- An Overview**. J Ding, V Tarokh, Y Yang [University of Minnesota & Duke University] (2018) [arXiv:1810.09583](https://arxiv.org/abs/1810.09583)

**Deep Learning with the Random Neural Network and its Applications**. Y Yin [Imperial College] (2018) [arXiv:1810.08653](https://arxiv.org/abs/1810.08653)

**The Frontiers of Fairness in Machine Learning**. A Chouldechova, A Roth [CMU & University of Pennsylvania] (2018) [arXiv:1810.08810](https://arxiv.org/abs/1810.08810)

**Applications of Deep Reinforcement Learning in Communications and Networking: A Survey**. N C Luong, D T Hoang, S Gong, D Niyato, P Wang, Y Liang, D I Kim [Nanyang Technological University & University of Technology Sydney & Chinese Academy of Sciences] (2018) [arXiv:1810.07862](https://arxiv.org/abs/1810.07862)

**A Survey on Deep Learning: Algorithms, Techniques, and Applications**. Pouyanfar S, Sadiq S, Yan Y, et al [ACM Computing Surveys (CSUR)] (2018) ([pdf](https://dl.acm.org/citation.cfm?id=3234150)) ([专知](https://mp.weixin.qq.com/s/AQrgvjFPXUpqfqQQgOFN9A))

**A Tale of Three Probabilistic Families: Discriminative, Descriptive and Generative Models**. Y N Wu, R Gao, T Han, S Zhu [UCLA] (2018) [arXiv:1810.04261](https://arxiv.org/abs/1810.04261)

**Deep learning for time series classification: a review**. H I Fawaz, G Forestier, J Weber, L Idoumghar, P Muller [Université Haute Alsace] (2018) [arXiv:1809.04356](https://arxiv.org/abs/1809.04356)

**A Survey on Deep Transfer Learning**. C Tan, F Sun, T Kong, W Zhang, C Yang, C Liu [Tsinghua University] (2018) [arXiv:1808.01974](https://arxiv.org/abs/1808.01974)

**Generalization Error in Deep Learning**. D Jakubovitz, R Giryes, M R. D. Rodrigues [Tel Aviv University & University College London] (2018) [arXiv:1808.01174](https://arxiv.org/abs/1808.01174)

**How convolutional neural network see the world - A survey of convolutional neural network visualization methods**. Z Qin, F Yu, C Liu, X Chen [George Mason University & Clarkson University] (2018) [arXiv:1804.11191](https://arxiv.org/abs/1804.11191)

**Deep Learning for Time-Series Analysis**. John Gamboa [University of Kaiserslautern, Germany] (2017) [arXiv:1701.01887](https://arxiv.org/abs/1701.01887)

**Deep Learning in Neural Networks: An Overview**. Ju ̈rgen Schmidhuber [University of Lugano & SUPSI, Switzerland] (2014) [arXiv:1404.7828](https://arxiv.org/abs/1404.7828)

- Graph Neural Networks

  **A Comprehensive Survey on Graph Neural Networks**. Z Wu, S Pan, F Chen, G Long, C Zhang, P S. Yu [University of Technology Sydney & Monash University & University of Illinois at Chicago] (2019) [arXiv:1901.00596](https://arxiv.org/abs/1901.00596)

  **Graph Neural Networks: A Review of Methods and Applications**. J Zhou, G Cui, Z Zhang, C Yang, Z Liu, M Sun [Tsinghua University] (2018) [arXiv:1812.08434](https://arxiv.org/abs/1812.08434)

  **Deep Learning on Graphs: A Survey**. Z Zhang, P Cui, W Zhu [Tsinghua University] (2018) [arXiv:1812.04202](https://arxiv.org/abs/1812.04202)



## :framed_picture: Figure Design & Dimension Reduction

**CFUN: Combining Faster R-CNN and U-net Network for Efficient Whole Heart Segmentation**. Z Xu, Z Wu, J Feng [Tsinghua University] (2018) [arXiv:1812.04914](https://arxiv.org/abs/1812.04914) [GitHub](https://github.com/Wuziyi616/CFUN)

**Deep Paper Gestalt**. J Huang [Virginia Tech] (2018) [arXiv:1812.08775](https://arxiv.org/abs/1812.08775) [GitHub](https://github.com/vt-vl-lab/paper-gestalt) [YouTube](https://www.youtube.com/watch?v=yQLsZLf02yg) [机器之心](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650754320&idx=1&sn=d6691ecd6adb98fa3c29986cf1efeebc&chksm=871a896eb06d00780f96e27b3ce3ee321c45ec21d30107f3e3778b5f674e172855a29fbcc70f&token=576114296&lang=zh_CN#rd)

**A Tutorial on Distance Metric Learning: Mathematical Foundations, Algorithms and Software**. J L Suárez, S García, F Herrera [University of Granada] (2018) [arXiv:1812.05944](https://arxiv.org/abs/1812.05944)

**Improving Generalization for Abstract Reasoning Tasks Using Disentangled Feature Representations**. X Steenbrugge, S Leroux, T Verbelen, B Dhoedt [Ghent University] (2018) [arXiv:1811.04784](https://arxiv.org/abs/1811.04784)

**UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction**. Leland McInnes and John Healy [Tutte Institute for Mathematics and Computing] (2018) [arXiv:1802.03426](https://arxiv.org/abs/1802.03426) [Github](https://github.com/lmcinnes/umap)







---

> Need to be reviewed.....

**Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs**. Y Balaji, H Hassani, R Chellappa, S Feizi [University of Maryland & University of Pennsylvania] (2018) [arXiv:1810.04147](https://arxiv.org/abs/1810.04147) [comment]

**Analyzing the Noise Robustness of Deep Neural Networks**. M Liu, S Liu, H Su, K Cao, J Zhu [Tsinghua University] (2018) [arXiv:1810.03913](https://arxiv.org/abs/1810.03913) [comment]

**Deep convolutional Gaussian processes**. K Blomqvist, S Kaski, M Heinonen [Aalto university] (2018) [arXiv:1810.03052](https://arxiv.org/abs/1810.03052) [GitHub](https://github.com/kekeblom/DeepCGP) [comment]

**Learning Confidence Sets using Support Vector Machines**. W Wang, X Qiao [Binghamton University] (2018) [arXiv:1809.10818](https://arxiv.org/abs/1809.10818) [comment]

**Learning with Random Learning Rates**. L Blier, P Wolinski, Y Ollivier [Facebook AI Research & Universite Paris Sud] (2018) [arXiv:1810.01322](https://arxiv.org/abs/1810.01322) [Github](https://github.com/leonardblier/alrao) [Blog](https://leonardblier.github.io/alrao/) [comment]

**Interpreting Adversarial Robustness: A View from Decision Surface in Input Space**. F Yu, C Liu, Y Wang, X Chen [George Mason University & Clarkson University & Northeastern University] (2018) [arXiv:1810.00144](https://arxiv.org/abs/1810.00144) [comment]

**Spurious samples in deep generative models: bug or feature?**. B Kégl, M Cherti, A Kazakçı [CNRS/Universite Paris-Saclay & PSL Research University] (2018) [arXiv:1810.01876](https://arxiv.org/abs/1810.01876) [comment]

**Inhibited Softmax for Uncertainty Estimation in Neural Networks**. M Możejko, M Susik, R Karczewski [Sigmoidal] (2018)  [arXiv:1810.01861](https://arxiv.org/abs/1810.01861) [GitHub](https://github.com/MSusik/Inhibited-softmax) [comment]

**Deep processing of structured data**. Ł Maziarka, M Śmieja, A Nowak, J Tabor, Ł Struski, P Spurek [Jagiellonian University] (2018) [arXiv:1810.01989](https://arxiv.org/abs/1810.01989) [comment]

**Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow**. Xue Bin Peng, Angjoo Kanazawa, Sam Toyer, Pieter Abbeel, Sergey Levine [University of California, Berkeley] (2018) [arXiv:1810.00821](https://arxiv.org/abs/1810.00821)

**Taming VAEs**. D J Rezende, F Viola [DeepMind] (2018) [arXiv:1810.00597](https://arxiv.org/abs/1810.00597) [comment]

**Adversarial Attacks and Defences: A Survey**. A Chakraborty, M Alam, V Dey, A Chattopadhyay, D Mukhopadhyay [Indian Institute of Technology & The Ohio State University & Nanyang Technological University] (2018) [arXiv:1810.00069](https://arxiv.org/abs/1810.00069) [comment]

**Over-Optimization of Academic Publishing Metrics: Observing Goodhart's Law in Action**. M Fire, C Guestrin [University of Washington] (2018) [arXiv:1809.07841](https://arxiv.org/abs/1809.07841) [comment]

**On the loss landscape of a class of deep neural networks with no bad local valleys**. Q Nguyen, M C Mukkamala, M Hein [Saarland University & University of Tübingen] (2018) [arXiv:1809.10749](https://arxiv.org/abs/1809.10749) [comment]

**Conditional WaveGAN**. Chae Young Lee, Anoop Toffy, Gue Jun Jung, Woo-Jin Han (2018) [GitHub](https://github.com/acheketa/cwavegan) [arXiv:1809.10636](https://arxiv.org/abs/1809.10636)

**An analytic theory of generalization dynamics and transfer learning in deep linear networks**. A K. Lampinen, S Ganguli [Stanford University] (2018) [arXiv:1809.10374](https://arxiv.org/abs/1809.10374) [comment]

**Dropout is a special case of the stochastic delta rule: faster and more accurate deep learning**. N Frazier-Logue, S J Hanson [Rutgers University] (2018) [arXiv:1808.03578](https://arxiv.org/abs/1808.03578) [comment]

**Grassmannian Learning: Embedding Geometry Awareness in Shallow and Deep Learning**. J Zhang, G Zhu, R W. H Jr., a K Huang [The University of Hong Kong] (2018) [arXiv:1808.02229](https://arxiv.org/abs/1808.02229) [comment]

**Is Robustness the Cost of Accuracy? -- A Comprehensive Study on the Robustness of 18 Deep Image Classification Models**. D Su, H Zhang... [IBM Research & University of California, Davis & MIT] (2018) [arXiv:1808.01688](https://arxiv.org/abs/1808.01688) [GitHub](https://github.com/huanzhang12/Adversarial_Survey) [comment]

**Recurrent Squeeze-and-Excitation Context Aggregation Net for Single Image Deraining**. Xia Li, Jianlong Wu, Zhouchen Lin, Hong Liu, Hongbin Zha. [Peking University] (2018) [arXiv:1807.05698](https://arxiv.org/abs/1807.05698) [GitHub](https://github.com/XiaLiPKU/RESCAN) [comment]

**Toward Convolutional Blind Denoising of Real Photographs**. S Guo, Z Yan, K Zhang, W Zuo, L Zhang [Harbin Institute of Technology & The Hong Kong Polytechnic University] (2018) [arXiv:1807.04686](https://arxiv.org/abs/1807.04686) [Github](https://github.com/GuoShi28/CBDNet) [comment]

**Seamless Nudity Censorship: an Image-to-Image Translation Approach based on Adversarial Training**. MD More, DM Souza, J Wehrmann, RC Barros (2018) [ResearchGate](https://www.researchgate.net/profile/Jonatas_Wehrmann/publication/325746502_Seamless_Nudity_Censorship_an_Image-to-Image_Translation_Approach_based_on_Adversarial_Training/links/5b2c7950aca2720785d66732/Seamless-Nudity-Censorship-an-Image-to-Image-Translation-Approach-based-on-Adversarial-Training.pdf) [comment]

**Classification and Geometry of General Perceptual Manifolds**. SY Chung, DD Lee, H Sompolinsky [Harvard University] (2018) [PRX](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.8.031003) [comment]

**The GAN Landscape: Losses, Architectures, Regularization, and Normalization**. K Kurach, M Lucic, X Zhai, M Michalski, S Gelly [Google Brain] (2018) [arXiv:1807.04720](https://arxiv.org/abs/1807.04720) [Github](https://github.com/google/compare_gan) [comment]

**Troubling Trends in Machine Learning Scholarship**. Z C. Lipton, J Steinhardt [Stanford University] (2018) [arXiv:1807.03341](https://arxiv.org/abs/1807.03341) [comment]

**On the Spectral Bias of Deep Neural Networks**. N Rahaman, D Arpit, A Baratin, F Draxler, M Lin, F A. Hamprecht, Y Bengio, A Courville [Heidelberg University & MILA] (2018) [arXiv:1806.08734](https://arxiv.org/abs/1806.08734) [comment]

**Opening the black box of deep learning**. D Lei, X Chen, J Zhao [Shanghai University] (2018) [arXiv:1805.08355](https://arxiv.org/abs/1805.08355) [comment]

**Foundations of Sequence-to-Sequence Modeling for Time Series**. V Kuznetsov, Z Mariet [Google Research & MIT] (2018) [arXiv:1805.03714](https://arxiv.org/abs/1805.03714)







---

[返回到首页](../index.html) | [返回到顶部](./APaperADay.html)


<div id="disqus_thread"></div>
<script>
/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://iphysresearch.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

<br>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
<br>

<script type="application/json" class="js-hypothesis-config">
  {
    "openSidebar": false,
    "showHighlights": true,
    "theme": classic,
    "enableExperimentalNewNoteButton": true
  }
</script>
<script async src="https://hypothes.is/embed.js"></script>



