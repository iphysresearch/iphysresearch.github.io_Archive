---
title: Paper Summary
date: 2018-08-22
---

[返回到首页](../index.html)

---

![](https://i.loli.net/2018/08/24/5b7fffecd8d1d.png)

---



# How to comment

> With use of the [hypothes.is](https://hypothes.is/) extension (right-sided), you can highlight, annote any comments and discuss these notes inline*at any pages*and *posts*.
>
> *Please Feel Free* to Let Me Know and *Share* it Here.



---



[TOC]



# :racing_car: **A Paper A Day**


Felt like I wasn’t reading enough – and what I was reading wasn’t sinking in enough. I also wanted to keep track of my sources in a more controlled manner. As a part of adding everything to my JabRef (maybe…), I figured I would write up my comments on papers. 

The goal is to read and comment once a day. and this [post](./APaperADay.html) will be updated day by day according to the reading process.

**Please note that these posts are for my future self to review the materials on these papers without reading them all over again.** 

Therefore, the list of contents is only collected due to my own interests.



<!--<details>
  <summary>Table of Contents</summary>
  <li><a href="#about">About</a></li>
  <li><a href="#install">Install</a></li>
  <li><a href="#usage">Usage</a></li>
  <li><a href="#update">Update</a></li>
  <li><a href="#contribute">Contribute</a></li>
  <li><a href="#license">License</a></li>
</details>-->


> Documentation is a love letter that you write to your future self.
>
> —— Damian Conway



<blockquote class="reddit-card" data-card-created="1543907974"><a href="https://www.reddit.com/r/MachineLearning/comments/a21d0q/what_are_the_must_read_papers_for_a_beginner_in/">What are the must read papers for a beginner in the field of Machine Learning and Artificial Intelligence? [Discussion]</a> from <a href="http://www.reddit.com/r/MachineLearning">r/MachineLearning</a></blockquote>
<script async src="//embed.redditmedia.com/widgets/platform.js" charset="UTF-8"></script>

[机器学习与深度学习经典论文整理](https://mp.weixin.qq.com/s/jKK6AwmCMGWgVK0vPX359w)

<!-- I am some comments
not end, not end...
here the comment ends -->

# :rainbow: GW Astronomy

## General

[Summary] Brügmann B. **Fundamentals of numerical relativity for gravitational wave sources**[J]. Science, 2018, 361(6400): 366-371.

[Summary] Samir A Hamouda and Salima Y Alwarfaliy. "**Gravitational Waves: The Physics of Space and Time**"[PDF](https://s3.amazonaws.com/academia.edu.documents/57199376/Gravitational_waves__1.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1537374292&Signature=umZx0ZmQYXLM9%2Fb2bu1kl5T5hN0%3D&response-content-disposition=inline%3B%20filename%3DGravitational_Waves_The_Physics_of_Space.pdf)

- What reading would you recommend for new grad students working on gravitational waves and compact object astrophysics?
  - "**Physics, Astrophysics and Cosmology with Gravitational Waves**" https://arxiv.org/pdf/0903.0338.pdf
  - "**The Geometry of Gravitational Wave Detection**" https://dcc.ligo.org/public/0106/T1300666/003/Whelan_geometry.pdf
  - "**Gravitational-wave sensitivity curves**" https://arxiv.org/pdf/1408.0740.pdf
  - "**Theory of Gravitational Waves**" https://arxiv.org/pdf/1607.04202.pdf
  - "**Gravitational wave sources in the era of multi-frequency gravitational wave astronomy**" https://arxiv.org/pdf/1610.05309.pdf
  - "**Gravitational waves from orbiting binaries without general relativity: a tutorial**" https://arxiv.org/pdf/1710.04635.pdf
  - "**Merging stellar-mass binary black holes**" https://arxiv.org/pdf/1806.05820.pdf
  - **gravitational-wave resources** http://hosting.astro.cornell.edu/~favata/gwresources.html
  - https://gr-asp.net | Serving last 13984 papers from gr-qc and related categories
  - https://www.black-holes.org <u>S</u>imulating E<u>x</u>tremef <u>S</u>pacetimes (SXS)

1. Jaranowski, Piotr, Andrzej Krolak, and Bernard F. Schutz. "Data analysis of gravitational-wave signals from spinning neutron stars: The signal and its detection." *Physical Review D* 58.6 (1998): 063001.
2. Jaranowski, Piotr, and Andrzej Krolak. "Data analysis of gravitational-wave signals from spinning neutron stars. II. Accuracy of estimation of parameters." *Physical Review D*59.6 (1999): 063003.
3. Jaranowski, Piotr, and Andrzej Krolak. "Data analysis of gravitational-wave signals from spinning neutron stars. III. Detection statistics and computational requirements." *Physical Review D* 61.6 (2000): 062001.
4. Astone P, Borkowski K M, Jaranowski P, et al. Data analysis of gravitational-wave signals from spinning neutron stars. IV. An all-sky search[J]. Physical Review D, 2002, 65(4): 042003.

[How do we know LIGO detected gravitational waves?](https://cqgplus.com/2016/06/06/how-do-we-know-ligo-detected-gravitational-waves/) Posted on [June 6, 2016](https://cqgplus.com/2016/06/06/how-do-we-know-ligo-detected-gravitational-waves/) by [Adam Day](https://cqgplus.com/author/publisherad/)

[The O2 Catalogue—It goes up to 11](https://cplberry.com/2018/12/07/o2-catalogue/) | An awesome review on O2 Catalogue posted by [CHRISTOPHER BERRY](https://cplberry.com/)

[Gravitational Waves from Gravitational Collapse](https://link.springer.com/article/10.12942/lrr-2011-1)

**Analyzing Gravitational Waves with General Relativity** https://arxiv.org/abs/1902.09801

## Data Analysis & Signal Processing in GW Astronomy

**A search for the isotropic stochastic background using data from Advanced LIGO's second observing run**.  https://arxiv.org/abs/1903.02886

**Looking for ancillary signals around GW150914**. https://arxiv.org/pdf/1903.02823.pdf

**Search for gravitational lensing signatures in LIGO-Virgo binary black hole events**. O.A. Hannuksela, K. Haris, K.K.Y. Ng, S. Kumar, A.K. Mehta, D. Keitel, T.G.F. Li, P. Ajith [Chinese University of Hong Kong, Tata Institute of Fundamental Research, MIT, Max-Planck-Institut für Gravitationsphysi, University of Portsmouth, Canadian Institute for Advanced Research] (2019) [arXiv:1901.02674](https://arxiv.org/abs/1901.02674)

**Matched-filter study and energy budget suggest no detectable gravitational-wave ‘extended emission’ from GW170817**. Miquel Oliver, David Keitel, Andrew L. Miller, Hector Estelles, Alicia M. Sintes [etc.][arXiv:1812.06724](https://arxiv.org/abs/1812.06724)

**The GstLAL template bank for spinning compact binary mergers in the second observation run of Advanced LIGO and Virgo**. Debnandini Mukherjee, etc. [etc.] (2018) [arXiv:1812.05121](https://arxiv.org/abs/1812.05121)

**Wavelet-based classification of transient signals for Gravitational Wave detectors**. <u>Elena Cuoco</u>, Massimiliano Razzano, Andrei Utina [EGO and Scuola Normale Superiore, Pisa University and INFN Pisa, Glasgow University] (2018 EUSIPCO) [PDF](https://ieeexplore.ieee.org/abstract/document/8553393)

**Structured sparsity regularization for gravitational-wave polarization reconstruction**. Fangchen Feng, Eric Chassande-Mottin and Philippe Bacon, Aure ́lia Fraysse [Univ. Paris Diderot & Univ. Paris-Sud] (2018 EUSIPCO) [PDF](https://ieeexplore.ieee.org/abstract/document/8553009)

**Detection and Estimation of Unmodeled Chirps**. Soumya D. Mohanty [The University of Texas Rio Grande Valley] (2018 EUSIPCO) [PDF](https://ieeexplore.ieee.org/abstract/document/8553248)

**GPU-Optimised Low-Latency Online Search for Gravitational Waves from Binary Coalescences**. Xiaoyang Guo, Qi Chu, Zhihui Du, Linqing Wen [Tsinghua University & University of Western Australia] (2018 EUSIPCO) [PDF](https://ieeexplore.ieee.org/abstract/document/8553574)

[[Paper Summary](./Techniques for gravitational-wave detection of compact binary coalescence.html)] **Techniques for gravitational-wave detection of compact binary coalescence**. Sarah Caudill for the LIGO Scientific Collaboration and the Virgo Collaboration [1098 XG Amsterdam, The Netherlands] (2018 EUSIPCO) [PDF](https://ieeexplore.ieee.org/abstract/document/8553549)

**Posterior samples of the parameters of black hole mergers released to date in the second Advanced LIGO--Virgo observing run**. Soumi De, Collin D. Capano, Christopher M. Biwer, Alexander H. Nitz, Duncan A. Brown [Syracuse U. & MPI Germany & Hannover & Los Alamos National Laboratory] (2018) [arXiv:1811.09232](https://arxiv.org/abs/1811.09232) [Github](https://github.com/gwastro/o2-bbh-pe)

**Investigating the noise residuals around the gravitational wave event GW150914**. Alex B. Nielsen, Alexander H. Nitz, Collin D. Capano, Duncan A. Brown [MPI Germany & Hannover Germany & Syracuse U.] (2018) [arXiv:1811.04071](https://arxiv.org/abs/1811.04071) [Github](https://github.com/gwastro/gw150914_investigation)

Creswell, James, et al. "**On the time lags of the LIGO signals**." *[Journal of Cosmology and Astroparticle Physics](http://iopscience.iop.org/article/10.1088/1475-7516/2017/08/013/meta)* 2017.08 (2017): 013. [arXiv:1706.04191](https://arxiv.org/abs/1706.04191)

[Paper Summary] Zevin, Michael, et al. "**Gravity Spy: integrating advanced LIGO detector characterization, <u>machine learning</u>, and citizen science**." *[Classical and quantum gravity](http://iopscience.iop.org/0264-9381/34/6/064003/)* 34.6 (2017): 064003. [arXiv:1611.04596](https://arxiv.org/abs/1611.04596) (**Current Challenge & CONV.**)

[Paper Summary] Abbott, Benjamin P., et al. "**GW170817: Observation of Gravitational Waves from a Binary Neutron Star Inspiral**." *[Physical Review Letters](https://journals.aps.org/prl/pdf/10.1103/PhysRevLett.119.161101)* 119.16 (2017): 161101. (**Glitch!**)

[Paper Summary] Abbott, B. P., et al. "**Binary black hole mergers in the first advanced LIGO observing run**." *[Physical Review X](https://link.aps.org/pdf/10.1103/PhysRevX.6.041015)* 6.4 (2016): 041015. [arXiv:1606.04856](https://arxiv.org/abs/1606.04856) (**Current Searches**)

[Paper Summary] Abbott, Benjamin P., et al. "**GW151226: Observation of gravitational waves from a 22-solar-mass binary black hole coalescence**." *[Physical review letters](https://link.aps.org/pdf/10.1103/PhysRevLett.116.241103)* 116.24 (2016): 241103. [arXiv:1606.04855](https://arxiv.org/abs/1606.04855) (**Current Searches & Current Parameter Estimation**)

[Paper Summary] Abbott, Benjamin P., et al. "**Characterization of transient noise in Advanced LIGO relevant to gravitational wave signal GW150914**." *[Classical and Quantum Gravity](http://iopscience.iop.org/article/10.1088/0264-9381/33/13/134001/meta)* 33.13 (2016): 134001. [arXiv:1602.03844](https://arxiv.org/abs/1602.03844)

**BayesLine: Bayesian Inference for Spectral Estimation of Gravitational Wave Detector Noise**. Tyson B. Littenberg, Neil J. Cornish [Northwestern U. & Montana State U.] (2015) [Phys. Rev. D 91, 084034](https://journals.aps.org/prd/abstract/10.1103/PhysRevD.91.084034) [arXiv:1410.3852](https://arxiv.org/abs/1410.3852)



https://orca.cf.ac.uk/118182/1/2019MuirAWMPhil.pdf



## GW data analysis with GWOSC

**Convenient filtering techniques for LIGO strain of the GW150914 event**. https://arxiv.org/abs/1903.00546

**A New Search Pipeline for Compact Binary Mergers: Results for Binary Black Holes in the First Observing Run of Advanced LIGO**. https://arxiv.org/abs/1902.10341

**A Highly Spinning and Aligned Binary Black Hole Merger in the Advanced LIGO First Observing Run**. https://arxiv.org/abs/1902.10331

**Potential Gravitational-wave and Gamma-ray Multi-messenger Candidate from Oct. 30, 2015**.  https://arxiv.org/abs/1902.09496

**Searches for Gravitational Waves from Known Pulsars at Two Harmonics in 2015–2017 LIGO Data**.https://arxiv.org/abs/1902.08507

**1-OGC: The first open gravitational-wave catalog of binary mergers from analysis of public Advanced LIGO data**. https://arxiv.org/abs/1811.01921



## GW Astronomy with Machine Learning

### GW related

**Deep Learning at Scale for Gravitational Wave Parameter Estimation of Binary Black Hole Mergers**. Hongyu Shen, E. A. Huerta, Zhizhen Zhao (2019) [arXiv:1903.01998](https://arxiv.org/abs/1903.01998)

**Deep learning detection of transients**. [Iftach Sadeh] (2019) [arXiv:1902.03620](https://arxiv.org/abs/1902.03620)

**Deep Learning for Multi-Messenger Astrophysics: A Gateway for Discovery in the Big Data Era**. ... <u>George D</u>, <u>Huerta E A</u>...etc. [USA] [arXiv:1902.00522](https://arxiv.org/abs/1902.00522)

**Sensitivity study using machine learning algorithms on simulated r-mode gravitational wave signals from newborn neutron stars**. Antonis Mytidis, Athanasios Aris Panagopoulos, Orestis P. Panagopoulos, Andrew Miller, Bernard Whiting  [...] (2019) [10.1103/PhysRevD.99.024024](https://doi.org/10.1103/PhysRevD.99.024024) [arXiv:1508.02064v2](https://arxiv.org/abs/1508.02064)

**TOROS Optical follow-up of the Advanced LIGO-VIRGO O2 second observational campaign**. Rodolfo Artola, Martin Beroiz, etc. [...] (2019) [arXiv:1901.02960](https://arxiv.org/abs/1901.02960)

**Gravitational Wave Denoising of Binary Black Hole Mergers with Deep Learning**. Wei Wei, E. A. Huerta [Urbana] (2019) [arXiv:1901.00869](https://arxiv.org/abs/1901.00869)

**A New Method to Observe Gravitational Waves emitted by Core Collapse Supernovae**. P. Astone, P. Cerda-Duran, I. Di Palma, M. Drago, F. Muciaccia, C. Palomba, F. Ricci [Italy] (2018) [10.1103/PhysRevD.98.122002](https://arxiv.org/ct?url=https%3A%2F%2Fdx.doi.org%2F10.1103%252FPhysRevD.98.122002&v=818db5a0) (2018) [arXiv:1812.05363](https://arxiv.org/abs/1812.05363)

**Predicting surface wave velocities at gravitational wave observatories using archival seismic data**. Nikhil Mukund, Michael Coughlin, Jan Harms, Sebastien Biscans, Jim Warner, Arnaud Pele, Keith Thorne, David Barker, Nicolas Arnaud, Fred Donovan, Irene Fiori, <u>Hunter Gabbard</u>, Brian Lantz, Richard Mittleman, Hugh Radkins, Bas Swinkels [...] (2018) [arXiv:1812.05185](https://arxiv.org/abs/1812.05185)

[Paper Summary] **Applying deep neural networks to the detection and space parameter estimation of compact binary coalescence with a network of gravitational wave detectors**. <u>Xilong Fan</u>, <u>Jin Li</u>, Xin Li, Yuanhong Zhong, Junwei Cao [Hubei University of Education & Chongqing U. & Tsinghua U.] (2018) [arXiv:1811.01380](https://arxiv.org/abs/1811.01380)

**Bilby: A user-friendly Bayesian inference library for gravitational-wave astronomy**. etc. [etc.] (2018) [arXiv:1811.02042](https://arxiv.org/abs/1811.02042)

**Total-variation methods for gravitational-wave denoising: performance tests on Advanced LIGO data**. Alejandro Torres-Forné, <u>Elena Cuoco</u>, Antonio Marquina, José A. Font, José M. Ibáñez [Universitat de Vale`ncia & EGO & SNS & INFN] (2018) [arXiv:1806.07329](https://arxiv.org/abs/1806.07329)

[Paper Summary] <u>Gabbard, H.</u>, Williams, M., Hayes, F., & <u>Messenger, C.</u> (2018). "**Matching matched filtering with deep networks for gravitational-wave astronomy**". *[Physical review letters](https://journals.aps.org/prl/pdf/10.1103/PhysRevLett.120.141103)*, *120*(14), 141103.

**A Method Of Detecting Gravitational Wave Based On Time-frequency Analysis And Convolutional Neural Networks**. Xiangru Li, Woliang Yu, Xilong Fan [arXiv:1712.00356](https://arxiv.org/abs/1712.00356)

[[Paper Summary](./Deep neural networks to enable real-time multimessenger astrophysics.html)] <u>George D</u>, <u>Huerta E A</u>. "**Deep neural networks to enable real-time multimessenger astrophysics**"[J]. Physical Review D, 2018, 97(4): 044039. (**First attempt using DNN!**)

**Classification methods for noise transients in advanced gravitational-wave detectors II: performance tests on Advanced LIGO data**. Jade Powell, Alejandro Torres-Forné, Ryan Lynch, Daniele Trifirò, <u>Elena Cuoco</u>, Marco Cavaglià, Ik Siong Heng, José A. Font [University of Glasgow, Universitat de Val\`encia, Cambridge, Universit\`a di Pisa, EGO, INFN, The University of Mississippi] (2016) [arXiv:1609.06262](https://arxiv.org/abs/1609.06262)

**Classification methods for noise transients in advanced gravitational-wave detectors**. Jade Powell, Daniele Trifiro, <u>Elena Cuoco</u>, Ik Siong Heng, Marco Cavaglia [University of Glasgow, EGO, INFN, The University of Mississippi] (2015) [arXiv:1505.01299](https://arxiv.org/abs/1505.01299)

Biswas R, Blackburn L, Cao J, et al. "**Application of machine learning algorithms to the study of noise artifacts in gravitational-wave data**"[J]. [Physical Review D](https://journals.aps.org/prd/abstract/10.1103/PhysRevD.88.062003), 2013, 88(6): 062003. [arXiv:1303.6984](https://arxiv.org/abs/1303.6984) (**ANN & SVM & RF**)





---

### GW not related

**Weak lensing cosmology with convolutional neural networks on noisy data**. [Dezső Ribli, Bálint Ármin Pataki, José Manuel Zorrilla Matilla, Daniel Hsu, Zoltán Haiman, István Csabai] (2019) [arXiv:1902.03663](https://arxiv.org/abs/1902.03663)

**Unsupervised learning and data clustering for the construction of Galaxy Catalogs in the Dark Energy Survey**. Asad Khan, E. A. Huerta, Sibo Wang, Robert Gruendl [University of Illinois at Urbana-Champaign, Urbana] (2018) [arXiv:1812.02183](https://arxiv.org/abs/1812.02183)

**Exploring galaxy evolution with generative models**. Kevin Schawinski, M. Dennis Turp, Ce Zhang [ETH Zurich] (2018) [arXiv:1812.01114](https://arxiv.org/abs/1812.01114)

**Probabilistic Random Forest: A machine learning algorithm for noisy datasets**. Itamar Reis, Dalya Baron, Sahar Shahaf [Tel-Aviv U.] (2018) [arXiv:1811.05994](https://arxiv.org/abs/1811.05994)

[[Paper Summary](./Classifying Lensed Gravitational Waves in the Geometrical Optics Limit with Machine Learning.html)] **Classifying Lensed Gravitational Waves in the Geometrical Optics Limit with Machine Learning**. Amit Jit Singh, Ivan S.C. Li, Otto A. Hannuksela, Tjonnie G.F. Li, Kyungmin Kim [The Chinese University of Hong Kong & Imperial College London] (2018) [arXiv:1810.07888](https://arxiv.org/abs/1810.07888)

**DeepSphere: Efficient spherical Convolutional Neural Network with HEALPix sampling for cosmological applications**. Nathanaël Perraudin, Michaël Defferrard, Tomasz Kacprzak, Raphael Sgier [Swiss Data Science Center & EPFL & ETH Zurich] (2018) [arXiv:1810.12186](https://arxiv.org/abs/1810.12186)

**Fusing numerical relativity and deep learning to detect higher-order multipole waveforms from eccentric binary black hole mergers**. Adam Rebei, <u>E. A. Huerta</u>, Sibo Wang, Sarah Habib, Roland Haas, Daniel Johnson, <u>Daniel George</u> [Urbana]  (2018) [arXiv:1807.09787](https://arxiv.org/abs/1807.09787)



http://www.tapir.caltech.edu/~vvarma/

# ❣️ Awesome Papers Related to My Interests

## Others

高频成分有助于解释卷积神经网络的生成 | High Frequency Component Helps Explain the Generalization of Convolutional Neural Networks | Haohan Wang、Xindi Wu、Pengcheng Yin、Eric P. Xing

在本文中，研究者研究了图像数据频谱与卷积神经网络生成行为之间的关系。他们首先注意到卷积神经网络有能力捕获图像的高频成分，而人类却几乎察觉不到这些高频成分。因此，这一观察结果可以作为对抗样本存在的一种解释，同时也有助于验证卷积神经网络鲁棒性和准确性之间的权衡。此外，观察结果直接引出的一些方法能够提升训练下卷积神经网络的对抗鲁棒性。最后，研究者利用这一观察结果设计了一种（半）黑盒对抗攻击方法。

**VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking**. Q Wang, H Muckenhirn, K Wilson, P Sridhar, Z Wu, J Hershey, R A. Saurous, R J. Weiss, Y Jia, I L Moreno [Google & Idiap Research Institute] (2018)  [arXiv:2018:04826](https://arxiv.org/abs/1810.04826) [Home](https://google.github.io/speaker-id/publications/VoiceFilter/) [VentureBeat](https://venturebeat.com/2018/10/12/google-researchers-use-ai-to-pick-out-voices-in-a-crowd/) [Tproger](https://tproger.ru/news/google-pick-out-voice/) [机器之心](https://www.jiqizhixin.com/articles/2018-10-17-8) [新智元](https://wallstreetcn.com/articles/3419688)

**Deep CNN-based Multi-task Learning for Open-Set Recognition**. P Oza, V M. Patel [Johns Hopkins University] (2019) [arXiv:1903.03161](https://arxiv.org/abs/1903.03161) 

**Phase-aware Speech Enhancement with Deep Complex U-Net**. H Choi, J Kim, J Huh, A Kim, J Ha, K Lee [Seoul National University & NAVER Corp] (2019) [arXiv:1903.03107](https://arxiv.org/abs/1903.03107) [Home](http://www.deepcomplexunet.tk)

**A Deep Generative Model of Speech Complex Spectrograms**. A A Nugraha, K Sekiguchi, K Yoshii [RIKEN Center for Advanced Intelligence Project (AIP) & Kyoto University] (2019)  [arXiv:1903.03269]

Utterance-level Aggregation For Speaker Recognition In The Wild. W Xie, A Nagrani, J S Chung, A Zisserman [University of Oxford] (2019) http://t.cn/EfEkz79 

《Bayesian Anomaly Detection and Classification》E Roberts, B A. Bassett, M Lochner [University of Cape Town] (2019) http://t.cn/EfHJOI7 

Heartbeat Anomaly Detection using Adversarial Oversampling. J L. P. Lima, D Macêdo, C Zanchettin [Universidade Federal de Pernambuco] (2019) [arXiv:1901.09972](https://arxiv.org/abs/1901.09972)

[RespNet: A deep learning model for extraction of respiration from photoplethysmogram](https://arxiv.org/abs/1902.04256). V Ravichandran, B Murugesan, V Balakarthikeyan, S M Shankaranarayana, K Ram, P S.P, J Joseph, M Sivaprakasam [Indian Institute of Technology Madras (IITM)] (2019) https://arxiv.org/abs/1902.04256

**AVP: Physics-informed Data Generation for Small-data Learning**. J Chen, Y Xie, K Wang, C Zhang, M A. Vannan, B Wang, Z Qian [Georgia Institute of Technology] (2019) [arXiv:1902.01522](https://arxiv.org/abs/1902.01522)

【基于CRNN的三维重叠音源事件定位和检测】’seld-net - Sound event localization and detection of overlapping sources in three dimensions using convolutional recurrent neural network' by yakku GitHub: http://t.cn/EcI63BR 

《Navigating with grid-like representations in artificial agents | DeepMind》 http://t.cn/R32KqjC ref:《Vector-based navigation using grid-like representations in artificial agents》http://t.cn/R32KqjN  GitHub:http://t.cn/Ec5Lguh

**Neural Networks Predict Fluid Dynamics Solutions from Tiny Datasets**. C White, D Ushizima, C Farhat [Stanford University] (2019) [arXiv:1902.00091](https://arxiv.org/abs/1902.00091) 用神经网络解决流体力学预测问题

**Active Anomaly Detection via Ensembles: Insights, Algorithms, and Interpretability**. S Das, M R Islam, N K Jayakodi, J R Doppa [Washington State University] (2019) [arXiv:1901.08930](https://arxiv.org/abs/1901.08930)

> 忽然有一个 idea，就是替换 active learner 为 match-filtering 的 pipeline。

**End-to-End Probabilistic Inference for Nonstationary Audio Analysis**. W J. Wilkinson, M R Andersen, J D. Reiss, D Stowell, A Solin [Queen Mary University of London & Aalto University] (2019) [arXiv:1901.11436]

**Unsupervised speech representation learning using WaveNet autoencoders**. J Chorowski, R J. Weiss, S Bengio, A v d Oord [University of Wrocław & Google Research & DeepMind] (2019) [arXiv:1901.08810] 

论文《Unsupervised speech representation learning using WaveNet autoencoders》介绍了通过将自编码神经网络用到语音波形提取语音中有意义的隐藏表征的无监督任务。目的是学习到一种能够捕捉信号中高层次语义内容的表征，同时又能够对有背景噪声或者潜在基频曲线（underlying pitch contour）的信号中的扰乱信息足够稳定。自编码器模型的行为由应用到隐藏表征的约束所决定。在此论文中，作者对比了三种变体：简单降维瓶颈、高斯变分自编码器和离散向量量化VAE。而后，作者对预测语音内容的能力等进行了分析。

**MAD-GAN: Multivariate Anomaly Detection for Time Series Data with Generative Adversarial Networks**. D Li, D Chen, L Shi, B Jin, J Goh, S Ng [National University of Singapore & UC Berkeley & ST Electronics (Info Security) Pte Ltd] (2019) [arXiv:1901.04997](https://arxiv.org/abs/1901.04997)

**Deep Neural Networks for Automatic Classification of Anesthetic-Induced Unconsciousness**. Konstantinos Patlatzoglou, etc. [etc.] (2018) [PDF](./2018Patlatzoglou-DeepNeuralNetworks.pdf)

**Using Convolutional Neural Networks to Classify Audio Signal in Noisy Sound Scenes**. M.V. Gubin [South Ural State University] (2018 GloSIC) [PDF](https://ieeexplore.ieee.org/abstract/document/8570117) [Github](https://github.com/gubinmv/cnn_in_noisy_scenes)

**Why does deep and cheap learning work so well?**. Henry W. Lin (Harvard), Max Tegmark (MIT), David Rolnick (MIT) (2016) [arXiv:1608.08225](https://arxiv.org/abs/1608.08225)

【基于深度网络的心脏病专家级动态心电图心律失常检测和分类】《Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network | Nature Medicine》[Stanford University] (2019) http://t.cn/EGEZz3N 

**Deep Speech Enhancement for Reverberated and Noisy Signals using Wide Residual Networks**. Dayana Ribas, Jorge Llombart, Antonio Miguel, Luis Vicente [University of Zaragoza] (2019) [arXiv:1901.00660](https://arxiv.org/abs/1901.00660)

**Seeing in the dark with recurrent convolutional neural networks**. T S. Hartmann [Harvard Medical School] (2018) [arXiv:1811.08537](https://arxiv.org/abs/1811.08537)

**CROSSBOW: Scaling Deep Learning with Small Batch Sizes on Multi-GPU Servers**. A Koliousis, P Watcharapichat, M Weidlich, L Mai, P Costa, P Pietzuch [Imperial College London & Microsoft Research & Humboldt-Universitat zu Berlin] (2019) [arXiv:1901.02244](https://arxiv.org/abs/1901.02244) [Github](https://github.com/lsds/Crossbow)





- Rotation-invariant convolutional neural networks for galaxy morphology prediction
- Deep learning for time series classification
- 《Learning Confidence for Out-of-Distribution Detection in Neural Networks》T DeVries, G W. Taylor [University of Guelph & Vector Institute] (2018) http://t.cn/RFPZvFB 
- 【流形学习与谱方法】《Manifold Learning and Spectral Methods》by David Pfau [DeepMind][*O*网页链接](http://t.cn/RdzYMu9) 
- GAN: https://arxiv.org/pdf/1701.00160.pdf
- 《Anomaly Detection with Generative Adversarial Networks for Multivariate Time Series》D Li, D Chen, J Goh, S Ng [National University of Singapore] (2018) http://t.cn/EvXuiAS 
- 【最新可复现图像去噪算法汇总】’Collection of popular and reproducible image denoising works.' by Bihan Wen GitHub: [*O*网页链接](http://t.cn/RkREnEk) another by Wenhan Yang [*O*网页链接](http://t.cn/RkREeyJ) 



## :cloud_with_rain: Denoising & Noise Modeling

> 【最新可复现图像去噪算法汇总】’Collection of popular and reproducible image denoising works.' by Bihan Wen GitHub: http://t.cn/RkREnEk another by Wenhan Yang http://t.cn/RkREeyJ 
>
> - by Bihan Wen
> - by Wenhan Yang

- [Paper Summary] K He, J Sun, X Tang. "**Single image haze removal using dark channel prior**" (2009)(**CVPR best paper**)([pdf](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.672.3815&rep=rep1&type=pdf))(**何凯明博士的第一篇paper！**)
- [Paper Summary] Olaf Ronneberger, Philipp Fischer, and Thomas Brox "**U-Net: Convolutional Networks for Biomedical Image Segmentation**" arXiv:1505.04597 (2015) **(U-Net)** ([Website](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)) ([code](https://github.com/xuyuting45/DSB2018-mx-unet)) ([code](https://github.com/chinakook/U-Net)) ([code](https://github.com/divamgupta/image-segmentation-keras/tree/master/Models)) ([code](https://github.com/chinakook/U-Net/blob/master/unet_gluon.ipynb)) ([code](https://gluon.mxnet.io/chapter14_generative-adversarial-networks/pixel2pixel.html?highlight=unet)) ([code](https://github.com/bckenstler/unet-nerve-segmentation-mxnet/blob/master/U-Net%20MXNet.ipynb))
- [Paper Summary] Xiao-Jiao Mao, Chunhua Shen, Yu-Bin Yang. "**Image Restoration Using Convolutional Auto-encoders with Symmetric Skip Connections**" arXiv:1606.08921 (2016) **(Skip connections)** ([code](https://github.com/7wik/convolutional-auto-encoders-with-skip-connections))
- [Paper Summary] F Zhu, G Chen, PA Heng. "**From Noise Modeling to Blind Image Denoising**" CVPR (2016) ([Website](https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Zhu_From_Noise_Modeling_CVPR_2016_paper.html))
- [Paper Summary] Fu, X., Huang, J., Ding, X., Liao, Y., Paisley. J "**Clearing the skies: A deep network architecture for single-image rain removal**" arXiv:1609.02087 (2017) (**DerainNet**)(a low-pass filter)
- [Paper Summary] Zhang, H., Sindagi, V., Patel. "**Image de-raining using a conditional generative adversarial network.**" arXiv:1701.05957 (2017) (去雨) (**ID-CGAN**)
- [Paper Summary] R Qian, R T. Tan, W Yang, J Su, J Liu. "**Attentive Generative Adversarial Network for Raindrop Removal from a Single Image**." arXiv:1711.10098 (2017) **(单图去雨)** ([code](http://t.cn/RDfhFhN)) (attentive GAN)
- [Paper Summary] Dmitry Ulyanov, Andrea Vedaldi, Victor Lempitsky. "**Deep Image Prior**" arXiv:1711.10925 (2017) ([Website](https://dmitryulyanov.github.io/deep_image_prior)) [机器之心](https://mp.weixin.qq.com/s/MePEEuwH-e5c2hwiEXo2wg)
- [Paper Summary] Li, R., Cheong, L.F., Tan, "**Single image deraining using scale-aware multi-stage recurrent network.**" arXiv:1712.06830 (2017)
- [Paper Summary] Jaakko Lehtinen, Jacob Munkberg, Jon Hasselgren, Samuli Laine, Tero Karras, Miika Aittala, Timo Aila "**Noise2Noise: Learning Image Restoration without Clean Data**" arXiv:1803.04189 (2018) (ICML 2018) ([机器之心](https://mp.weixin.qq.com/s/JZaWJzVHXShgTQUuiJlDVA)) ([nvidia](https://news.developer.nvidia.com/ai-can-now-fix-your-grainy-photos-by-only-looking-at-grainy-photos/)) ([GitHub](https://github.com/NVlabs/noise2noise))
- [Paper Summary] C Chen, Q Chen, J Xu, V Koltun. "**Learning to See in the Dark**" arXiv:1805.01934 (CVPR)(2018)([YouRube](https://www.youtube.com/watch?v=qWKUFK7MWvg&feature=youtu.be))
- [Paper Summary] D Stoller, S Ewert, S Dixon. "**Wave-U-Net: A Multi-Scale Neural Network for End-to-End Audio Source Separation**" arXiv:1806.03185 (**Wave-U-Net**)([code](https://github.com/f90/Wave-U-Net))([code](https://github.com/ShichengChen/WaveUNet))
- [Paper Summary] Jingwen Chen, Jiawei Chen, Hongyang Chao, Ming Yang. "**Image Blind Denoising With Generative Adversarial Network Based Noise Modeling**" CVPR (2018) **(GAN盲降噪)**([Website](http://openaccess.thecvf.com/content_cvpr_2018/html/Chen_Image_Blind_Denoising_CVPR_2018_paper.html))([将门创投](https://mp.weixin.qq.com/s/Vb0sIXC7s0yMRfhZFeC-wg))([PaperWeekly](https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247494460&idx=1&sn=df833e559d0d502c36358da721175bd3))
- [Paper Summary] S Guo, Z Yan, K Zhang, W Zuo, L Zhang. "**Toward Convolutional Blind Denoising of Real Photographs**" arXiv:1807.04686 (2018) **(CBDNet)** ([code](http://t.cn/Rgrv2Lr ))
- [Paper Summary] Xia Li, Jianlong Wu, Zhouchen Lin, Hong Liu1, and Hongbin Zha. "**Recurrent Squeeze-and-Excitation Context Aggregation Net for Single Image Deraining**." arXiv:1807.05698 (2018) **(单图去雨)** ([code](https://github.com/XiaLiPKU/RESCAN))(RESCAN)
- **I Can See Clearly Now : Image Restoration via De-Raining**. H Porav, T Bruls, P Newman [University of Oxford] (2019) [arXiv:1901.00893](https://arxiv.org/abs/1901.00893) [Home](https://ciumonk.github.io/RobotCar-rainy/)
- **Noise2Self: Blind Denoising by Self-Supervision**. J Batson, L Royer [Chan-Zuckerberg Biohub] (2019) [arXiv:1901.11365](https://arxiv.org/abs/1901.11365) [Github](https://github.com/czbiohub/noise2self)

《Self-Supervised Deep Image Denoising》S Laine, J Lehtinen, T Aila [NVIDIA] (2019) http://t.cn/EtlXNWl 



- DeVries T, Taylor G W. "**Learning Confidence for Out-of-Distribution Detection in Neural Networks**"[J]. arXiv:1802.04865, (2018).

---

## :surfer: Survey & Review

- [Paper Summary] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. "**Deep learning**." **(Three Giants' Survey)**

## :running_man: ImageNet Evolution & Models

> ![](https://i.loli.net/2018/08/31/5b88fe77f16e6.png)
>
> ![](https://i.loli.net/2018/08/31/5b89001a12508.png)
>
> ![](https://i.loli.net/2018/08/31/5b890a2ae3742.png)
>
> [From: Alfredo Canziani, Adam Paszke, Eugenio Culurciello, An Analysis of Deep Neural Network Models for Practical Applications, 2017.]
>
> *Deep Learning broke out from here！*

- [[Paper Summary](./ImageNet Classification with Deep Convolutional Neural Networks.html)] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. "**Imagenet classification with deep convolutional neural networks**." (2012). **(AlexNet, Deep Learning Breakthrough!)**
- [Paper Summary] Pierre Sermanet, David Eigen, Xiang Zhang, Michael Mathieu, Rob Fergus, Yann LeCun. "**OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks**" (2013). **(winner of the localization task of ILSVRC2013)**
- [Zeiler and Fergus, 2013] **(ZFNet)**
- [[Paper Summary](./Very deep convolutional networks for large-scale image recognition.html)] Simonyan, Karen, and Andrew Zisserman. "**Very deep convolutional networks for large-scale image recognition**." (2014).**(VGGNet,Neural Networks become very deep!)**
- [Paper Summary] Szegedy, Christian, et al. "**Going deeper with convolutions**." (2015).**(GoogLeNet, Deeper networks, computational efficiency)**
- [Paper Summary] He, Kaiming, et al. "**Deep residual learning for image recognition**." (2015).**(ResNet, Very very deep networks using residual connections, CVPR best paper)**
- Xception: Deep Learning with Depthwise Separable Convolutions. F Chollet (2016) 
- From: Alfredo Canziani, Adam Paszke, Eugenio Culurciello, 2017.
- Mahajan et al, “Exploring the Limits of Weakly Supervised Pretraining”, arXiv 2018
- **Invertible Residual Networks**. J Behrmann, W Grathwohl, R T. Q. Chen, D Duvenaud, J Jacobsen [University of Bremen & Vector Institute and University of Toronto] (2019) [arXiv:1811.00995](https://arxiv.org/abs/1811.00995) [机器之心](https://mp.weixin.qq.com/s/AyJ_ZtNFTjkWVH3_Kw7wJg) [AI科技评论](https://mp.weixin.qq.com/s/vTAirbw9WZUi4cJg4jwKGg)

【(Colab Notebooks)AlexNet/VGG/GoogleNet/Inception/MobileNet/ShuffleNet/ResNet/DenseNet的Keras参考实现(及速查)】’Material used for Deep Learning related workshops for Machine Learning Tokyo (MLT)' by Machine-Learning-Tokyo GitHub: http://t.cn/ELtfypS Cheat Sheet:http://t.cn/ELtfypo 



## :goal_net: Model Configurations

- [Paper Summary] Maas, Andrew L, Hannun, Awni Y, and Ng, Andrew Y. "**Rectifier nonlinearities improve neural network acoustic models.**" Proc. ICML, 30, (2013). **(Leaky ReLU)**
- [Paper Summary] Goodfellow, Ian J., Warde-Farley, David, Mirza, Mehdi, Courville, Aaron C., and Bengio, Yoshua.
  "**Maxout networks.**" In Proceedings of the 30th International Conference on Machine Learning, ICML (2013) **(Maxout "Neuron")**
- [Paper Summary] Graham, Ben. "**Spatially-sparse convolutional neural networks.**" ArXiv e-prints, September 2014c. **(very leaky ReLU)**
- [Paper Summary] X Glorot, Y Bengio. "**Understanding the difficulty of training deep feedforward neural networks**" Proceedings of the thirteenth international conference on artificial intelligence and statistics. (2010) **(Xavier initialization)** 
- [Paper Summary] K He, X Zhang, S Ren, J Sun. "**Delving deep into rectifiers: Surpassing human-level performance on imagenet classification**" Proceedings of the IEEE international conference on computer vision. (2015) **(Leaky ReLU & Xavier initialization with additional factor)**
- [Paper Summary] Ioffe, Sergey, and Christian Szegedy. "**Batch normalization: Accelerating deep network training by reducing internal covariate shift**." (2015).**(An outstanding Work in 2015)**
- [Paper Summary] DA Clevert, T Unterthiner, S Hochreiter. "**Fast and accurate deep network learning by exponential linear units (elus)**" arXiv:1511.07289 (2015)
- [Paper Summary] Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. "**Layer normalization**." (2016).**(Update of Batch Normalization)**
- [Paper Summary] Courbariaux, Matthieu, et al. "**Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to+ 1 or−1**." **(New Model,Fast)**
- [Paper Summary] Jaderberg, Max, et al. "**Decoupled neural interfaces using synthetic gradients**." (2016). **(Innovation of Training Method,Amazing Work)**
- [Paper Summary] Chen, Tianqi, Ian Goodfellow, and Jonathon Shlens. "Net2net: Accelerating learning via knowledge transfer."(2015).**(Modify previously trained network to reduce training epochs)**
- [Paper Summary] Wei, Tao, et al. "**Network Morphism.**" (2016). **(Modify previously trained network to reduce training epochs)**
- Girshick, “Fast R-CNN”, ICCV 2015 Figure copyright Ross Girshick, 2015. Reproduced with permission
- Karpathy and Fei-Fei, “Deep Visual-Semantic Alignments for Generating Image Descriptions”, CVPR 2015 
  - Figure copyright IEEE, 2015. Reproduced for educational purposes.



## :straight_ruler: Regularization



Ba, Kiros, and Hinton, “Layer Normalization”, arXiv 2016 **(Layer Normalization)**

Ulyanov et al, Improved Texture Networks: Maximizing Quality and Diversity in Feed-forward Stylization and Texture Synthesis, CVPR 2017 **(Instance Normalization)**

Wu and He, “Group Normalization”, arXiv 2018 (Appeared 3/22/2018) **(Group Normalization)**

Huang et al, “Decorrelated Batch Normalization”, arXiv 2018 (Appeared 4/23/2018) **(Decorrelated Batch Normalization)**



- **Dropout**
  - [Paper Summary] Hinton, Geoffrey E., et al. "**Improving neural networks by preventing co-adaptation of feature detectors**." (2012). 
  - [Paper Summary] Srivastava, Nitish, et al. "**Dropout: a simple way to prevent neural networks from overfitting**." (2014)

- Wan et al, “Regularization of Neural Networks using DropConnect”, ICML 2013 **(DropConnect)**
- Graham, “Fractional Max Pooling”, arXiv 2014 **(Fractional Max Pooling)**
- Huang et al, “Deep Networks with Stochastic Depth”, ECCV 2016 **(Stochastic Depth)**



## :skier: Optimization

- [Paper Summary] J Bergstra, Y Bengio. "**Random search for hyper-parameter optimization**" Journal of Machine Learning Research, (2012) **(Hyperparameter Optimization: Random search)**

- [Paper Summary] Sutskever, Ilya, et al. "**On the importance of initialization and momentum in deep learning**." (2013) **(SGD + Momentum optimizer)**
- [Paper Summary] Kingma, Diederik, and Jimmy Ba. "**Adam: A method for stochastic optimization**." (2014). **(Adam)(Maybe used most often currently)**
- [Paper Summary] Dauphin, Yann N., et al. "**Identifying and attacking the saddle point problem in high-dimensional non-convex optimization**" (2014) 
- [Paper Summary] Andrychowicz, Marcin, et al. "**Learning to learn by gradient descent by gradient descent**." (2016).**(Neural Optimizer,Amazing Work)**
- [Paper Summary] Han, Song, Huizi Mao, and William J. Dally. "**Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding**." (2015). **(ICLR best paper, new direction to make NN running fast,DeePhi Tech Startup)**
- [Paper Summary] Iandola, Forrest N., et al. "**SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 1MB model size**." (2016).**(Also a new direction to optimize NN,DeePhi Tech Startup)**
- **(L-BFGS)**
  - Le et al, “On optimization methods for deep learning, ICML 2011” 
  - Ba et al, “Distributed second-order optimization using Kronecker-factored approximations”, ICLR 2017

- **(Model Ensembles)**
  - Loshchilov and Hutter, “SGDR: Stochastic gradient descent with restarts”, arXiv 2016 
  - Huang et al, “Snapshot ensembles: train 1, get M for free”, ICLR 2017 
  - Figures copyright Yixuan Li and Geoff Pleiss, 2017. Reproduced with permission.
  - Polyak and Juditsky, “Acceleration of stochastic approximation by averaging”, SIAM Journal on Control and Optimization, 1992. **(Polyak averaging)**







## :tv: Visualization / Understanding / Generalization / Transfer

- Virsualization

  Krizhevsky, “One weird trick for parallelizing convolutional neural networks”, arXiv 2014（first layer）
  He et al, “Deep Residual Learning for Image Recognition”, CVPR 2016（first layer）
  Huang et al, “Densely Connected Convolutional Networks”, CVPR 2017（first layer）

  Van der Maaten and Hinton, “Visualizing Data using t-SNE”, JMLR 2008 （t-sne）

  Yosinski et al, “Understanding Neural Networks Through Deep Visualization”, ICML DL Workshop 2014（visualizing activations, Gradient Ascent - better regularizer）

  Springenberg et al, “Striving for Simplicity: The All Convolutional Net”, ICLR Workshop 2015（Maximally Activation Patches）

  Zeiler and Fergus, “Visualizing and Understanding Convolutional Networks”, ECCV 2014（Occlusion, Intermediate features via (guided) backprop）

  Simonyan, Vedaldi, and Zisserman, “Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps”, ICLR Workshop 2014.（Saliency, Gradient Ascent）

  Springenberg et al, “Striving for Simplicity: The All Convolutional Net”, ICLR Workshop 2015 (Intermediate features via (guided) backprop)

  Nguyen et al, “Multifaceted Feature Visualization: Uncovering the Different Types of Features Learned By Each Neuron in Deep Neural Networks”, ICML Visualization for Deep Learning Workshop 2016. (Gradient Ascent adding “multi-faceted” visualization )

  Nguyen et al, “Synthesizing the preferred inputs for neurons in neural networks via deep generator networks,” NIPS 2016（Gradient Ascent Optimize in FC6 latent space）

  Mahendran and Vedaldi, “Understanding Deep Image Representations by Inverting Them”, CVPR 2015（feature inversion）

  Johnson, Alahi, and Fei-Fei, “Perceptual Losses for Real-Time Style Transfer and Super-Resolution”, ECCV 2016. (feature inversion, Fast Style Transfer)
  Gatys, Ecker, and Bethge, “Texture Synthesis Using Convolutional Neural Networks”, NIPS 2015 (neural texture synthesis)

  Gatys, Ecker, and Bethge, “Image style transfer using convolutional neural networks”, CVPR 2016 (neural style transfer)

  Ulyanov et al, “Texture Networks: Feed-forward Synthesis of Textures and Stylized Images”, ICML 2016 (Fast Style Transfer)
  Ulyanov et al, “Instance Normalization: The Missing Ingredient for Fast Stylization”, arXiv 2016 (Fast Style Transfer)

  Dumoulin, Shlens, and Kudlur, “A Learned Representation for Artistic Style”, ICLR 2017. (one network, many styles)



Understanding deep learning requires rethinking generalization

- **Distilling the knowledge in a neural network** (2015), G. Hinton et al. [[pdf\]](http://arxiv.org/pdf/1503.02531)
- **Deep neural networks are easily fooled: High confidence predictions for unrecognizable images** (2015), A. Nguyen et al. [[pdf\]](http://arxiv.org/pdf/1412.1897)
- **How transferable are features in deep neural networks?** (2014), J. Yosinski et al. [[pdf\]](http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf)
- **Learning and transferring mid-Level image representations using convolutional neural networks** (2014), M. Oquab et al. [[pdf\]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Oquab_Learning_and_Transferring_2014_CVPR_paper.pdf)
- **Visualizing and understanding convolutional networks** (2014), M. Zeiler and R. Fergus [[pdf\]](http://arxiv.org/pdf/1311.2901)
- Transfer Learning
  - **Decaf: A deep convolutional activation feature for generic visual recognition** (2014), J. Donahue et al. [[pdf\]](http://arxiv.org/pdf/1310.1531)
  - **CNN features off-the-Shelf: An astounding baseline for recognition** (2014), A. Razavian et al. [[pdf\]](http://www.cv-foundation.org//openaccess/content_cvpr_workshops_2014/W15/papers/Razavian_CNN_Features_Off-the-Shelf_2014_CVPR_paper.pdf)



## :beginner: Weight Initialization

- **Understanding the difficulty of training deep feedforward neural networks** by Glorot and Bengio, 2010 [[PDF](http://www.jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf?hc_location=ufi)]
- **Exact solutions to the nonlinear dynamics of learning in deep linear neural networks** by Saxe et al, 2013 [[PDF](https://arxiv.org/pdf/1312.6120)]
- **Random walk initialization for training very deep feedforward networks** by Sussillo and Abbott, 2014 [[PDF](https://arxiv.org/pdf/1412.6558)]
- **Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification** by He et al., 2015 [[PDF](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf)]
- **Data-dependent Initializations of Convolutional Neural Networks** by Krähenbühl et al., 2015 [[PDF](https://arxiv.org/pdf/1511.06856)]
- **All you need is a good init**, Mishkin and Matas, 2015 [[PDF](https://arxiv.org/pdf/1511.06422)]







Detection and Segmentation

Sliding Window:

Farabet et al, “Learning Hierarchical Features for Scene Labeling,” TPAMI 2013 

Pinheiro and Collobert, “Recurrent Convolutional Neural Networks for Scene Labeling”, ICML 2014

Fully convolutional：

Long, Shelhamer, and Darrell, “Fully Convolutional Networks for Semantic Segmentation”, CVPR 2015

Noh et al, “Learning Deconvolution Network for Semantic Segmentation”, ICCV 2015

Multi-view 3D Reconstruction：

Choy, C. B., Xu, D., Gwak, J., Chen, K., & Savarese, S. (2016, October). 3d-r2n2: A unified approach for single and multi-view
3d object reconstruction. In European Conference on Computer Vision (pp. 628-644). Springer, Cham.

Human Pose Estimation:

Johnson and Everingham, "Clustered Pose and Nonlinear Appearance Models for Human Pose Estimation", BMVC 2010

Toshev and Szegedy, “DeepPose: Human Pose Estimation via Deep Neural Networks”, CVPR 2014







RNN

Ba, Mnih, and Kavukcuoglu, “Multiple Object Recognition with Visual Attention”, ICLR 2015. 

Gregor et al, “DRAW: A Recurrent Neural Network For Image Generation”, ICML 2015 

Sutskever et al, “Sequence to Sequence Learning with Neural Networks”, NIPS 2014

Karpathy, Johnson, and Fei-Fei: Visualizing and Understanding Recurrent Networks, ICLR Workshop 2016

Bengio et al, “Learning long-term dependencies with gradient descent is difficult”, IEEE Transactions on Neural Networks, 1994 

Pascanu et al, “On the difficulty of training recurrent neural networks”, ICML 2013

Hochreiter and Schmidhuber, “Long Short Term Memory”, Neural Computation 1997

Srivastava et al, “Highway Networks”, ICML DL Workshop 2015

Learning phrase representations using rnn encoder-decoder for statistical machine translation, Cho et al. 2014 **(GRU)**

LSTM: A Search Space Odyssey, Greff et al., 2015

An Empirical Exploration of Recurrent Network Architectures, Jozefowicz et al., 2015

---

[返回到首页](../index.html) | [返回到顶部](./index.html)


<div id="disqus_thread"></div>
<script>
/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://iphysresearch.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

<br>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
<br>

<script type="application/json" class="js-hypothesis-config">
  {
    "openSidebar": false,
    "showHighlights": true,
    "theme": classic,
    "enableExperimentalNewNoteButton": true
  }
</script>
<script async src="https://hypothes.is/embed.js"></script>



